{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple example reconstructing the sin function\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-28 18:02:23.439203: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-28 18:02:24.873689: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/maxi/Repos/SGpp/lib:\n",
      "2023-02-28 18:02:24.873810: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/maxi/Repos/SGpp/lib:\n",
      "2023-02-28 18:02:24.873817: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768, 9)\n"
     ]
    }
   ],
   "source": [
    "import HPO\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import pysgpp\n",
    "\n",
    "import sys\n",
    "\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import tensorflow.keras.optimizers as opt\n",
    "from scikeras.wrappers import KerasRegressor, KerasClassifier\n",
    "\n",
    "import sklearn.metrics\n",
    "\n",
    "def to_standard(lower, upper, value):\n",
    "    return (value-lower)/(upper-lower)\n",
    "\n",
    "\n",
    "def from_standard(lower, upper, value):\n",
    "    return value*(upper-lower)+lower\n",
    "\n",
    "\n",
    "dataset = np.loadtxt(\"pima-indians-diabetes.csv\", delimiter=\",\")\n",
    "print(dataset.shape)\n",
    "# separate the data from the target attributes\n",
    "X = dataset[:,0:7]\n",
    "Y = dataset[:,8]\n",
    "\n",
    "dataset = HPO.Dataset(X, Y)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameterspace & Model & Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUDGET = 100\n",
    "VERBOSE = 2\n",
    "CV = 2\n",
    "SCORING = 'accuracy'\n",
    "\n",
    "hyperparameterspace = {\n",
    "    'model__loss': [\"list\", 'binary_crossentropy', 'categorical_crossentropy', 'binary_crossentropy', 'mean_squared_error', 'mean_absolute_error'],\n",
    "    'model__optimizer': [\"list\", 'sgd', 'rmsprop', 'adam', 'adadelta', 'adagrad', 'adamax', 'adafactor', 'nadam', 'ftrl'],\n",
    "    'epochs': [\"interval-int\", 1, 400],\n",
    "    'optimizer__learning_rate': [\"interval\", 0.000001, 0.001]\n",
    "}\n",
    "\n",
    "##################### Model for grid and random search #####################\n",
    "\n",
    "# Function to create model, required for KerasClassifier\n",
    "def create_model(optimizer, loss):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(10, input_shape=(7,), activation='relu'))\n",
    "    model.add(Dense(20, activation='relu'))\n",
    "    model.add(Dense(10, activation='relu'))\n",
    "    model.add(Dense(20, activation='relu'))\n",
    "    model.add(Dense(10, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    if optimizer == 'sgd':\n",
    "        optimizer = opt.SGD()\n",
    "    elif optimizer == 'rmsprop':\n",
    "        optimizer = opt.RMSprop()\n",
    "    elif optimizer == 'adam':\n",
    "        optimizer = opt.Adam()\n",
    "    elif optimizer == 'adadelta':\n",
    "        optimizer = opt.Adadelta()\n",
    "    elif optimizer == 'adagrad':\n",
    "        optimizer = opt.Adagrad()\n",
    "    elif optimizer == 'adamax':\n",
    "        optimizer = opt.Adamax()\n",
    "    elif optimizer == 'adafactor':\n",
    "        optimizer = opt.Adafactor()\n",
    "    elif optimizer == 'nadam':\n",
    "        optimizer = opt.Nadam()\n",
    "    elif optimizer == 'ftrl':\n",
    "        optimizer = opt.Ftrl()\n",
    "\n",
    "    # Compile model\n",
    "    model.compile(loss=loss,\n",
    "                  optimizer=optimizer)\n",
    "    return model\n",
    "\n",
    "model = KerasClassifier(model=create_model, verbose=0)\n",
    "\n",
    "##################### Blackbox function for bayesian optimization #####################\n",
    "\n",
    "hyperparameterspace_special = {}\n",
    "for key in hyperparameterspace.keys():\n",
    "    liste = []\n",
    "    for i in range(1, len(hyperparameterspace[key])):\n",
    "        liste.append(hyperparameterspace[key][i])\n",
    "    hyperparameterspace_special[key] = liste\n",
    "\n",
    "\n",
    "def blackboxfunction(params):  # Maximizing \n",
    "    index = int(params[0]*(len(hyperparameterspace_special[\"model__loss\"])-1))\n",
    "    loss = hyperparameterspace_special[\"model__loss\"][index]\n",
    "    \n",
    "    index = int(params[1]*(len(hyperparameterspace_special[\"model__optimizer\"])-1))\n",
    "    model_optimizer = hyperparameterspace_special[\"model__optimizer\"][index]\n",
    "\n",
    "    epochs = int(params[2])\n",
    "\n",
    "    learning_rate = params[3]\n",
    "\n",
    "    # Function to create model, required for KerasClassifier\n",
    "    def create_model():\n",
    "        # create model\n",
    "        model = Sequential()\n",
    "        model.add(Dense(10, input_shape=(7,), activation='relu'))\n",
    "        model.add(Dense(20, activation='relu'))\n",
    "        model.add(Dense(10, activation='relu'))\n",
    "        model.add(Dense(20, activation='relu'))\n",
    "        model.add(Dense(10, activation='relu'))\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "        if model_optimizer == 'sgd':\n",
    "            optimizer = opt.SGD(learning_rate=learning_rate)\n",
    "        elif model_optimizer == 'rmsprop':\n",
    "            optimizer = opt.RMSprop(learning_rate=learning_rate)\n",
    "        elif model_optimizer == 'adam':\n",
    "            optimizer = opt.Adam(learning_rate=learning_rate)\n",
    "        elif model_optimizer == 'adadelta':\n",
    "            optimizer = opt.Adadelta(learning_rate=learning_rate)\n",
    "        elif model_optimizer == 'adagrad':\n",
    "            optimizer = opt.Adagrad(learning_rate=learning_rate)\n",
    "        elif model_optimizer == 'adamax':\n",
    "            optimizer = opt.Adamax(learning_rate=learning_rate)\n",
    "        elif model_optimizer == 'nadam':\n",
    "            optimizer = opt.Nadam(learning_rate=learning_rate)\n",
    "        elif model_optimizer == 'ftrl':\n",
    "            optimizer = opt.Ftrl(learning_rate=learning_rate)\n",
    "\n",
    "        # Compile model\n",
    "        model.compile(loss=loss,\n",
    "                    optimizer=optimizer)\n",
    "        return model\n",
    "\n",
    "    model = KerasClassifier(model=create_model, verbose=0)\n",
    "\n",
    "\n",
    "    model.fit(dataset.get_X_train(), dataset.get_Y_train(), epochs=epochs)\n",
    "\n",
    "    Y_predicted = model.predict(dataset.get_X_test())\n",
    "\n",
    "    return sklearn.metrics.accuracy_score(dataset.get_Y_test(), Y_predicted)\n",
    "    \n",
    "\n",
    "##################### Function for sparse grid search #####################\n",
    "class ExampleFunction(pysgpp.ScalarFunction): # Minimizing\n",
    "\n",
    "    def __init__(self):\n",
    "        super(ExampleFunction, self).__init__(len(hyperparameterspace))\n",
    "\n",
    "\n",
    "    def eval(self, x):\n",
    "        index = int(x[0]*(len(hyperparameterspace_special[\"model__loss\"])-1))\n",
    "        loss = hyperparameterspace_special[\"model__loss\"][index]\n",
    "        \n",
    "        index = int(x[1]*(len(hyperparameterspace_special[\"model__optimizer\"])-1))\n",
    "        model_optimizer = hyperparameterspace_special[\"model__optimizer\"][index]\n",
    "        \n",
    "        \n",
    "        epochs = int(from_standard(1, 400, x[2]))\n",
    "\n",
    "        learning_rate = from_standard(0.000001, 0.001, x[3])\n",
    "        \n",
    "        # Function to create model, required for KerasClassifier\n",
    "        def create_model():\n",
    "            # create model\n",
    "            model = Sequential()\n",
    "            model.add(Dense(10, input_shape=(7,), activation='relu'))\n",
    "            model.add(Dense(20, activation='relu'))\n",
    "            model.add(Dense(10, activation='relu'))\n",
    "            model.add(Dense(20, activation='relu'))\n",
    "            model.add(Dense(10, activation='relu'))\n",
    "            model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "            if model_optimizer == 'sgd':\n",
    "                optimizer = opt.SGD(learning_rate=learning_rate)\n",
    "            elif model_optimizer == 'rmsprop':\n",
    "                optimizer = opt.RMSprop(learning_rate=learning_rate)\n",
    "            elif model_optimizer == 'adam':\n",
    "                optimizer = opt.Adam(learning_rate=learning_rate)\n",
    "            elif model_optimizer == 'adadelta':\n",
    "                optimizer = opt.Adadelta(learning_rate=learning_rate)\n",
    "            elif model_optimizer == 'adagrad':\n",
    "                optimizer = opt.Adagrad(learning_rate=learning_rate)\n",
    "            elif model_optimizer == 'adamax':\n",
    "                optimizer = opt.Adamax(learning_rate=learning_rate)\n",
    "            elif model_optimizer == 'adafactor':\n",
    "                optimizer = opt.Adafactor(learning_rate=learning_rate)\n",
    "            elif model_optimizer == 'nadam':\n",
    "                optimizer = opt.Nadam(learning_rate=learning_rate)\n",
    "            elif model_optimizer == 'ftrl':\n",
    "                optimizer = opt.Ftrl(learning_rate=learning_rate)\n",
    "\n",
    "            # Compile model\n",
    "            model.compile(loss=loss,\n",
    "                        optimizer=optimizer)\n",
    "            return model\n",
    "\n",
    "        model = KerasClassifier(model=create_model, verbose=0)\n",
    "\n",
    "\n",
    "        model.fit(dataset.get_X_train(), dataset.get_Y_train(), epochs=epochs)\n",
    "\n",
    "        Y_predicted = model.predict(dataset.get_X_test())\n",
    "\n",
    "        return -sklearn.metrics.accuracy_score(dataset.get_Y_test().tolist(), Y_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 45 candidates, totalling 90 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-28 18:02:27.723215: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2023-02-28 18:02:27.723309: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (maxi-XPS-15-9560): /proc/driver/nvidia/version does not exist\n",
      "2023-02-28 18:02:27.725146: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END epochs=200, model__loss=binary_crossentropy, model__optimizer=sgd, optimizer__learning_rate=0.0005005000000000001; total time=   6.2s\n",
      "[CV] END epochs=200, model__loss=binary_crossentropy, model__optimizer=sgd, optimizer__learning_rate=0.0005005000000000001; total time=   5.6s\n",
      "[CV] END epochs=200, model__loss=binary_crossentropy, model__optimizer=rmsprop, optimizer__learning_rate=0.0005005000000000001; total time=   5.1s\n",
      "[CV] END epochs=200, model__loss=binary_crossentropy, model__optimizer=rmsprop, optimizer__learning_rate=0.0005005000000000001; total time=   5.4s\n",
      "[CV] END epochs=200, model__loss=binary_crossentropy, model__optimizer=adam, optimizer__learning_rate=0.0005005000000000001; total time=   6.3s\n",
      "[CV] END epochs=200, model__loss=binary_crossentropy, model__optimizer=adam, optimizer__learning_rate=0.0005005000000000001; total time=   5.7s\n",
      "[CV] END epochs=200, model__loss=binary_crossentropy, model__optimizer=adadelta, optimizer__learning_rate=0.0005005000000000001; total time=   5.1s\n",
      "[CV] END epochs=200, model__loss=binary_crossentropy, model__optimizer=adadelta, optimizer__learning_rate=0.0005005000000000001; total time=   5.1s\n",
      "[CV] END epochs=200, model__loss=binary_crossentropy, model__optimizer=adagrad, optimizer__learning_rate=0.0005005000000000001; total time=   4.5s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m optimization \u001b[39m=\u001b[39m HPO\u001b[39m.\u001b[39mOptimization(dataset, model, hyperparameterspace, \u001b[39mtype\u001b[39m\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mgrid_search\u001b[39m\u001b[39m\"\u001b[39m, cv\u001b[39m=\u001b[39mCV, scoring\u001b[39m=\u001b[39mSCORING, budget\u001b[39m=\u001b[39mBUDGET, verbosity\u001b[39m=\u001b[39mVERBOSE)\n\u001b[0;32m----> 2\u001b[0m result \u001b[39m=\u001b[39m optimization\u001b[39m.\u001b[39;49mfit()\n\u001b[1;32m      4\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mBest result:\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[39mprint\u001b[39m(result\u001b[39m.\u001b[39mbest_score_)\n",
      "File \u001b[0;32m~/Repos/Masterarbeit/Code/HPO.py:343\u001b[0m, in \u001b[0;36mOptimization.fit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtype \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mgrid_search\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    341\u001b[0m     clf \u001b[39m=\u001b[39m GridSearchCV(\n\u001b[1;32m    342\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhyperparameterspace_processed, cv\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcv, scoring\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscoring, error_score\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mraise\u001b[39m\u001b[39m'\u001b[39m, verbose\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbosity)\n\u001b[0;32m--> 343\u001b[0m     \u001b[39mreturn\u001b[39;00m clf\u001b[39m.\u001b[39;49mfit(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset\u001b[39m.\u001b[39;49mget_X(), \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset\u001b[39m.\u001b[39;49mget_Y())\n\u001b[1;32m    345\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtype \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mrandom_search\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    347\u001b[0m     clf \u001b[39m=\u001b[39m RandomizedSearchCV(\n\u001b[1;32m    348\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhyperparameterspace_processed, cv\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcv, scoring\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscoring, verbose\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbosity, n_iter\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbudget)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/model_selection/_search.py:874\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    868\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[1;32m    869\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    870\u001b[0m     )\n\u001b[1;32m    872\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[0;32m--> 874\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_search(evaluate_candidates)\n\u001b[1;32m    876\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    878\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/model_selection/_search.py:1388\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1386\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_search\u001b[39m(\u001b[39mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1387\u001b[0m     \u001b[39m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1388\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparam_grid))\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/model_selection/_search.py:821\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    813\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    814\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[1;32m    815\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFitting \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m folds for each of \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m candidates,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    816\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m totalling \u001b[39m\u001b[39m{2}\u001b[39;00m\u001b[39m fits\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m    817\u001b[0m             n_splits, n_candidates, n_candidates \u001b[39m*\u001b[39m n_splits\n\u001b[1;32m    818\u001b[0m         )\n\u001b[1;32m    819\u001b[0m     )\n\u001b[0;32m--> 821\u001b[0m out \u001b[39m=\u001b[39m parallel(\n\u001b[1;32m    822\u001b[0m     delayed(_fit_and_score)(\n\u001b[1;32m    823\u001b[0m         clone(base_estimator),\n\u001b[1;32m    824\u001b[0m         X,\n\u001b[1;32m    825\u001b[0m         y,\n\u001b[1;32m    826\u001b[0m         train\u001b[39m=\u001b[39;49mtrain,\n\u001b[1;32m    827\u001b[0m         test\u001b[39m=\u001b[39;49mtest,\n\u001b[1;32m    828\u001b[0m         parameters\u001b[39m=\u001b[39;49mparameters,\n\u001b[1;32m    829\u001b[0m         split_progress\u001b[39m=\u001b[39;49m(split_idx, n_splits),\n\u001b[1;32m    830\u001b[0m         candidate_progress\u001b[39m=\u001b[39;49m(cand_idx, n_candidates),\n\u001b[1;32m    831\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_and_score_kwargs,\n\u001b[1;32m    832\u001b[0m     )\n\u001b[1;32m    833\u001b[0m     \u001b[39mfor\u001b[39;49;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[39min\u001b[39;49;00m product(\n\u001b[1;32m    834\u001b[0m         \u001b[39menumerate\u001b[39;49m(candidate_params), \u001b[39menumerate\u001b[39;49m(cv\u001b[39m.\u001b[39;49msplit(X, y, groups))\n\u001b[1;32m    835\u001b[0m     )\n\u001b[1;32m    836\u001b[0m )\n\u001b[1;32m    838\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    839\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    840\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo fits were performed. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    841\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWas the CV iterator empty? \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    842\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWere there no candidates?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    843\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     58\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[1;32m     59\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[1;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     61\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[1;32m     62\u001b[0m )\n\u001b[0;32m---> 63\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/joblib/parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1085\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[1;32m   1086\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1088\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[1;32m   1089\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[1;32m   1091\u001b[0m \u001b[39mif\u001b[39;00m pre_dispatch \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mall\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   1092\u001b[0m     \u001b[39m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[1;32m   1093\u001b[0m     \u001b[39m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[1;32m   1094\u001b[0m     \u001b[39m# consumption.\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/joblib/parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    899\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    900\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 901\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch(tasks)\n\u001b[1;32m    902\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/joblib/parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    818\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[0;32m--> 819\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend\u001b[39m.\u001b[39;49mapply_async(batch, callback\u001b[39m=\u001b[39;49mcb)\n\u001b[1;32m    820\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[1;32m    821\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[1;32m    822\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[1;32m    823\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[1;32m    824\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/joblib/_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    207\u001b[0m     \u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[1;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[1;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/joblib/_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[1;32m    595\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[1;32m    596\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[0;32m--> 597\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/parallel.py:123\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m     config \u001b[39m=\u001b[39m {}\n\u001b[1;32m    122\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconfig):\n\u001b[0;32m--> 123\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    684\u001b[0m         estimator\u001b[39m.\u001b[39mfit(X_train, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[1;32m    685\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 686\u001b[0m         estimator\u001b[39m.\u001b[39;49mfit(X_train, y_train, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\n\u001b[1;32m    688\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[1;32m    689\u001b[0m     \u001b[39m# Note fit time as time until error\u001b[39;00m\n\u001b[1;32m    690\u001b[0m     fit_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start_time\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/scikeras/wrappers.py:1494\u001b[0m, in \u001b[0;36mKerasClassifier.fit\u001b[0;34m(self, X, y, sample_weight, **kwargs)\u001b[0m\n\u001b[1;32m   1492\u001b[0m     sample_weight \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m \u001b[39mif\u001b[39;00m sample_weight \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m sample_weight\n\u001b[1;32m   1493\u001b[0m     sample_weight \u001b[39m*\u001b[39m\u001b[39m=\u001b[39m compute_sample_weight(class_weight\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclass_weight, y\u001b[39m=\u001b[39my)\n\u001b[0;32m-> 1494\u001b[0m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mfit(X\u001b[39m=\u001b[39;49mX, y\u001b[39m=\u001b[39;49my, sample_weight\u001b[39m=\u001b[39;49msample_weight, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1495\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/scikeras/wrappers.py:762\u001b[0m, in \u001b[0;36mBaseWrapper.fit\u001b[0;34m(self, X, y, sample_weight, **kwargs)\u001b[0m\n\u001b[1;32m    757\u001b[0m kwargs[\u001b[39m\"\u001b[39m\u001b[39mepochs\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mget(\n\u001b[1;32m    758\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mepochs\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mfit__epochs\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mepochs)\n\u001b[1;32m    759\u001b[0m )\n\u001b[1;32m    760\u001b[0m kwargs[\u001b[39m\"\u001b[39m\u001b[39minitial_epoch\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39minitial_epoch\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m0\u001b[39m)\n\u001b[0;32m--> 762\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit(\n\u001b[1;32m    763\u001b[0m     X\u001b[39m=\u001b[39;49mX,\n\u001b[1;32m    764\u001b[0m     y\u001b[39m=\u001b[39;49my,\n\u001b[1;32m    765\u001b[0m     sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[1;32m    766\u001b[0m     warm_start\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mwarm_start,\n\u001b[1;32m    767\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    768\u001b[0m )\n\u001b[1;32m    770\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/scikeras/wrappers.py:931\u001b[0m, in \u001b[0;36mBaseWrapper._fit\u001b[0;34m(self, X, y, sample_weight, warm_start, epochs, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m    927\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeature_encoder_\u001b[39m.\u001b[39mtransform(X)\n\u001b[1;32m    929\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_model_compatibility(y)\n\u001b[0;32m--> 931\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_keras_model(\n\u001b[1;32m    932\u001b[0m     X,\n\u001b[1;32m    933\u001b[0m     y,\n\u001b[1;32m    934\u001b[0m     sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[1;32m    935\u001b[0m     warm_start\u001b[39m=\u001b[39;49mwarm_start,\n\u001b[1;32m    936\u001b[0m     epochs\u001b[39m=\u001b[39;49mepochs,\n\u001b[1;32m    937\u001b[0m     initial_epoch\u001b[39m=\u001b[39;49minitial_epoch,\n\u001b[1;32m    938\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    939\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/scikeras/wrappers.py:526\u001b[0m, in \u001b[0;36mBaseWrapper._fit_keras_model\u001b[0;34m(self, X, y, sample_weight, warm_start, epochs, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m    524\u001b[0m         hist \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_\u001b[39m.\u001b[39mfit(x\u001b[39m=\u001b[39mX, y\u001b[39m=\u001b[39my, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_args)\n\u001b[1;32m    525\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 526\u001b[0m     hist \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel_\u001b[39m.\u001b[39;49mfit(x\u001b[39m=\u001b[39;49mX, y\u001b[39m=\u001b[39;49my, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_args)\n\u001b[1;32m    528\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m warm_start \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mhistory_\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mor\u001b[39;00m initial_epoch \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    529\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhistory_ \u001b[39m=\u001b[39m defaultdict(\u001b[39mlist\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/engine/training.py:1650\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1642\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1643\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1644\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1647\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m   1648\u001b[0m ):\n\u001b[1;32m   1649\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1650\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   1651\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1652\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:880\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    877\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    879\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 880\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    882\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    883\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:912\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    909\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    910\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    911\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 912\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_no_variable_creation_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    913\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    914\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    915\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    916\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:133\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[39m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[39;00m\n\u001b[1;32m    131\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    132\u001b[0m   (concrete_function,\n\u001b[0;32m--> 133\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_maybe_define_function(args, kwargs)\n\u001b[1;32m    134\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\u001b[39m.\u001b[39m_call_flat(\n\u001b[1;32m    135\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39mconcrete_function\u001b[39m.\u001b[39mcaptured_inputs)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:324\u001b[0m, in \u001b[0;36mTracingCompiler._maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_maybe_define_function\u001b[39m(\u001b[39mself\u001b[39m, args, kwargs):\n\u001b[1;32m    304\u001b[0m   \u001b[39m\"\"\"Gets a function for these inputs, defining it if necessary.\u001b[39;00m\n\u001b[1;32m    305\u001b[0m \n\u001b[1;32m    306\u001b[0m \u001b[39m  Caller must hold self._lock.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    321\u001b[0m \u001b[39m      shape relaxation retracing.\u001b[39;00m\n\u001b[1;32m    322\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[1;32m    323\u001b[0m   args, kwargs, filtered_flat_args \u001b[39m=\u001b[39m (\n\u001b[0;32m--> 324\u001b[0m       \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_function_spec\u001b[39m.\u001b[39;49mcanonicalize_function_inputs(args, kwargs))\n\u001b[1;32m    326\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_signature \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    327\u001b[0m     args \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_signature\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/function_spec.py:536\u001b[0m, in \u001b[0;36mFunctionSpec.canonicalize_function_inputs\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m    533\u001b[0m       kwargs\u001b[39m.\u001b[39msetdefault(kwarg, default)\n\u001b[1;32m    535\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_input_signature \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 536\u001b[0m   inputs, flat_inputs, filtered_flat_inputs \u001b[39m=\u001b[39m _convert_numpy_inputs(inputs)\n\u001b[1;32m    537\u001b[0m   kwargs, flat_kwargs, filtered_flat_kwargs \u001b[39m=\u001b[39m _convert_numpy_inputs(kwargs)\n\u001b[1;32m    538\u001b[0m   flat_inputs \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m flat_kwargs\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/function_spec.py:625\u001b[0m, in \u001b[0;36m_convert_numpy_inputs\u001b[0;34m(inputs)\u001b[0m\n\u001b[1;32m    623\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_convert_numpy_inputs\u001b[39m(inputs):\n\u001b[1;32m    624\u001b[0m   \u001b[39m\"\"\"Converts numpy array inputs to tensors.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 625\u001b[0m   flat_inputs \u001b[39m=\u001b[39m composite_tensor_utils\u001b[39m.\u001b[39;49mflatten_with_variables(inputs)\n\u001b[1;32m    627\u001b[0m   \u001b[39m# Check for NumPy arrays in arguments and convert them to Tensors.\u001b[39;00m\n\u001b[1;32m    628\u001b[0m   \u001b[39m# TODO(nareshmodi): Skip ndarray conversion to tensor altogether, perhaps\u001b[39;00m\n\u001b[1;32m    629\u001b[0m   \u001b[39m# finding a way to store them directly in the cache key (currently not\u001b[39;00m\n\u001b[1;32m    630\u001b[0m   \u001b[39m# possible since ndarrays are not hashable).\u001b[39;00m\n\u001b[1;32m    631\u001b[0m   need_packing \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/composite_tensor_utils.py:35\u001b[0m, in \u001b[0;36mflatten_with_variables\u001b[0;34m(inputs)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[39m# We assume that any CompositeTensors have already converted their components\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[39m# from numpy arrays to Tensors, so we don't need to expand composites here for\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[39m# the numpy array conversion. Instead, we do so because the flattened inputs\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[39m# are eventually passed to ConcreteFunction()._call_flat, which requires\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[39m# expanded composites.\u001b[39;00m\n\u001b[1;32m     34\u001b[0m flat_inputs \u001b[39m=\u001b[39m []\n\u001b[0;32m---> 35\u001b[0m \u001b[39mfor\u001b[39;00m value \u001b[39min\u001b[39;00m nest\u001b[39m.\u001b[39;49mflatten(inputs):\n\u001b[1;32m     36\u001b[0m   \u001b[39mif\u001b[39;00m (\u001b[39misinstance\u001b[39m(value, composite_tensor\u001b[39m.\u001b[39mCompositeTensor) \u001b[39mand\u001b[39;00m\n\u001b[1;32m     37\u001b[0m       \u001b[39mnot\u001b[39;00m _pywrap_utils\u001b[39m.\u001b[39mIsResourceVariable(value)):\n\u001b[1;32m     38\u001b[0m     components \u001b[39m=\u001b[39m value\u001b[39m.\u001b[39m_type_spec\u001b[39m.\u001b[39m_to_components(value)  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/util/nest.py:454\u001b[0m, in \u001b[0;36mflatten\u001b[0;34m(structure, expand_composites)\u001b[0m\n\u001b[1;32m    452\u001b[0m   \u001b[39mreturn\u001b[39;00m [\u001b[39mNone\u001b[39;00m]\n\u001b[1;32m    453\u001b[0m expand_composites \u001b[39m=\u001b[39m \u001b[39mbool\u001b[39m(expand_composites)\n\u001b[0;32m--> 454\u001b[0m \u001b[39mreturn\u001b[39;00m _pywrap_utils\u001b[39m.\u001b[39;49mFlatten(structure, expand_composites)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optimization = HPO.Optimization(dataset, model, hyperparameterspace, type=\"grid_search\", cv=CV, scoring=SCORING, budget=BUDGET, verbosity=VERBOSE)\n",
    "result = optimization.fit()\n",
    "\n",
    "print(\"Best result:\")\n",
    "print(result.best_score_)\n",
    "print(\"Corresponding parameters:\")\n",
    "print(result.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 5 candidates, totalling 10 fits\n",
      "[CV] END epochs=200, model__loss=mean_squared_error, model__optimizer=adafactor, optimizer__learning_rate=0.0005005000000000001; total time=   0.1s\n",
      "[CV] END epochs=200, model__loss=mean_squared_error, model__optimizer=adafactor, optimizer__learning_rate=0.0005005000000000001; total time=   0.1s\n",
      "[CV] END epochs=200, model__loss=mean_absolute_error, model__optimizer=adam, optimizer__learning_rate=0.0005005000000000001; total time=   5.5s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m optimization \u001b[39m=\u001b[39m HPO\u001b[39m.\u001b[39mOptimization(dataset, model, hyperparameterspace, \u001b[39mtype\u001b[39m\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mrandom_search\u001b[39m\u001b[39m\"\u001b[39m, cv\u001b[39m=\u001b[39mCV, scoring\u001b[39m=\u001b[39mSCORING, budget\u001b[39m=\u001b[39mBUDGET, verbosity\u001b[39m=\u001b[39mVERBOSE)\n\u001b[0;32m----> 2\u001b[0m result \u001b[39m=\u001b[39m optimization\u001b[39m.\u001b[39;49mfit()\n\u001b[1;32m      3\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mBest result:\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[39mprint\u001b[39m(result\u001b[39m.\u001b[39mbest_score_)\n",
      "File \u001b[0;32m~/Repos/Masterarbeit/Code/HPO.py:349\u001b[0m, in \u001b[0;36mOptimization.fit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    345\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtype \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mrandom_search\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    347\u001b[0m     clf \u001b[39m=\u001b[39m RandomizedSearchCV(\n\u001b[1;32m    348\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhyperparameterspace_processed, cv\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcv, scoring\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscoring, verbose\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbosity, n_iter\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbudget)\n\u001b[0;32m--> 349\u001b[0m     \u001b[39mreturn\u001b[39;00m clf\u001b[39m.\u001b[39;49mfit(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset\u001b[39m.\u001b[39;49mget_X(), \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset\u001b[39m.\u001b[39;49mget_Y())\n\u001b[1;32m    351\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtype \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbayesian\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    352\u001b[0m     \u001b[39mreturn\u001b[39;00m bayesian_optimisation(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39mget_X(), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39mget_Y(), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbudget, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhyperparameterspace_processed)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/model_selection/_search.py:874\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    868\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[1;32m    869\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    870\u001b[0m     )\n\u001b[1;32m    872\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[0;32m--> 874\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_search(evaluate_candidates)\n\u001b[1;32m    876\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    878\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/model_selection/_search.py:1768\u001b[0m, in \u001b[0;36mRandomizedSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1766\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_search\u001b[39m(\u001b[39mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1767\u001b[0m     \u001b[39m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1768\u001b[0m     evaluate_candidates(\n\u001b[1;32m   1769\u001b[0m         ParameterSampler(\n\u001b[1;32m   1770\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparam_distributions, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_iter, random_state\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrandom_state\n\u001b[1;32m   1771\u001b[0m         )\n\u001b[1;32m   1772\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/model_selection/_search.py:821\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    813\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    814\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[1;32m    815\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFitting \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m folds for each of \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m candidates,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    816\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m totalling \u001b[39m\u001b[39m{2}\u001b[39;00m\u001b[39m fits\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m    817\u001b[0m             n_splits, n_candidates, n_candidates \u001b[39m*\u001b[39m n_splits\n\u001b[1;32m    818\u001b[0m         )\n\u001b[1;32m    819\u001b[0m     )\n\u001b[0;32m--> 821\u001b[0m out \u001b[39m=\u001b[39m parallel(\n\u001b[1;32m    822\u001b[0m     delayed(_fit_and_score)(\n\u001b[1;32m    823\u001b[0m         clone(base_estimator),\n\u001b[1;32m    824\u001b[0m         X,\n\u001b[1;32m    825\u001b[0m         y,\n\u001b[1;32m    826\u001b[0m         train\u001b[39m=\u001b[39;49mtrain,\n\u001b[1;32m    827\u001b[0m         test\u001b[39m=\u001b[39;49mtest,\n\u001b[1;32m    828\u001b[0m         parameters\u001b[39m=\u001b[39;49mparameters,\n\u001b[1;32m    829\u001b[0m         split_progress\u001b[39m=\u001b[39;49m(split_idx, n_splits),\n\u001b[1;32m    830\u001b[0m         candidate_progress\u001b[39m=\u001b[39;49m(cand_idx, n_candidates),\n\u001b[1;32m    831\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_and_score_kwargs,\n\u001b[1;32m    832\u001b[0m     )\n\u001b[1;32m    833\u001b[0m     \u001b[39mfor\u001b[39;49;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[39min\u001b[39;49;00m product(\n\u001b[1;32m    834\u001b[0m         \u001b[39menumerate\u001b[39;49m(candidate_params), \u001b[39menumerate\u001b[39;49m(cv\u001b[39m.\u001b[39;49msplit(X, y, groups))\n\u001b[1;32m    835\u001b[0m     )\n\u001b[1;32m    836\u001b[0m )\n\u001b[1;32m    838\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    839\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    840\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo fits were performed. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    841\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWas the CV iterator empty? \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    842\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWere there no candidates?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    843\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     58\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[1;32m     59\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[1;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     61\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[1;32m     62\u001b[0m )\n\u001b[0;32m---> 63\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/joblib/parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1085\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[1;32m   1086\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1088\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[1;32m   1089\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[1;32m   1091\u001b[0m \u001b[39mif\u001b[39;00m pre_dispatch \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mall\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   1092\u001b[0m     \u001b[39m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[1;32m   1093\u001b[0m     \u001b[39m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[1;32m   1094\u001b[0m     \u001b[39m# consumption.\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/joblib/parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    899\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    900\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 901\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch(tasks)\n\u001b[1;32m    902\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/joblib/parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    818\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[0;32m--> 819\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend\u001b[39m.\u001b[39;49mapply_async(batch, callback\u001b[39m=\u001b[39;49mcb)\n\u001b[1;32m    820\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[1;32m    821\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[1;32m    822\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[1;32m    823\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[1;32m    824\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/joblib/_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    207\u001b[0m     \u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[1;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[1;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/joblib/_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[1;32m    595\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[1;32m    596\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[0;32m--> 597\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/parallel.py:123\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m     config \u001b[39m=\u001b[39m {}\n\u001b[1;32m    122\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconfig):\n\u001b[0;32m--> 123\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    684\u001b[0m         estimator\u001b[39m.\u001b[39mfit(X_train, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[1;32m    685\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 686\u001b[0m         estimator\u001b[39m.\u001b[39;49mfit(X_train, y_train, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\n\u001b[1;32m    688\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[1;32m    689\u001b[0m     \u001b[39m# Note fit time as time until error\u001b[39;00m\n\u001b[1;32m    690\u001b[0m     fit_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start_time\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/scikeras/wrappers.py:1494\u001b[0m, in \u001b[0;36mKerasClassifier.fit\u001b[0;34m(self, X, y, sample_weight, **kwargs)\u001b[0m\n\u001b[1;32m   1492\u001b[0m     sample_weight \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m \u001b[39mif\u001b[39;00m sample_weight \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m sample_weight\n\u001b[1;32m   1493\u001b[0m     sample_weight \u001b[39m*\u001b[39m\u001b[39m=\u001b[39m compute_sample_weight(class_weight\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclass_weight, y\u001b[39m=\u001b[39my)\n\u001b[0;32m-> 1494\u001b[0m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mfit(X\u001b[39m=\u001b[39;49mX, y\u001b[39m=\u001b[39;49my, sample_weight\u001b[39m=\u001b[39;49msample_weight, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1495\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/scikeras/wrappers.py:762\u001b[0m, in \u001b[0;36mBaseWrapper.fit\u001b[0;34m(self, X, y, sample_weight, **kwargs)\u001b[0m\n\u001b[1;32m    757\u001b[0m kwargs[\u001b[39m\"\u001b[39m\u001b[39mepochs\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mget(\n\u001b[1;32m    758\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mepochs\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mfit__epochs\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mepochs)\n\u001b[1;32m    759\u001b[0m )\n\u001b[1;32m    760\u001b[0m kwargs[\u001b[39m\"\u001b[39m\u001b[39minitial_epoch\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39minitial_epoch\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m0\u001b[39m)\n\u001b[0;32m--> 762\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit(\n\u001b[1;32m    763\u001b[0m     X\u001b[39m=\u001b[39;49mX,\n\u001b[1;32m    764\u001b[0m     y\u001b[39m=\u001b[39;49my,\n\u001b[1;32m    765\u001b[0m     sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[1;32m    766\u001b[0m     warm_start\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mwarm_start,\n\u001b[1;32m    767\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    768\u001b[0m )\n\u001b[1;32m    770\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/scikeras/wrappers.py:931\u001b[0m, in \u001b[0;36mBaseWrapper._fit\u001b[0;34m(self, X, y, sample_weight, warm_start, epochs, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m    927\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeature_encoder_\u001b[39m.\u001b[39mtransform(X)\n\u001b[1;32m    929\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_model_compatibility(y)\n\u001b[0;32m--> 931\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_keras_model(\n\u001b[1;32m    932\u001b[0m     X,\n\u001b[1;32m    933\u001b[0m     y,\n\u001b[1;32m    934\u001b[0m     sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[1;32m    935\u001b[0m     warm_start\u001b[39m=\u001b[39;49mwarm_start,\n\u001b[1;32m    936\u001b[0m     epochs\u001b[39m=\u001b[39;49mepochs,\n\u001b[1;32m    937\u001b[0m     initial_epoch\u001b[39m=\u001b[39;49minitial_epoch,\n\u001b[1;32m    938\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    939\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/scikeras/wrappers.py:526\u001b[0m, in \u001b[0;36mBaseWrapper._fit_keras_model\u001b[0;34m(self, X, y, sample_weight, warm_start, epochs, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m    524\u001b[0m         hist \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_\u001b[39m.\u001b[39mfit(x\u001b[39m=\u001b[39mX, y\u001b[39m=\u001b[39my, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_args)\n\u001b[1;32m    525\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 526\u001b[0m     hist \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel_\u001b[39m.\u001b[39;49mfit(x\u001b[39m=\u001b[39;49mX, y\u001b[39m=\u001b[39;49my, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_args)\n\u001b[1;32m    528\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m warm_start \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mhistory_\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mor\u001b[39;00m initial_epoch \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    529\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhistory_ \u001b[39m=\u001b[39m defaultdict(\u001b[39mlist\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/engine/training.py:1650\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1642\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1643\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1644\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1647\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m   1648\u001b[0m ):\n\u001b[1;32m   1649\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1650\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   1651\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1652\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:880\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    877\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    879\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 880\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    882\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    883\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:912\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    909\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    910\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    911\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 912\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_no_variable_creation_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    913\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    914\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    915\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    916\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:133\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[39m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[39;00m\n\u001b[1;32m    131\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    132\u001b[0m   (concrete_function,\n\u001b[0;32m--> 133\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_maybe_define_function(args, kwargs)\n\u001b[1;32m    134\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\u001b[39m.\u001b[39m_call_flat(\n\u001b[1;32m    135\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39mconcrete_function\u001b[39m.\u001b[39mcaptured_inputs)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:336\u001b[0m, in \u001b[0;36mTracingCompiler._maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m    331\u001b[0m captures \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_captures_container\u001b[39m.\u001b[39mget_snapshot()\n\u001b[1;32m    333\u001b[0m \u001b[39m# cache_key_deletion_observer is useless here. It's based on all captures.\u001b[39;00m\n\u001b[1;32m    334\u001b[0m \u001b[39m# A new cache key will be built later when saving ConcreteFunction because\u001b[39;00m\n\u001b[1;32m    335\u001b[0m \u001b[39m# only active captures should be saved.\u001b[39;00m\n\u001b[0;32m--> 336\u001b[0m lookup_func_key, _ \u001b[39m=\u001b[39m function_context\u001b[39m.\u001b[39;49mmake_cache_key((args, kwargs),\n\u001b[1;32m    337\u001b[0m                                                      captures)\n\u001b[1;32m    338\u001b[0m concrete_function \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_function_cache\u001b[39m.\u001b[39mlookup(lookup_func_key, \u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    339\u001b[0m \u001b[39mif\u001b[39;00m concrete_function \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/function_context.py:133\u001b[0m, in \u001b[0;36mmake_cache_key\u001b[0;34m(args, captures)\u001b[0m\n\u001b[1;32m    131\u001b[0m   captures \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m()\n\u001b[1;32m    132\u001b[0m signature_context \u001b[39m=\u001b[39m trace_type\u001b[39m.\u001b[39mInternalTracingContext()\n\u001b[0;32m--> 133\u001b[0m args_signature \u001b[39m=\u001b[39m trace_type\u001b[39m.\u001b[39;49mfrom_value(\n\u001b[1;32m    134\u001b[0m     args, signature_context)\n\u001b[1;32m    135\u001b[0m captures_dict_tracetype \u001b[39m=\u001b[39m trace_type\u001b[39m.\u001b[39mfrom_value(\n\u001b[1;32m    136\u001b[0m     captures, signature_context)\n\u001b[1;32m    138\u001b[0m \u001b[39m# TODO(fmuham): Use the actual FunctionType\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/core/function/trace_type/trace_type_builder.py:129\u001b[0m, in \u001b[0;36mfrom_value\u001b[0;34m(value, context)\u001b[0m\n\u001b[1;32m    126\u001b[0m     \u001b[39mreturn\u001b[39;00m default_types\u001b[39m.\u001b[39mNamedTuple\u001b[39m.\u001b[39mfrom_type_and_attributes(\n\u001b[1;32m    127\u001b[0m         named_tuple_type, \u001b[39mtuple\u001b[39m(from_value(c, context) \u001b[39mfor\u001b[39;00m c \u001b[39min\u001b[39;00m value))\n\u001b[1;32m    128\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 129\u001b[0m     \u001b[39mreturn\u001b[39;00m default_types\u001b[39m.\u001b[39;49mTuple(\u001b[39m*\u001b[39;49m(from_value(c, context) \u001b[39mfor\u001b[39;49;00m c \u001b[39min\u001b[39;49;00m value))\n\u001b[1;32m    131\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(value, collections\u001b[39m.\u001b[39mabc\u001b[39m.\u001b[39mMapping):\n\u001b[1;32m    132\u001b[0m   \u001b[39mreturn\u001b[39;00m default_types\u001b[39m.\u001b[39mDict({k: from_value(value[k], context) \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m value})\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/core/function/trace_type/trace_type_builder.py:129\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    126\u001b[0m     \u001b[39mreturn\u001b[39;00m default_types\u001b[39m.\u001b[39mNamedTuple\u001b[39m.\u001b[39mfrom_type_and_attributes(\n\u001b[1;32m    127\u001b[0m         named_tuple_type, \u001b[39mtuple\u001b[39m(from_value(c, context) \u001b[39mfor\u001b[39;00m c \u001b[39min\u001b[39;00m value))\n\u001b[1;32m    128\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 129\u001b[0m     \u001b[39mreturn\u001b[39;00m default_types\u001b[39m.\u001b[39mTuple(\u001b[39m*\u001b[39m(from_value(c, context) \u001b[39mfor\u001b[39;00m c \u001b[39min\u001b[39;00m value))\n\u001b[1;32m    131\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(value, collections\u001b[39m.\u001b[39mabc\u001b[39m.\u001b[39mMapping):\n\u001b[1;32m    132\u001b[0m   \u001b[39mreturn\u001b[39;00m default_types\u001b[39m.\u001b[39mDict({k: from_value(value[k], context) \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m value})\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/core/function/trace_type/trace_type_builder.py:114\u001b[0m, in \u001b[0;36mfrom_value\u001b[0;34m(value, context)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[39mif\u001b[39;00m context\u001b[39m.\u001b[39mis_legacy_signature \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(value, trace\u001b[39m.\u001b[39mTraceType):\n\u001b[1;32m    113\u001b[0m   \u001b[39mreturn\u001b[39;00m value\n\u001b[0;32m--> 114\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39;49m(value, trace\u001b[39m.\u001b[39;49mSupportsTracingProtocol):\n\u001b[1;32m    115\u001b[0m   \u001b[39mreturn\u001b[39;00m value\u001b[39m.\u001b[39m__tf_tracing_type__(context)\n\u001b[1;32m    117\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(value, \u001b[39m\"\u001b[39m\u001b[39m__wrapped__\u001b[39m\u001b[39m\"\u001b[39m):\n",
      "File \u001b[0;32m/usr/lib/python3.10/typing.py:1502\u001b[0m, in \u001b[0;36m_ProtocolMeta.__instancecheck__\u001b[0;34m(cls, instance)\u001b[0m\n\u001b[1;32m   1493\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m   1494\u001b[0m     \u001b[39mgetattr\u001b[39m(\u001b[39mcls\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m_is_protocol\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mFalse\u001b[39;00m) \u001b[39mand\u001b[39;00m\n\u001b[1;32m   1495\u001b[0m     \u001b[39mnot\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mcls\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m_is_runtime_protocol\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mFalse\u001b[39;00m) \u001b[39mand\u001b[39;00m\n\u001b[1;32m   1496\u001b[0m     \u001b[39mnot\u001b[39;00m _allow_reckless_class_checks(depth\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[1;32m   1497\u001b[0m ):\n\u001b[1;32m   1498\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mInstance and class checks can only be used with\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1499\u001b[0m                     \u001b[39m\"\u001b[39m\u001b[39m @runtime_checkable protocols\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   1501\u001b[0m \u001b[39mif\u001b[39;00m ((\u001b[39mnot\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mcls\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m_is_protocol\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mFalse\u001b[39;00m) \u001b[39mor\u001b[39;00m\n\u001b[0;32m-> 1502\u001b[0m         _is_callable_members_only(\u001b[39mcls\u001b[39;49m)) \u001b[39mand\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m         \u001b[39missubclass\u001b[39m(instance\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m, \u001b[39mcls\u001b[39m)):\n\u001b[1;32m   1504\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m   1505\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_is_protocol:\n",
      "File \u001b[0;32m/usr/lib/python3.10/typing.py:1427\u001b[0m, in \u001b[0;36m_is_callable_members_only\u001b[0;34m(cls)\u001b[0m\n\u001b[1;32m   1425\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_is_callable_members_only\u001b[39m(\u001b[39mcls\u001b[39m):\n\u001b[1;32m   1426\u001b[0m     \u001b[39m# PEP 544 prohibits using issubclass() with protocols that have non-method members.\u001b[39;00m\n\u001b[0;32m-> 1427\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mall\u001b[39m(callable(\u001b[39mgetattr\u001b[39m(\u001b[39mcls\u001b[39m, attr, \u001b[39mNone\u001b[39;00m)) \u001b[39mfor\u001b[39;00m attr \u001b[39min\u001b[39;00m _get_protocol_attrs(\u001b[39mcls\u001b[39;49m))\n",
      "File \u001b[0;32m/usr/lib/python3.10/typing.py:1408\u001b[0m, in \u001b[0;36m_get_protocol_attrs\u001b[0;34m(cls)\u001b[0m\n\u001b[1;32m   1404\u001b[0m \u001b[39m# These special attributes will be not collected as protocol members.\u001b[39;00m\n\u001b[1;32m   1405\u001b[0m EXCLUDED_ATTRIBUTES \u001b[39m=\u001b[39m _TYPING_INTERNALS \u001b[39m+\u001b[39m _SPECIAL_NAMES \u001b[39m+\u001b[39m [\u001b[39m'\u001b[39m\u001b[39m_MutableMapping__marker\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m-> 1408\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get_protocol_attrs\u001b[39m(\u001b[39mcls\u001b[39m):\n\u001b[1;32m   1409\u001b[0m     \u001b[39m\"\"\"Collect protocol members from a protocol class objects.\u001b[39;00m\n\u001b[1;32m   1410\u001b[0m \n\u001b[1;32m   1411\u001b[0m \u001b[39m    This includes names actually defined in the class dictionary, as well\u001b[39;00m\n\u001b[1;32m   1412\u001b[0m \u001b[39m    as names that appear in annotations. Special names (above) are skipped.\u001b[39;00m\n\u001b[1;32m   1413\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m   1414\u001b[0m     attrs \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optimization = HPO.Optimization(dataset, model, hyperparameterspace, type=\"random_search\", cv=CV, scoring=SCORING, budget=BUDGET, verbosity=VERBOSE)\n",
    "result = optimization.fit()\n",
    "print(\"Best result:\")\n",
    "print(result.best_score_)\n",
    "print(\"Corresponding parameters:\")\n",
    "print(result.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian Optimization \n",
    "\n",
    "https://thuijskens.github.io/2016/12/29/bayesian-optimisation/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [####----------------] 20.0%\n",
      "Current time per iteration: 17.58371454999724\n",
      "Approx. time remaining: 70.33485819998896\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m optimization \u001b[39m=\u001b[39m HPO\u001b[39m.\u001b[39mOptimization(dataset, blackboxfunction, hyperparameterspace, \u001b[39mtype\u001b[39m\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbayesian\u001b[39m\u001b[39m\"\u001b[39m, budget\u001b[39m=\u001b[39mBUDGET, verbosity\u001b[39m=\u001b[39mVERBOSE)\n\u001b[0;32m----> 2\u001b[0m result \u001b[39m=\u001b[39m optimization\u001b[39m.\u001b[39;49mfit()\n\u001b[1;32m      4\u001b[0m \u001b[39m# fig = plt.figure()\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[39m# ax = plt.axes(projection='3d')\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      9\u001b[0m \n\u001b[1;32m     10\u001b[0m \u001b[39m# ax.scatter3D(x, y, result[1], c=result[1], cmap='Greens')\u001b[39;00m\n\u001b[1;32m     12\u001b[0m index_best \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "File \u001b[0;32m~/Repos/Masterarbeit/Code/HPO.py:352\u001b[0m, in \u001b[0;36mOptimization.fit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    349\u001b[0m     \u001b[39mreturn\u001b[39;00m clf\u001b[39m.\u001b[39mfit(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39mget_X(), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39mget_Y())\n\u001b[1;32m    351\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtype \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbayesian\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m--> 352\u001b[0m     \u001b[39mreturn\u001b[39;00m bayesian_optimisation(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset\u001b[39m.\u001b[39;49mget_X(), \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset\u001b[39m.\u001b[39;49mget_Y(), \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbudget, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhyperparameterspace_processed)\n\u001b[1;32m    354\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtype \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39msparse\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    356\u001b[0m     f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\n",
      "File \u001b[0;32m~/Repos/Masterarbeit/Code/HPO.py:241\u001b[0m, in \u001b[0;36mbayesian_optimisation\u001b[0;34m(X, Y, n_iters, sample_loss, bounds, x0, n_pre_samples, gp_params, random_search, alpha, epsilon)\u001b[0m\n\u001b[1;32m    237\u001b[0m     next_sample \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39muniform(\n\u001b[1;32m    238\u001b[0m         bounds[:, \u001b[39m0\u001b[39m], bounds[:, \u001b[39m1\u001b[39m], bounds\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m])\n\u001b[1;32m    240\u001b[0m \u001b[39m# Sample loss for new set of parameters\u001b[39;00m\n\u001b[0;32m--> 241\u001b[0m cv_score \u001b[39m=\u001b[39m sample_loss(next_sample)\n\u001b[1;32m    243\u001b[0m \u001b[39m# Update lists\u001b[39;00m\n\u001b[1;32m    244\u001b[0m x_list\u001b[39m.\u001b[39mappend(next_sample)\n",
      "Cell \u001b[0;32mIn[2], line 109\u001b[0m, in \u001b[0;36mblackboxfunction\u001b[0;34m(params)\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[39mreturn\u001b[39;00m model\n\u001b[1;32m    106\u001b[0m model \u001b[39m=\u001b[39m KerasClassifier(model\u001b[39m=\u001b[39mcreate_model, verbose\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[0;32m--> 109\u001b[0m model\u001b[39m.\u001b[39;49mfit(dataset\u001b[39m.\u001b[39;49mget_X_train(), dataset\u001b[39m.\u001b[39;49mget_Y_train(), epochs\u001b[39m=\u001b[39;49mepochs)\n\u001b[1;32m    111\u001b[0m Y_predicted \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(dataset\u001b[39m.\u001b[39mget_X_test())\n\u001b[1;32m    113\u001b[0m \u001b[39mreturn\u001b[39;00m sklearn\u001b[39m.\u001b[39mmetrics\u001b[39m.\u001b[39maccuracy_score(dataset\u001b[39m.\u001b[39mget_Y_test(), Y_predicted)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/scikeras/wrappers.py:1494\u001b[0m, in \u001b[0;36mKerasClassifier.fit\u001b[0;34m(self, X, y, sample_weight, **kwargs)\u001b[0m\n\u001b[1;32m   1492\u001b[0m     sample_weight \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m \u001b[39mif\u001b[39;00m sample_weight \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m sample_weight\n\u001b[1;32m   1493\u001b[0m     sample_weight \u001b[39m*\u001b[39m\u001b[39m=\u001b[39m compute_sample_weight(class_weight\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclass_weight, y\u001b[39m=\u001b[39my)\n\u001b[0;32m-> 1494\u001b[0m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mfit(X\u001b[39m=\u001b[39;49mX, y\u001b[39m=\u001b[39;49my, sample_weight\u001b[39m=\u001b[39;49msample_weight, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1495\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/scikeras/wrappers.py:762\u001b[0m, in \u001b[0;36mBaseWrapper.fit\u001b[0;34m(self, X, y, sample_weight, **kwargs)\u001b[0m\n\u001b[1;32m    757\u001b[0m kwargs[\u001b[39m\"\u001b[39m\u001b[39mepochs\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mget(\n\u001b[1;32m    758\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mepochs\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mfit__epochs\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mepochs)\n\u001b[1;32m    759\u001b[0m )\n\u001b[1;32m    760\u001b[0m kwargs[\u001b[39m\"\u001b[39m\u001b[39minitial_epoch\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39minitial_epoch\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m0\u001b[39m)\n\u001b[0;32m--> 762\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit(\n\u001b[1;32m    763\u001b[0m     X\u001b[39m=\u001b[39;49mX,\n\u001b[1;32m    764\u001b[0m     y\u001b[39m=\u001b[39;49my,\n\u001b[1;32m    765\u001b[0m     sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[1;32m    766\u001b[0m     warm_start\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mwarm_start,\n\u001b[1;32m    767\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    768\u001b[0m )\n\u001b[1;32m    770\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/scikeras/wrappers.py:931\u001b[0m, in \u001b[0;36mBaseWrapper._fit\u001b[0;34m(self, X, y, sample_weight, warm_start, epochs, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m    927\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeature_encoder_\u001b[39m.\u001b[39mtransform(X)\n\u001b[1;32m    929\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_model_compatibility(y)\n\u001b[0;32m--> 931\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_keras_model(\n\u001b[1;32m    932\u001b[0m     X,\n\u001b[1;32m    933\u001b[0m     y,\n\u001b[1;32m    934\u001b[0m     sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[1;32m    935\u001b[0m     warm_start\u001b[39m=\u001b[39;49mwarm_start,\n\u001b[1;32m    936\u001b[0m     epochs\u001b[39m=\u001b[39;49mepochs,\n\u001b[1;32m    937\u001b[0m     initial_epoch\u001b[39m=\u001b[39;49minitial_epoch,\n\u001b[1;32m    938\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    939\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/scikeras/wrappers.py:526\u001b[0m, in \u001b[0;36mBaseWrapper._fit_keras_model\u001b[0;34m(self, X, y, sample_weight, warm_start, epochs, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m    524\u001b[0m         hist \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_\u001b[39m.\u001b[39mfit(x\u001b[39m=\u001b[39mX, y\u001b[39m=\u001b[39my, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_args)\n\u001b[1;32m    525\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 526\u001b[0m     hist \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel_\u001b[39m.\u001b[39;49mfit(x\u001b[39m=\u001b[39;49mX, y\u001b[39m=\u001b[39;49my, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_args)\n\u001b[1;32m    528\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m warm_start \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mhistory_\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mor\u001b[39;00m initial_epoch \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    529\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhistory_ \u001b[39m=\u001b[39m defaultdict(\u001b[39mlist\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/engine/training.py:1650\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1642\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1643\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1644\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1647\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m   1648\u001b[0m ):\n\u001b[1;32m   1649\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1650\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   1651\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1652\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:880\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    877\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    879\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 880\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    882\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    883\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:912\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    909\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    910\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    911\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 912\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_no_variable_creation_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    913\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    914\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    915\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    916\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:134\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    132\u001b[0m   (concrete_function,\n\u001b[1;32m    133\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 134\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m    135\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mconcrete_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1741\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1732\u001b[0m       \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1733\u001b[0m           \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mTensor \u001b[39m\u001b[39m{\u001b[39;00mtensor_input\u001b[39m}\u001b[39;00m\u001b[39m is not compatible with the shape this \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1734\u001b[0m           \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mfunction was traced with. Expected shape \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1737\u001b[0m           \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39myou may need to pass a tf.TensorSpec(..., shape=...) with a \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1738\u001b[0m           \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mless specific shape, having None on axes which can vary.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   1740\u001b[0m args \u001b[39m=\u001b[39m tensor_inputs \u001b[39m+\u001b[39m captured_inputs\n\u001b[0;32m-> 1741\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39;49mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1742\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1743\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1744\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m   1745\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_inference_function\u001b[39m.\u001b[39mcall(\n\u001b[1;32m   1746\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39mcancellation_manager))\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/ops/gradients_util.py:1034\u001b[0m, in \u001b[0;36mPossibleTapeGradientTypes\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m   1032\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mPossibleTapeGradientTypes\u001b[39m(tensors):\n\u001b[1;32m   1033\u001b[0m   \u001b[39m\"\"\"Determines whether and how `args` may require tape gradients.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1034\u001b[0m   \u001b[39mreturn\u001b[39;00m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_TapeSetPossibleGradientTypes(tensors)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optimization = HPO.Optimization(dataset, blackboxfunction, hyperparameterspace, type=\"bayesian\", budget=BUDGET, verbosity=VERBOSE)\n",
    "result = optimization.fit()\n",
    "\n",
    "# fig = plt.figure()\n",
    "# ax = plt.axes(projection='3d')\n",
    "\n",
    "# x = [result[0][i][0] for i in range(len(result[0]))]\n",
    "# y = [result[0][i][1] for i in range(len(result[0]))]\n",
    "\n",
    "# ax.scatter3D(x, y, result[1], c=result[1], cmap='Greens')\n",
    "\n",
    "index_best = 0\n",
    "for i in range(len(result[1])):\n",
    "    if result[1][i] == max(result[1]):\n",
    "        index_best = i\n",
    "\n",
    "best_score = result[1][index_best]\n",
    "best_params = result[0][index_best]\n",
    "\n",
    "\n",
    "print(\"Best MSE:\")\n",
    "print(best_score)\n",
    "print(\"With Hyperparameters: \")\n",
    "i = 0\n",
    "for key in hyperparameterspace.keys():\n",
    "    if hyperparameterspace[key][0] == \"list\":\n",
    "        index = int(best_params[i]*(len(hyperparameterspace_special[key])-1))\n",
    "        print(key + \": \" + str(hyperparameterspace_special[key][index]))\n",
    "    else:\n",
    "        print(key + \": \" + str(best_params[i]))\n",
    "    i += 1\n",
    "\n",
    "\n",
    "print([result[0][i] for i in range(len(result[0])) if result[1][i] == max(result[1])])\n",
    "#print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sparse grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adaptive grid generation (Ritter-Novak)...\n"
     ]
    }
   ],
   "source": [
    "f = ExampleFunction()\n",
    "\n",
    "optimization = HPO.Optimization(dataset, f, hyperparameterspace, type=\"sparse\", budget=BUDGET, verbosity=VERBOSE)\n",
    "result = optimization.fit()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
