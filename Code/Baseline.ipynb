{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline experiment\n",
    "\n",
    "Experiment to compare the 4 Optimization algorithms before trying to improve sparse search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import HPO\n",
    "\n",
    "import pysgpp\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import sklearn.metrics\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras import backend as K\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from scikeras.wrappers import KerasRegressor\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.compose import TransformedTargetRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.feature_selection import SelectPercentile, chi2\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "\n",
    "VERBOSE = 1\n",
    "CV = 3 #[(slice(None), slice(None))]\n",
    "TESTING = True\n",
    "\n",
    "DATASETS = []\n",
    "\n",
    "GRID_RESULT = []\n",
    "RANDOM_RESULT = []\n",
    "BAYESIAN_RESULT = []\n",
    "SPARSE_RESULT = []\n",
    "SPARSE_RESULT_OPTIMIZED = []\n",
    "\n",
    "GRID_COST = []\n",
    "RANDOM_COST = []\n",
    "BAYESIAN_COST = []\n",
    "SPARSE_COST = []\n",
    "SPARSE_COST_OPTIMIZED = []"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter space definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ITER = 2\n",
    "\n",
    "hyperparameterspace = {\n",
    "    'regressor__regressor__epochs': [\"interval-int\", 15, 20],\n",
    "    'regressor__regressor__batch_size': [\"interval-int\", 1, 200],\n",
    "    'regressor__regressor__model__optimizer__learning_rate': [\"interval-log\", 0.000001, 0.1]\n",
    "}\n",
    "\n",
    "hyperparameterspace_special = {}\n",
    "for key in hyperparameterspace.keys():\n",
    "    liste = []\n",
    "    for i in range(1, len(hyperparameterspace[key])):\n",
    "        liste.append(hyperparameterspace[key][i])\n",
    "    hyperparameterspace_special[key] = liste\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu_advanced(x):\n",
    "    return K.relu(x)\n",
    "\n",
    "ACTIVATION_FUNCTION = relu_advanced\n",
    "\n",
    "INITIALIZER = tf.keras.initializers.RandomNormal(stddev=0.05, seed=42)\n",
    "# \n",
    "def create_model(learning_rate=0.0001, input_dim=10):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(30, input_shape=(input_dim,), activation=ACTIVATION_FUNCTION,\n",
    "                kernel_initializer=INITIALIZER, bias_initializer=INITIALIZER))\n",
    "    model.add(Dense(30, activation=ACTIVATION_FUNCTION,\n",
    "                kernel_initializer=INITIALIZER, bias_initializer=INITIALIZER))\n",
    "    model.add(Dense(1, activation=None))\n",
    "\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "    model.compile(loss='mean_absolute_error', optimizer=optimizer)\n",
    "    return model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = [233211]#, 359952, 359931, 359949, 359938]\n",
    "# [359940, 317614, 359934, 359946, 359932, 233214, 359943]\n",
    "\n",
    "valid_datasets = 0\n",
    "for i in range(len(ids)):\n",
    "    print(\"######################################################################################################################################################\")\n",
    "    print(\"Current Dataset:\", (i+1), \"of\", len(ids), \"with id:\", ids[i])\n",
    "\n",
    "    dataset = HPO.Dataset(task_id=ids[i])\n",
    "\n",
    "    print(\"The average value for target is:\", sum(\n",
    "        dataset.get_Y()/len(dataset.get_Y())))\n",
    "    print(\"Min target:\", min(dataset.get_Y()),\n",
    "          \"Max target:\", max(dataset.get_Y()))\n",
    "\n",
    "    ################## MODEL AND FUNCTION DEFINITION ####################\n",
    "\n",
    "    def evaluate_model(loss, epochs, batch_size, model_learning_rate, neurons_per_layer, number_of_layers):\n",
    "\n",
    "        kfold = KFold(n_splits=CV)\n",
    "\n",
    "        split = (kfold.split(dataset.get_X(), dataset.get_Y()))\n",
    "\n",
    "        values = []\n",
    "\n",
    "        numeric_features = [not x for x in dataset.get_categorical_indicator()]\n",
    "        numeric_transformer = Pipeline(\n",
    "            steps=[(\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "                   (\"scaler\", StandardScaler())]\n",
    "        )\n",
    "\n",
    "        categorical_transformer = Pipeline(\n",
    "            steps=[\n",
    "                (\"encoder\", OneHotEncoder(handle_unknown=\"infrequent_if_exist\", sparse_output=False)),\n",
    "                # (\"selector\", SelectPercentile(chi2, percentile=50)),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        number_numeric_features = 0\n",
    "        for x in numeric_features:\n",
    "            if x:\n",
    "                number_numeric_features += 1\n",
    "\n",
    "        preprocessor = ColumnTransformer(\n",
    "            transformers=[\n",
    "                (\"num\", numeric_transformer, numeric_features),\n",
    "                (\"cat\", categorical_transformer,\n",
    "                 dataset.get_categorical_indicator()),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        #preprocessor.fit(dataset.get_X())\n",
    "        # (number_numeric_features+len(categorical_transformer[\"encoder\"].categories_))\n",
    "\n",
    "        # final regressor\n",
    "        \n",
    "\n",
    "        # pipeline = Pipeline([\n",
    "        #     ('preprocessor', preprocessor),\n",
    "        #     ('regressor', regressor)\n",
    "        # ])\n",
    "\n",
    "        for i, (train_index, test_index) in enumerate(split):\n",
    "            X_train = dataset.get_X()[train_index]\n",
    "            Y_train = dataset.get_Y()[train_index]\n",
    "\n",
    "            X_val = dataset.get_X()[test_index]\n",
    "            Y_val = dataset.get_Y()[test_index]\n",
    "\n",
    "            preprocessor.fit(X_train)\n",
    "\n",
    "            X_train = preprocessor.transform(X_train)\n",
    "            X_val = preprocessor.transform(X_val)\n",
    "\n",
    "            regressor = TransformedTargetRegressor(regressor=KerasRegressor(model=create_model, input_dim=len(X_train[0]), verbose=0),\n",
    "                                               transformer=StandardScaler())\n",
    "            \n",
    "            regressor.fit(X_train, Y_train, epochs=epochs,\n",
    "                         batch_size=batch_size)\n",
    "\n",
    "            Y_predicted = regressor.predict(X_val)\n",
    "            error = sklearn.metrics.mean_absolute_error(Y_predicted, Y_val)\n",
    "            values.append(error)\n",
    "\n",
    "            K.clear_session()\n",
    "\n",
    "        result = sum(values)/len(values)\n",
    "        return result\n",
    "\n",
    "    def blackboxfunction(params):\n",
    "        # index = int(params[0]*(len(hyperparameterspace_special[\"loss\"])-1))\n",
    "        # hyperparameterspace_special[\"loss\"][index]\n",
    "        loss = 'mean_squared_error'\n",
    "\n",
    "        epochs = int(params[0])\n",
    "\n",
    "        batch_size = int(params[1])\n",
    "\n",
    "        model_learning_rate = params[2]\n",
    "\n",
    "        neurons_per_layer = 40  # int(params[3])\n",
    "\n",
    "        number_of_layers = 1  # int(params[4])\n",
    "\n",
    "        return evaluate_model(loss, epochs, batch_size, model_learning_rate, neurons_per_layer, number_of_layers)\n",
    "\n",
    "    ##################### Function for sparse grid search #####################\n",
    "\n",
    "    class ExampleFunction(pysgpp.ScalarFunction):\n",
    "\n",
    "        def __init__(self):\n",
    "            super(ExampleFunction, self).__init__(\n",
    "                len(hyperparameterspace.keys()))\n",
    "\n",
    "        def eval(self, x):\n",
    "            # index = int(x[0]*(len(hyperparameterspace_special[\"loss\"])-1))\n",
    "            # hyperparameterspace_special[\"loss\"][index]\n",
    "            loss = 'mean_squared_error'\n",
    "\n",
    "            epochs = int(HPO.from_standard(\n",
    "                hyperparameterspace_special[\"regressor__regressor__epochs\"][0], hyperparameterspace_special[\"regressor__regressor__epochs\"][1], x[0]))\n",
    "\n",
    "            batch_size = int(HPO.from_standard(\n",
    "                hyperparameterspace_special[\"regressor__regressor__batch_size\"][0], hyperparameterspace_special[\"regressor__regressor__batch_size\"][1], x[1]))\n",
    "\n",
    "            model_learning_rate = HPO.from_standard_log(hyperparameterspace_special[\"regressor__regressor__model__optimizer__learning_rate\"][\n",
    "                                                        0], hyperparameterspace_special[\"regressor__regressor__model__optimizer__learning_rate\"][1], x[2])\n",
    "\n",
    "            # int(HPO.from_standard(hyperparameterspace_special[\"model__neurons_per_layer\"][0], hyperparameterspace_special[\"model__neurons_per_layer\"][1], x[3]))\n",
    "            neurons_per_layer = 40\n",
    "\n",
    "            # int(HPO.from_standard(hyperparameterspace_special[\"model__number_of_layers\"][0], hyperparameterspace_special[\"model__number_of_layers\"][1], x[4]))\n",
    "            number_of_layers = 1\n",
    "\n",
    "            return evaluate_model(loss, epochs, batch_size, model_learning_rate, neurons_per_layer, number_of_layers)\n",
    "\n",
    "    ##### For each dataset: run models with different budget #####\n",
    "\n",
    "    for j in range(ITER):\n",
    "        BUDGET = (j+1) * 3\n",
    "        print(\"\\n################################################## Current Budget:\",\n",
    "              BUDGET, \"##################################################\")\n",
    "\n",
    "        ############################## GRID SEARCH #######################\n",
    "        # print(\"Performing grid search\")\n",
    "\n",
    "        # optimization = HPO.GridSearchOptimization(\n",
    "        #     dataset, create_model, hyperparameterspace, budget=BUDGET, verbosity=VERBOSE, cv=CV)\n",
    "\n",
    "        # result, cost = optimization.fit()\n",
    "\n",
    "        # if VERBOSE > 0:\n",
    "        #     print(\"Best params found by grid search:\")\n",
    "        #     print(result.best_params_)\n",
    "\n",
    "        # GRID_RESULT.append(-result.best_score_)\n",
    "        # GRID_COST.append(cost)\n",
    "\n",
    "        # K.clear_session()\n",
    "\n",
    "        # ########################### RANDOM SEARCH #######################\n",
    "        # print(\"Performing random search\")\n",
    "\n",
    "        # optimization = HPO.RandomSearchOptimization(\n",
    "        #     dataset, create_model, hyperparameterspace, budget=BUDGET, verbosity=VERBOSE, cv=CV)\n",
    "\n",
    "        # result, cost = optimization.fit()\n",
    "\n",
    "        # if VERBOSE > 0:\n",
    "        #     print(\"Best params found by random search:\")\n",
    "        #     print(result.best_params_)\n",
    "\n",
    "        # RANDOM_RESULT.append(-result.best_score_)\n",
    "        # RANDOM_COST.append(cost)\n",
    "\n",
    "        # K.clear_session()\n",
    "\n",
    "        ########################### BAYESIAN OPT #####################\n",
    "        print(\"Performing bayesian optimization\")\n",
    "\n",
    "        optimization = HPO.BayesianOptimization(\n",
    "            dataset, blackboxfunction, hyperparameterspace, budget=BUDGET, verbosity=VERBOSE)\n",
    "\n",
    "        result = optimization.fit()\n",
    "\n",
    "        index_best = 0\n",
    "        for m in range(len(result[1])):\n",
    "            if result[1][m] == max(result[1]):\n",
    "                index_best = m\n",
    "\n",
    "        best_score = result[1][index_best]\n",
    "        best_params = result[0][index_best]\n",
    "\n",
    "        if VERBOSE > 0:\n",
    "            print(\"With Hyperparameters: \")\n",
    "            i = 0\n",
    "            for key in hyperparameterspace.keys():\n",
    "                if hyperparameterspace[key][0] == \"list\":\n",
    "                    index = int(\n",
    "                        best_params[i]*(len(hyperparameterspace_special[key])-1))\n",
    "                    print(key + \": \" +\n",
    "                          str(hyperparameterspace_special[key][index]))\n",
    "                else:\n",
    "                    print(key + \": \" + str(best_params[i]))\n",
    "                i += 1\n",
    "\n",
    "        BAYESIAN_RESULT.append(best_score)\n",
    "        BAYESIAN_COST.append(BUDGET)\n",
    "\n",
    "        K.clear_session()\n",
    "\n",
    "        ########################### SPARSE OPT ############################\n",
    "        print(\"Performing sparse search\")\n",
    "\n",
    "        f = ExampleFunction()\n",
    "\n",
    "        optimization = HPO.SparseGridSearchOptimization(\n",
    "            dataset, f, hyperparameterspace, budget=BUDGET, verbosity=VERBOSE, degree=2, adaptivity=0.2, optimizer=\"rprop\")\n",
    "\n",
    "        result = optimization.fit()\n",
    "\n",
    "        SPARSE_RESULT.append(result[0][1])\n",
    "        SPARSE_RESULT_OPTIMIZED.append(result[0][3])\n",
    "\n",
    "        SPARSE_COST.append(result[1])\n",
    "        SPARSE_COST_OPTIMIZED.append(result[1])\n",
    "\n",
    "        K.clear_session()\n",
    "\n",
    "        print(GRID_RESULT)\n",
    "        print(RANDOM_RESULT)\n",
    "        print(BAYESIAN_RESULT)\n",
    "        print(SPARSE_RESULT)\n",
    "        print(SPARSE_RESULT_OPTIMIZED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(GRID_RESULT)\n",
    "print(RANDOM_RESULT)\n",
    "print(BAYESIAN_RESULT)\n",
    "print(SPARSE_RESULT)\n",
    "print(SPARSE_RESULT_OPTIMIZED)\n",
    "count = 0\n",
    "for i in range(len(ids)):\n",
    "    print(\"Current dataset:\", i, \"with name id:\", ids[i])\n",
    "    for j in range(ITER):\n",
    "        plt.plot(GRID_COST[count], GRID_RESULT[count], '+', color='black')\n",
    "        plt.plot(RANDOM_COST[count], RANDOM_RESULT[count], 'x', color='red')\n",
    "        plt.plot(BAYESIAN_COST[count], BAYESIAN_RESULT[count], '.', color='blue')\n",
    "        plt.plot(SPARSE_COST[count], SPARSE_RESULT[count], '+', color='purple')\n",
    "        plt.plot(SPARSE_COST_OPTIMIZED[count], SPARSE_RESULT_OPTIMIZED[count], 'x', color='pink')\n",
    "        plt.xlabel(\"Cost\")\n",
    "        plt.ylabel(\"Result (mean squared error)\")\n",
    "        plt.yscale(\"log\")\n",
    "        plt.legend([\"Grid search\", \"Random search\", \"Bayesian Opt\", \"Sparse search\", \"Sparse search (opt)\"], bbox_to_anchor=(1.04, 1), loc=\"upper left\")\n",
    "        count += 1\n",
    "    plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
