{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline experiment\n",
    "\n",
    "Experiment to compare the 4 Optimization algorithms before trying to improve sparse search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys  \n",
    "sys.path.insert(0, '../')\n",
    "\n",
    "import HPO\n",
    "import pysgpp\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import tensorflow as tf\n",
    "import sklearn.metrics\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from scikeras.wrappers import KerasRegressor\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.compose import TransformedTargetRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.feature_selection import SelectPercentile, chi2\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from numpy.random import seed\n",
    "import random\n",
    "import time\n",
    "import os\n",
    "import math\n",
    "from matplotlib import cm\n",
    "import matplotlib \n",
    "import matplotlib.patches as patches\n",
    "\n",
    "import operator\n",
    "\n",
    "from scipy.stats import norm\n",
    "\n",
    "# matplotlib.use(\"pgf\")\n",
    "# matplotlib.rcParams.update({\n",
    "#     \"pgf.texsystem\": \"pdflatex\",\n",
    "#     'font.family': 'serif',\n",
    "#     'text.usetex': True,\n",
    "#     'pgf.rcfonts': False,\n",
    "# })\n",
    "\n",
    "random.seed(1)\n",
    "seed(2)\n",
    "tf.random.set_seed(3)\n",
    "\n",
    "def reset_seeds():\n",
    "    np.random.seed(1)\n",
    "    random.seed(2)\n",
    "    tf.random.set_seed(3)\n",
    "\n",
    "VERBOSE = 0\n",
    "\n",
    "SPARSE_RESULT = []\n",
    "SPARSE_RESULT_OPTIMIZED = []\n",
    "\n",
    "SPARSE_COST = []\n",
    "SPARSE_COST_OPTIMIZED = []"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter space definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameterspace = {\n",
    "    'x0': [\"interval\", -2, 8],\n",
    "    'x1': [\"interval\", -2, 8],\n",
    "    'x2': [\"interval\", -2, 8],\n",
    "    'x3': [\"interval\", -2, 8],\n",
    "    # 'x4': [\"interval\", -2, 8],\n",
    "    # 'x5': [\"interval\", -2, 8],\n",
    "}\n",
    "\n",
    "hyperparameterspace_special = {}\n",
    "for key in hyperparameterspace.keys():\n",
    "    liste = []\n",
    "    for i in range(1, len(hyperparameterspace[key])):\n",
    "        liste.append(hyperparameterspace[key][i])\n",
    "    hyperparameterspace_special[key] = liste\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "BUDGETS = [1 + i * 52 for i in range(19)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REF_PER_STEP: 1\n",
      "REF_PER_STEP: 2\n",
      "REF_PER_STEP: 3\n",
      "REF_PER_STEP: 4\n",
      "REF_PER_STEP: 5\n",
      "REF_PER_STEP: 6\n",
      "REF_PER_STEP: 7\n",
      "REF_PER_STEP: 8\n",
      "REF_PER_STEP: 9\n",
      "REF_PER_STEP: 10\n",
      "REF_PER_STEP: 11\n",
      "REF_PER_STEP: 12\n",
      "REF_PER_STEP: 13\n",
      "REF_PER_STEP: 14\n",
      "REF_PER_STEP: 15\n",
      "REF_PER_STEP: 16\n",
      "REF_PER_STEP: 17\n",
      "REF_PER_STEP: 18\n",
      "REF_PER_STEP: 19\n",
      "REF_PER_STEP: 20\n",
      "REF_PER_STEP: 21\n",
      "REF_PER_STEP: 22\n",
      "REF_PER_STEP: 23\n",
      "REF_PER_STEP: 24\n",
      "REF_PER_STEP: 25\n",
      "REF_PER_STEP: 26\n",
      "REF_PER_STEP: 27\n",
      "REF_PER_STEP: 28\n",
      "REF_PER_STEP: 29\n",
      "REF_PER_STEP: 30\n",
      "REF_PER_STEP: 31\n",
      "REF_PER_STEP: 32\n",
      "REF_PER_STEP: 33\n",
      "REF_PER_STEP: 34\n",
      "REF_PER_STEP: 35\n",
      "REF_PER_STEP: 36\n",
      "REF_PER_STEP: 37\n",
      "REF_PER_STEP: 38\n",
      "REF_PER_STEP: 39\n",
      "REF_PER_STEP: 40\n",
      "REF_PER_STEP: 41\n",
      "REF_PER_STEP: 42\n",
      "REF_PER_STEP: 43\n",
      "REF_PER_STEP: 44\n",
      "REF_PER_STEP: 45\n",
      "REF_PER_STEP: 46\n",
      "REF_PER_STEP: 47\n",
      "REF_PER_STEP: 48\n",
      "REF_PER_STEP: 49\n",
      "REF_PER_STEP: 50\n",
      "{(1,21.571450925827087)(2,27.920985744612324)(3,22.817786017257824)(4,22.35293514442489)(5,28.661029883609707)(6,22.759198399134995)(7,24.29179277188364)(8,24.680280809661944)(9,25.18768605020383)(10,21.105053547590707)(11,24.11667334367236)(12,23.49361193651392)(13,21.787647106472527)(14,21.798211231102012)(15,24.84601159359948)(16,23.780270801805464)(17,22.62560394058462)(18,21.468508620323423)(19,16.304286766760434)(20,28.102135000988376)(21,19.10348671712194)(22,20.315986522319232)(23,24.31993047159746)(24,19.498992076741313)(25,20.576132823276613)(26,21.212287960932105)(27,18.289366923243087)(28,22.865610933033416)(29,19.873478964007138)(30,16.3210794406717)(31,21.53201789485596)(32,21.636680302178963)(33,19.530470654609733)(34,18.405080643057666)(35,20.394881902261908)(36,18.96647355055265)(37,22.179759514439716)(38,20.980777919385286)(39,19.229622434366327)(40,17.63697243517336)(41,21.619072476537703)(42,19.65008932496867)(43,22.82634152931717)(44,20.62913984173121)(45,18.318526976141065)(46,20.49146076991186)(47,18.86015380464162)(48,22.12802478790763)(49,24.104174273944967)(50,17.86989806728193)}\n",
      "\n",
      "{(1,9.232409027301737)(2,13.735954156544304)(3,10.934313341357385)(4,12.616105224302142)(5,10.201321804777155)(6,10.711329526176161)(7,9.73222094351259)(8,13.227793485437022)(9,11.514580716244746)(10,12.106161026119873)(11,8.115121555219547)(12,13.150241926967045)(13,11.073843230530839)(14,10.655574342297587)(15,9.554689130871244)(16,12.200138275799116)(17,9.397100405687596)(18,9.665133829202158)(19,12.094647217026047)(20,11.81411777220905)(21,9.313802742558725)(22,13.667155148958992)(23,11.182052270816108)(24,9.293952560370489)(25,8.75904649277789)(26,10.87353679318036)(27,8.662659583008173)(28,11.03661260272074)(29,9.534745515969902)(30,11.440287481006013)(31,11.962128708714923)(32,11.618739693890515)(33,9.149890532763013)(34,9.33835671177356)(35,10.212142338611212)(36,12.69541276598593)(37,12.06404533416111)(38,12.305059788528444)(39,10.523726360130036)(40,10.80397418843489)(41,10.148129318757366)(42,14.022519856117516)(43,10.053373687164953)(44,8.46122235576871)(45,8.928111267317984)(46,9.461743926922331)(47,11.683277032362685)(48,9.953365584448662)(49,10.926396547581751)(50,7.958965198371433)}\n",
      "\n",
      "{(1,10.149214314572884)(2,9.163146934343093)(3,9.886637545145767)(4,10.109245408097731)(5,10.286882391759157)(6,10.184503907574499)(7,10.734293606120293)(8,8.66107592378394)(9,11.287459738044646)(10,9.102771685728817)(11,9.635923106295216)(12,8.262586167462338)(13,8.004767399629497)(14,9.64001702157945)(15,9.219131452878539)(16,8.584087228603824)(17,8.444021690380072)(18,8.491525785061807)(19,8.62119916818063)(20,8.9505871029475)(21,8.890429746092101)(22,10.163068910680831)(23,9.522052079202789)(24,8.673604097066095)(25,7.7085242327590375)(26,9.036297594795062)(27,9.170165272649285)(28,8.464871029218475)(29,8.706524613026392)(30,9.126652469933301)(31,9.579980245636563)(32,9.207242587693267)(33,9.642649117518852)(34,9.457020781843372)(35,8.472055244581469)(36,8.292255917103095)(37,9.195869765927572)(38,10.639120743280717)(39,8.944224381861726)(40,8.860796338248491)(41,8.9780566079851)(42,8.503664004091878)(43,9.633204387241893)(44,9.151046998009932)(45,9.25524151533916)(46,7.566636501981327)(47,11.448096827739795)(48,9.633550772707439)(49,8.401742914495973)(50,9.626282519383338)}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "################## MODEL AND FUNCTION DEFINITION ####################\n",
    "\n",
    "def evaluate_model(epochs, batch_size, x2, x3):#, x4, x5):\n",
    "    #return epochs * batch_size\n",
    "    ################### ROSENBROCK ###############\n",
    "    # sum = 0\n",
    "    # sum += (1-epochs)**2 + 100 * (batch_size - epochs**2) ** 2\n",
    "    # return sum\n",
    "\n",
    "    # ################# RASTRIGIN #################\n",
    "    sum = 0\n",
    "    sum += epochs ** 2 - 10 * math.cos(2 * math.pi * epochs)\n",
    "    sum += batch_size ** 2 - 10 * math.cos(2 * math.pi * batch_size)\n",
    "    sum += x2 ** 2 - 10 * math.cos(2 * math.pi * x2)\n",
    "    sum += x3 ** 2 - 10 * math.cos(2 * math.pi * x3)\n",
    "    # sum += x4 ** 2 - 10 * math.cos(2 * math.pi * x4)\n",
    "    # sum += x5 ** 2 - 10 * math.cos(2 * math.pi * x5)\n",
    "    return len(hyperparameterspace) * 10 + sum\n",
    "\n",
    "\n",
    "    ################# EGGHOLDER #################\n",
    "    return -epochs * math.sin(math.sqrt(abs(epochs - (batch_size + 47)))) - (batch_size + 47) * math.sin(math.sqrt(abs((batch_size + 47 + 0.5 * epochs))))\n",
    "\n",
    "\n",
    "def function(coordinates):\n",
    "    return evaluate_model(coordinates[0], coordinates[1], coordinates[2], coordinates[3])#, coordinates[4], coordinates[5])\n",
    "\n",
    "\n",
    "BUDGET = 400\n",
    "\n",
    "N_ITERS = 10\n",
    "\n",
    "ALT_1 = \"{\"\n",
    "ALT_2 = \"{\"\n",
    "ALT_3 = \"{\"\n",
    "\n",
    "REF_PER_STEP = 1\n",
    "\n",
    "for i in range(50):\n",
    "    REF_PER_STEP = i + 1\n",
    "\n",
    "    print(\"REF_PER_STEP:\", REF_PER_STEP)\n",
    "\n",
    "    #reset_seeds()\n",
    "    summe = 0\n",
    "    for i in range(N_ITERS):\n",
    "\n",
    "        optimizer = HPO.IterativeRandomOptimization(HPO.Dataset([],[]), function, \n",
    "                                                    hyperparameterspace, BUDGET, 0, 0.85, \n",
    "                                                    init_points=10*len(hyperparameterspace), \n",
    "                                                    alternative=0, ref_per_step=REF_PER_STEP)\n",
    "        points = optimizer.fit()\n",
    "\n",
    "        points.sort(key=operator.attrgetter('value'))\n",
    "        summe += points[0].get_value()\n",
    "\n",
    "    ALT_1 += \"(\" + str(REF_PER_STEP) + \",\" + str(summe/N_ITERS) + \")\"\n",
    "\n",
    "    #reset_seeds()\n",
    "\n",
    "    summe = 0\n",
    "    for i in range(N_ITERS):\n",
    "\n",
    "        optimizer = HPO.IterativeRandomOptimization(HPO.Dataset([],[]), function, \n",
    "                                                    hyperparameterspace, BUDGET, 0, 0.45, \n",
    "                                                    init_points=8*len(hyperparameterspace), \n",
    "                                                    alternative=1, ref_per_step=REF_PER_STEP)\n",
    "        points = optimizer.fit()\n",
    "\n",
    "        points.sort(key=operator.attrgetter('value'))\n",
    "        summe += points[0].get_value()\n",
    "\n",
    "    ALT_2 += \"(\" + str(REF_PER_STEP) + \",\" + str(summe/N_ITERS) + \")\"\n",
    "\n",
    "    #reset_seeds()\n",
    "\n",
    "    summe = 0\n",
    "    for i in range(N_ITERS):\n",
    "\n",
    "        optimizer = HPO.IterativeRandomOptimization(HPO.Dataset([],[]), function, \n",
    "                                                    hyperparameterspace, BUDGET, 0, 0.7, \n",
    "                                                    init_points=7*len(hyperparameterspace), \n",
    "                                                    alternative=2, ref_per_step=REF_PER_STEP)\n",
    "        points = optimizer.fit()\n",
    "\n",
    "        points.sort(key=operator.attrgetter('value'))\n",
    "        summe += points[0].get_value()\n",
    "\n",
    "        # x_values = []\n",
    "        # y_values = []\n",
    "        # for i in range(len(points)):\n",
    "        #     x_values.append(points[i].get_coordinates()[0])\n",
    "        #     y_values.append(points[i].get_coordinates()[1])\n",
    "\n",
    "        # fig = plt.figure()\n",
    "        # ax = plt.axes()\n",
    "        # surface = plt.scatter(x_values, y_values, c=\"red\")\n",
    "\n",
    "        # plt.plot([-512, 512],[512, 512])\n",
    "        # plt.plot([-512, 512],[-512, -512])\n",
    "        # plt.plot([-512, -512],[512, -512])\n",
    "        # plt.plot([512, 512],[512, -512])\n",
    "\n",
    "        # plt.gca().set_aspect(\"equal\")\n",
    "\n",
    "        #plt.savefig(\"./Alternative_3.pgf\",bbox_inches='tight' )\n",
    "\n",
    "        #plt.show()\n",
    "\n",
    "    ALT_3 += \"(\" + str(REF_PER_STEP) + \",\" + str(summe/N_ITERS) + \")\"\n",
    "\n",
    "\n",
    "ALT_1 += \"}\"\n",
    "ALT_2 += \"}\"\n",
    "ALT_3 += \"}\"\n",
    "\n",
    "print(ALT_1+\"\\n\")\n",
    "print(ALT_2+\"\\n\")\n",
    "print(ALT_3+\"\\n\")\n",
    "    \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
