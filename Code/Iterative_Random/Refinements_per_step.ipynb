{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline experiment\n",
    "\n",
    "Experiment to compare the 4 Optimization algorithms before trying to improve sparse search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys  \n",
    "sys.path.insert(0, '../')\n",
    "\n",
    "import HPO\n",
    "import pysgpp\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import tensorflow as tf\n",
    "import sklearn.metrics\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from scikeras.wrappers import KerasRegressor\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.compose import TransformedTargetRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.feature_selection import SelectPercentile, chi2\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from numpy.random import seed\n",
    "import random\n",
    "import time\n",
    "import os\n",
    "import math\n",
    "from matplotlib import cm\n",
    "import matplotlib \n",
    "import matplotlib.patches as patches\n",
    "\n",
    "import operator\n",
    "\n",
    "from scipy.stats import norm\n",
    "\n",
    "# matplotlib.use(\"pgf\")\n",
    "# matplotlib.rcParams.update({\n",
    "#     \"pgf.texsystem\": \"pdflatex\",\n",
    "#     'font.family': 'serif',\n",
    "#     'text.usetex': True,\n",
    "#     'pgf.rcfonts': False,\n",
    "# })\n",
    "\n",
    "random.seed(1)\n",
    "seed(2)\n",
    "tf.random.set_seed(3)\n",
    "\n",
    "def reset_seeds():\n",
    "    np.random.seed(1)\n",
    "    random.seed(2)\n",
    "    tf.random.set_seed(3)\n",
    "\n",
    "VERBOSE = 0\n",
    "\n",
    "SPARSE_RESULT = []\n",
    "SPARSE_RESULT_OPTIMIZED = []\n",
    "\n",
    "SPARSE_COST = []\n",
    "SPARSE_COST_OPTIMIZED = []"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter space definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameterspace = {\n",
    "    'x0': [\"interval\", -2, 8],\n",
    "    'x1': [\"interval\", -2, 8],\n",
    "    'x2': [\"interval\", -2, 8],\n",
    "    'x3': [\"interval\", -2, 8],\n",
    "    'x4': [\"interval\", -2, 8],\n",
    "    'x5': [\"interval\", -2, 8],\n",
    "}\n",
    "\n",
    "hyperparameterspace_special = {}\n",
    "for key in hyperparameterspace.keys():\n",
    "    liste = []\n",
    "    for i in range(1, len(hyperparameterspace[key])):\n",
    "        liste.append(hyperparameterspace[key][i])\n",
    "    hyperparameterspace_special[key] = liste\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "BUDGETS = [1 + i * 52 for i in range(19)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REF_PER_STEP: 1\n",
      "REF_PER_STEP: 2\n",
      "REF_PER_STEP: 3\n",
      "REF_PER_STEP: 4\n",
      "REF_PER_STEP: 5\n",
      "REF_PER_STEP: 6\n",
      "REF_PER_STEP: 7\n",
      "REF_PER_STEP: 8\n",
      "REF_PER_STEP: 9\n",
      "REF_PER_STEP: 10\n",
      "REF_PER_STEP: 11\n",
      "REF_PER_STEP: 12\n",
      "REF_PER_STEP: 13\n",
      "REF_PER_STEP: 14\n",
      "REF_PER_STEP: 15\n",
      "REF_PER_STEP: 16\n",
      "REF_PER_STEP: 17\n",
      "REF_PER_STEP: 18\n",
      "REF_PER_STEP: 19\n",
      "REF_PER_STEP: 20\n",
      "REF_PER_STEP: 21\n",
      "REF_PER_STEP: 22\n",
      "REF_PER_STEP: 23\n",
      "REF_PER_STEP: 24\n",
      "REF_PER_STEP: 25\n",
      "REF_PER_STEP: 26\n",
      "REF_PER_STEP: 27\n",
      "REF_PER_STEP: 28\n",
      "REF_PER_STEP: 29\n",
      "REF_PER_STEP: 30\n",
      "REF_PER_STEP: 31\n",
      "REF_PER_STEP: 32\n",
      "REF_PER_STEP: 33\n",
      "REF_PER_STEP: 34\n",
      "REF_PER_STEP: 35\n",
      "REF_PER_STEP: 36\n",
      "REF_PER_STEP: 37\n",
      "REF_PER_STEP: 38\n",
      "REF_PER_STEP: 39\n",
      "REF_PER_STEP: 40\n",
      "REF_PER_STEP: 41\n",
      "REF_PER_STEP: 42\n",
      "REF_PER_STEP: 43\n",
      "REF_PER_STEP: 44\n",
      "REF_PER_STEP: 45\n",
      "REF_PER_STEP: 46\n",
      "REF_PER_STEP: 47\n",
      "REF_PER_STEP: 48\n",
      "REF_PER_STEP: 49\n",
      "REF_PER_STEP: 50\n",
      "{(1,48.71293502446924)(2,50.302621752270944)(3,53.02356274109237)(4,47.49361376157556)(5,45.63645829771873)(6,43.4672909424926)(7,51.67495600450866)(8,46.61027087555904)(9,51.27991940099114)(10,50.62518124297309)(11,52.12365485532708)(12,51.807952009027346)(13,45.808307632334575)(14,48.434788904208084)(15,46.891792275080505)(16,55.7345988253242)(17,51.31357007891148)(18,48.66632606070176)(19,47.6256534814249)(20,50.29400422195458)(21,57.4966844173028)(22,50.81041984544258)(23,50.57666077778573)(24,52.11270428092664)(25,47.360232028865845)(26,51.64422994779293)(27,53.39916017858904)(28,41.53692276396916)(29,51.738538368113)(30,43.165572795937564)(31,45.185356304526024)(32,52.34589985062587)(33,46.62886134557472)(34,48.87918677092345)(35,43.32529169954582)(36,52.3976184265567)(37,45.524625037295564)(38,53.81120286076221)(39,46.574742758573535)(40,52.2772613613183)(41,41.152405277923215)(42,52.27981628060418)(43,54.245536157002604)(44,49.5112776687351)(45,55.403183152307484)(46,47.54543510989261)(47,49.66451083691296)(48,47.89043057198963)(49,52.097875556131484)(50,54.40563624896633)}\n",
      "\n",
      "{(1,27.34039944922215)(2,23.90468763713727)(3,29.0179171591244)(4,28.670345495328284)(5,22.087697983964652)(6,22.33902057668309)(7,26.010009589367353)(8,27.176054611026096)(9,26.70547378798964)(10,23.025565424812875)(11,23.768726667379543)(12,23.800225129673713)(13,26.528073578397937)(14,27.29246739613813)(15,20.006776629711258)(16,26.310416716552048)(17,25.21776645643939)(18,31.075757756336305)(19,30.464405657703345)(20,21.26416619545794)(21,24.298490503626844)(22,21.98558765031671)(23,29.511962245854882)(24,27.490077600241694)(25,25.494274214320335)(26,27.970347737645106)(27,27.076346019105888)(28,21.83324214367723)(29,25.79816012275801)(30,23.038972101808287)(31,27.683371721600345)(32,20.01780525615539)(33,24.92030043127864)(34,27.50494182105996)(35,22.171473091828265)(36,27.69024803335079)(37,23.052402681337185)(38,23.773501112585013)(39,28.771374765170197)(40,24.642945487829074)(41,26.84039953899445)(42,26.57524752076581)(43,26.840946919815337)(44,24.42994251853525)(45,25.722803810611317)(46,22.03332611159169)(47,20.906036477487657)(48,20.191668342417493)(49,22.301244981201375)(50,27.787929763159575)}\n",
      "\n",
      "{(1,22.18662115623201)(2,18.829800910025646)(3,22.157169711854845)(4,23.920761822390283)(5,21.824931108563366)(6,19.50094703164362)(7,22.709414338157746)(8,19.5218304480407)(9,21.740003721910824)(10,20.914436594517817)(11,20.810451063179297)(12,18.72147197662047)(13,21.52737443609096)(14,23.329653125237492)(15,24.71361595149181)(16,22.35935211968271)(17,19.962524019416634)(18,20.706584899479452)(19,21.564129939596686)(20,20.14026696461728)(21,20.582224093703623)(22,23.408395995039065)(23,23.048648706824537)(24,22.6120912916738)(25,20.93500263049617)(26,21.42737934119993)(27,21.326012599980537)(28,22.11260238501432)(29,20.08702210486529)(30,19.558258115872473)(31,23.85514827425544)(32,19.885941714709872)(33,22.416361930975704)(34,19.491961298070255)(35,25.13372309683525)(36,21.521699780544413)(37,23.871221680440986)(38,24.278988103459934)(39,22.176918020433664)(40,21.317620660657443)(41,24.516093321586403)(42,22.399580136627794)(43,19.78987275718456)(44,22.307274731125172)(45,23.517882302070063)(46,20.38009598739485)(47,20.218262219369773)(48,21.771736666744278)(49,18.288826792813467)(50,21.575098979250576)}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "################## MODEL AND FUNCTION DEFINITION ####################\n",
    "\n",
    "def evaluate_model(epochs, batch_size, x2, x3, x4, x5):\n",
    "    #return epochs * batch_size\n",
    "    ################### ROSENBROCK ###############\n",
    "    # sum = 0\n",
    "    # sum += (1-epochs)**2 + 100 * (batch_size - epochs**2) ** 2\n",
    "    # return sum\n",
    "\n",
    "    # ################# RASTRIGIN #################\n",
    "    sum = 0\n",
    "    sum += epochs ** 2 - 10 * math.cos(2 * math.pi * epochs)\n",
    "    sum += batch_size ** 2 - 10 * math.cos(2 * math.pi * batch_size)\n",
    "    sum += x2 ** 2 - 10 * math.cos(2 * math.pi * x2)\n",
    "    sum += x3 ** 2 - 10 * math.cos(2 * math.pi * x3)\n",
    "    sum += x4 ** 2 - 10 * math.cos(2 * math.pi * x4)\n",
    "    sum += x5 ** 2 - 10 * math.cos(2 * math.pi * x5)\n",
    "    return len(hyperparameterspace) * 10 + sum\n",
    "\n",
    "\n",
    "    ################# EGGHOLDER #################\n",
    "    return -epochs * math.sin(math.sqrt(abs(epochs - (batch_size + 47)))) - (batch_size + 47) * math.sin(math.sqrt(abs((batch_size + 47 + 0.5 * epochs))))\n",
    "\n",
    "\n",
    "def function(coordinates):\n",
    "    return evaluate_model(coordinates[0], coordinates[1], coordinates[2], coordinates[3], coordinates[4], coordinates[5])\n",
    "\n",
    "\n",
    "BUDGET = 400\n",
    "\n",
    "N_ITERS = 10\n",
    "\n",
    "ALT_1 = \"{\"\n",
    "ALT_2 = \"{\"\n",
    "ALT_3 = \"{\"\n",
    "\n",
    "REF_PER_STEP = 1\n",
    "\n",
    "for i in range(50):\n",
    "    REF_PER_STEP = i + 1\n",
    "\n",
    "    print(\"REF_PER_STEP:\", REF_PER_STEP)\n",
    "\n",
    "    #reset_seeds()\n",
    "    summe = 0\n",
    "    for i in range(N_ITERS):\n",
    "\n",
    "        optimizer = HPO.IterativeRandomOptimization(HPO.Dataset([],[]), function, \n",
    "                                                    hyperparameterspace, BUDGET, 0, 0.75, \n",
    "                                                    init_points=10*len(hyperparameterspace), \n",
    "                                                    alternative=0, ref_per_step=REF_PER_STEP)\n",
    "        points = optimizer.fit()\n",
    "\n",
    "        points.sort(key=operator.attrgetter('value'))\n",
    "        summe += points[0].get_value()\n",
    "\n",
    "    ALT_1 += \"(\" + str(REF_PER_STEP) + \",\" + str(summe/N_ITERS) + \")\"\n",
    "\n",
    "    #reset_seeds()\n",
    "\n",
    "    summe = 0\n",
    "    for i in range(N_ITERS):\n",
    "\n",
    "        optimizer = HPO.IterativeRandomOptimization(HPO.Dataset([],[]), function, \n",
    "                                                    hyperparameterspace, BUDGET, 0, 0.35, \n",
    "                                                    init_points=8*len(hyperparameterspace), \n",
    "                                                    alternative=1, ref_per_step=REF_PER_STEP)\n",
    "        points = optimizer.fit()\n",
    "\n",
    "        points.sort(key=operator.attrgetter('value'))\n",
    "        summe += points[0].get_value()\n",
    "\n",
    "    ALT_2 += \"(\" + str(REF_PER_STEP) + \",\" + str(summe/N_ITERS) + \")\"\n",
    "\n",
    "    #reset_seeds()\n",
    "\n",
    "    summe = 0\n",
    "    for i in range(N_ITERS):\n",
    "\n",
    "        optimizer = HPO.IterativeRandomOptimization(HPO.Dataset([],[]), function, \n",
    "                                                    hyperparameterspace, BUDGET, 0, 0.6, \n",
    "                                                    init_points=7*len(hyperparameterspace), \n",
    "                                                    alternative=2, ref_per_step=REF_PER_STEP)\n",
    "        points = optimizer.fit()\n",
    "\n",
    "        points.sort(key=operator.attrgetter('value'))\n",
    "        summe += points[0].get_value()\n",
    "\n",
    "        # x_values = []\n",
    "        # y_values = []\n",
    "        # for i in range(len(points)):\n",
    "        #     x_values.append(points[i].get_coordinates()[0])\n",
    "        #     y_values.append(points[i].get_coordinates()[1])\n",
    "\n",
    "        # fig = plt.figure()\n",
    "        # ax = plt.axes()\n",
    "        # surface = plt.scatter(x_values, y_values, c=\"red\")\n",
    "\n",
    "        # plt.plot([-512, 512],[512, 512])\n",
    "        # plt.plot([-512, 512],[-512, -512])\n",
    "        # plt.plot([-512, -512],[512, -512])\n",
    "        # plt.plot([512, 512],[512, -512])\n",
    "\n",
    "        # plt.gca().set_aspect(\"equal\")\n",
    "\n",
    "        #plt.savefig(\"./Alternative_3.pgf\",bbox_inches='tight' )\n",
    "\n",
    "        #plt.show()\n",
    "\n",
    "    ALT_3 += \"(\" + str(REF_PER_STEP) + \",\" + str(summe/N_ITERS) + \")\"\n",
    "\n",
    "\n",
    "ALT_1 += \"}\"\n",
    "ALT_2 += \"}\"\n",
    "ALT_3 += \"}\"\n",
    "\n",
    "print(ALT_1+\"\\n\")\n",
    "print(ALT_2+\"\\n\")\n",
    "print(ALT_3+\"\\n\")\n",
    "    \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
