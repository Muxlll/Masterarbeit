{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dabb667d",
   "metadata": {},
   "source": [
    "# Hyperparameteroptimization\n",
    "\n",
    "Steps:\n",
    "   1. Definition of the data\n",
    "   2. Definition of the hyperparameter space\n",
    "   3. Loop over all different combinations of the hyperparamter space\n",
    "       1. Define the model with the hyperparameters\n",
    "       2. Optimize model (learning phase)\n",
    "       3. Evaluate model and store metric with the parameters\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e6368f",
   "metadata": {},
   "source": [
    "## 0. Imports & utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "254923fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import torch\n",
    "\n",
    "import timeit\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import itertools\n",
    "\n",
    "from mpl_toolkits import mplot3d\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time, sys\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import pysgpp\n",
    "\n",
    "\n",
    "def update_progress(progress, time, remaining_time):\n",
    "    bar_length = 20\n",
    "    if isinstance(progress, int):\n",
    "        progress = float(progress)\n",
    "    if not isinstance(progress, float):\n",
    "        progress = 0\n",
    "    if progress < 0:\n",
    "        progress = 0\n",
    "    if progress >= 1:\n",
    "        progress = 1\n",
    "\n",
    "    block = int(round(bar_length * progress))\n",
    "    clear_output(wait = True)\n",
    "    text = \"Progress: [{0}] {1:.1f}%\".format( \"#\" * block + \"-\" * (bar_length - block), progress * 100)\n",
    "    text += \"\\nCurrent time per iteration: \" + str(time)\n",
    "    text += \"\\nApprox. time remaining: \" + str(remaining_time)\n",
    "    print(text)\n",
    "\n",
    "    \n",
    "def to_standard(lower, upper, value):\n",
    "    return (value-lower)/(upper-lower)\n",
    "\n",
    "\n",
    "def from_standard(lower, upper, value):\n",
    "    return value*(upper-lower)+lower"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "390510ac",
   "metadata": {},
   "source": [
    "## 1. Definition of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59d6d9fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Training samples:  320\n",
      "Number of Testing samples:  80\n"
     ]
    }
   ],
   "source": [
    "NORMAL_FILE_PATH = \"ecg/normal\"\n",
    "ABNORMAL_FILE_PATH = \"ecg/abnormal\"\n",
    "\n",
    "SPLIT_RATIO = 0.8\n",
    "\n",
    "# Load the .0 and .1 files as integer and with max 75 elements per entry.\n",
    "normal_data = np.array([[np.loadtxt(entry, dtype=int, usecols=1, max_rows=75)] for entry in os.scandir(NORMAL_FILE_PATH) if not entry.name.endswith(\".ann\")], dtype=object)\n",
    "abnormal_data = np.array([[np.loadtxt(entry, dtype=int, usecols=1, max_rows=75)] for entry in os.scandir(ABNORMAL_FILE_PATH) if not entry.name.endswith(\".ann\")], dtype=object)\n",
    "\n",
    "# Pad the with zeroes, so that each entry has 75 data points. Also append the class number at the end (0=normal, 1=abnormal).\n",
    "normal_data = np.array([np.append(np.pad(d[0], pad_width=(0, 75 - len(d[0]))), 0) for d in normal_data])\n",
    "abnormal_data = np.array([np.append(np.pad(d[0], pad_width=(0, 75 - len(d[0]))), 1) for d in abnormal_data])\n",
    "\n",
    "# Combine the normal and abnormal data and shuffle the whole dataset.\n",
    "combined_data = np.concatenate((normal_data, abnormal_data))\n",
    "np.random.shuffle(combined_data)\n",
    "\n",
    "# Split into training and validation sets.\n",
    "X_train = torch.Tensor(combined_data[:int(len(combined_data) * SPLIT_RATIO), 0:75])\n",
    "X_test = torch.Tensor(combined_data[int(len(combined_data) * SPLIT_RATIO):, 0:75])\n",
    "Y_train = torch.Tensor(combined_data[:int(len(combined_data) * SPLIT_RATIO), 75:])\n",
    "Y_test = torch.Tensor(combined_data[int(len(combined_data) * SPLIT_RATIO):, 75:])\n",
    "\n",
    "print(\"Number of Training samples: \", len(X_train))\n",
    "print(\"Number of Testing samples: \", len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "573e7eb2",
   "metadata": {},
   "source": [
    "## 2. Definition of Hyperparameter space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2e13b83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of hyperparameters:  2\n"
     ]
    }
   ],
   "source": [
    "#from interval import Interval\n",
    "\n",
    "\n",
    "hyperparameters = {\n",
    "#    \"learning_rate\" : Interval(0.00001, 0.01),\n",
    "    \"learning_rate\" : [0.00001, 0.01],\n",
    "    \"epochs\" : [0, 300]\n",
    "}\n",
    "\n",
    "print(\"Number of hyperparameters: \", len(hyperparameters))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6abe03cd",
   "metadata": {},
   "source": [
    "## 3. Loop over combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "380997d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [####################] 100.0%\n",
      "Current time per iteration: 0.22124562499993772\n",
      "Approx. time remaining: 0.0\n",
      "Iterations took  49.06498508699815  seconds.\n"
     ]
    }
   ],
   "source": [
    "number_per_dimension = 20\n",
    "\n",
    "list_of_values = []\n",
    "\n",
    "for k in hyperparameters.keys():\n",
    "    values = []\n",
    "    \n",
    "    lower, upper = hyperparameters[k][0], hyperparameters[k][1]\n",
    "    \n",
    "    for j in range(number_per_dimension):\n",
    "        values.append(lower+((upper-lower)/(2*number_per_dimension))+j*((upper-lower)/(number_per_dimension)))\n",
    "\n",
    "    list_of_values.append(values)\n",
    "    \n",
    "\n",
    "results_accuracy = []\n",
    "results_loss = []\n",
    "\n",
    "all_combinations = itertools.product(*list_of_values)\n",
    "\n",
    "\n",
    "number_combinations = 1\n",
    "for i in range(len(list_of_values)):\n",
    "    number_combinations *= len(list_of_values[i])\n",
    "\n",
    "    \n",
    "time = 0\n",
    "count = 0\n",
    "for combination in all_combinations:\n",
    "    #print(\"Current combination: \",combination)\n",
    "    starttime = timeit.default_timer()\n",
    "    \n",
    "    learning_rate = combination[0]\n",
    "    epochs = combination[1]\n",
    "    \n",
    "    # Create neural network with 3 layers (75, 5, 1).\n",
    "    class Net(nn.Module):\n",
    "        def __init__(self):\n",
    "            super(Net, self).__init__()\n",
    "            self.fc1 = nn.Linear(75, 15)\n",
    "            self.fc2 = nn.Linear(15, 1)\n",
    "\n",
    "        def forward(self, x):\n",
    "            x = self.fc1(x)\n",
    "            x = F.relu(x)\n",
    "            x = self.fc2(x)\n",
    "            x = torch.sigmoid(x)\n",
    "            return x\n",
    "\n",
    "    # Set optimizer and loss function.\n",
    "    n = Net()\n",
    "    #optimizer = optim.RMSprop(n.parameters(), lr=0.001)\n",
    "    optimizer = optim.RMSprop(n.parameters(), lr=learning_rate)\n",
    "    loss_fn = torch.nn.BCELoss()\n",
    "    #epochs = 300\n",
    "    t_loss = []\n",
    "    v_loss = []\n",
    "    t_acc = []\n",
    "    v_acc = []\n",
    "\n",
    "\n",
    "    def avg(l):\n",
    "        return sum(l) / len(l)\n",
    "\n",
    "    # Training\n",
    "    for i in range(int(epochs)):\n",
    "        n.train()\n",
    "        y_pred_train = n(X_train)\n",
    "        loss_train = loss_fn(y_pred_train, Y_train)\n",
    "        y_pred_test = n(X_test)\n",
    "        loss_test = loss_fn(y_pred_test, Y_test)\n",
    "        optimizer.zero_grad()\n",
    "        loss_train.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        n.eval()\n",
    "        t_loss.append(loss_train.item())\n",
    "        v_loss.append(loss_test.item())\n",
    "        predictions_test = [round(i[0]) for i in y_pred_test.tolist()]\n",
    "        accuracy_test = Y_test.tolist()\n",
    "        acc_test = avg([1 - (abs(predictions_test[i] - accuracy_test[i][0])) for i in\n",
    "                        range(len(accuracy_test))])\n",
    "        predictions_train = [round(i[0]) for i in y_pred_train.tolist()]\n",
    "        accuracy_train = Y_train.tolist()\n",
    "        acc_train = avg([1 - (abs(predictions_train[i] - accuracy_train[i][0])) for i in\n",
    "                         range(len(accuracy_train))])\n",
    "        t_acc.append(acc_train)\n",
    "        v_acc.append(acc_test)\n",
    "\n",
    "\n",
    "    results_loss.append((combination ,v_loss[-1]))\n",
    "    results_accuracy.append((combination, v_acc[-1]))\n",
    "    \n",
    "    count+=1\n",
    "    percentage = count/number_combinations\n",
    "\n",
    "    endtime = timeit.default_timer()\n",
    "    time += (endtime-starttime)\n",
    "    \n",
    "    remaining_time_prediction = (time/count)*number_combinations - time\n",
    "    \n",
    "    update_progress(percentage, (endtime-starttime), remaining_time_prediction)\n",
    "    \n",
    "#print(\"Resulting losses: \")\n",
    "#print(results_loss)\n",
    "print(\"Iterations took \", time, \" seconds.\")\n",
    "\n",
    "#print(\"Resulting accuracy: \")\n",
    "#print(results_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a1ef727",
   "metadata": {},
   "source": [
    "## 4. Plotting and Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bde4b4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_dim_vals = [x[0][0] for x in results_accuracy]\n",
    "y_dim_vals = [x[0][1] for x in results_accuracy]\n",
    "\n",
    "accuracies = [x[1] for x in results_accuracy]\n",
    "losses = [x[1] for x in results_loss]\n",
    "\n",
    "ax = plt.axes(projection='3d')\n",
    "ax.plot_trisurf(x_dim_vals, y_dim_vals, accuracies)\n",
    "ax.scatter3D(x_dim_vals, y_dim_vals, accuracies, c=accuracies);\n",
    "ax.set_xlabel('learning_rate')\n",
    "ax.set_ylabel('epochs')\n",
    "ax.set_zlabel('Accuracy')\n",
    "#fig1.canvas.draw()\n",
    "\n",
    "print(\"Highest Accuracy: \", max(accuracies))\n",
    "combi = -1\n",
    "for i in results_accuracy:\n",
    "    if i[1] - min(accuracies) < 10**(-10):\n",
    "        combi = i[0]\n",
    "print(\"With hyperparameter combination: \", combi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "232272c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fig2 = plt.figure(2)\n",
    "ax = plt.axes(projection='3d')\n",
    "ax.scatter3D(x_dim_vals, y_dim_vals, losses, c=losses);\n",
    "ax.plot_trisurf(x_dim_vals, y_dim_vals, losses)\n",
    "ax.set_xlabel('learning_rate')\n",
    "ax.set_ylabel('epochs')\n",
    "ax.set_zlabel('Loss')\n",
    "\n",
    "print(\"Smallest Loss: \", min(losses))\n",
    "combi = -1\n",
    "for i in results_loss:\n",
    "    if i[1] - min(losses) < 10**(-10):\n",
    "        combi = i[0]\n",
    "print(\"With hyperparameter combination: \", combi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68bd419d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
