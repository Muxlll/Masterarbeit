{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline experiment\n",
    "\n",
    "Experiment to compare the 4 Optimization algorithms before trying to improve sparse search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys  \n",
    "sys.path.insert(0, '../')\n",
    "\n",
    "import HPO\n",
    "import pysgpp\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import sklearn.metrics\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from scikeras.wrappers import KerasRegressor\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.compose import TransformedTargetRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.feature_selection import SelectPercentile, chi2\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from numpy.random import seed\n",
    "import random\n",
    "import time\n",
    "import os\n",
    "import math\n",
    "from matplotlib import cm\n",
    "import matplotlib \n",
    "\n",
    "# matplotlib.use(\"pgf\")\n",
    "# matplotlib.rcParams.update({\n",
    "#     \"pgf.texsystem\": \"pdflatex\",\n",
    "#     'font.family': 'serif',\n",
    "#     'text.usetex': True,\n",
    "#     'pgf.rcfonts': False,\n",
    "# })\n",
    "\n",
    "random.seed(1)\n",
    "seed(2)\n",
    "tf.random.set_seed(3)\n",
    "\n",
    "def reset_seeds():\n",
    "    np.random.seed(1)\n",
    "    random.seed(2)\n",
    "    tf.random.set_seed(3)\n",
    "\n",
    "VERBOSE = 0\n",
    "\n",
    "SPARSE_RESULT = []\n",
    "SPARSE_RESULT_OPTIMIZED = []\n",
    "\n",
    "SPARSE_COST = []\n",
    "SPARSE_COST_OPTIMIZED = []"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter space definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameterspace = {\n",
    "    'x0': [\"interval\", -5, 10],\n",
    "    'x1': [\"interval\", -5, 10],\n",
    "    #'learning_rate': [\"interval-log\", 0.000000001, 0.1],\n",
    "    #'number_layers': [\"interval-int\", 1, 20],\n",
    "    #'neurons_per_layer': [\"interval-int\", 1, 50]\n",
    "}\n",
    "\n",
    "hyperparameterspace_special = {}\n",
    "for key in hyperparameterspace.keys():\n",
    "    liste = []\n",
    "    for i in range(1, len(hyperparameterspace[key])):\n",
    "        liste.append(hyperparameterspace[key][i])\n",
    "    hyperparameterspace_special[key] = liste\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIRECTORY = \"Current_tests/\"+time.strftime(\"%H_%M_%S\", time.localtime())\n",
    "\n",
    "SPARSE_PARAMS = [5, 0.85, \"gradient_descent\"]\n",
    "\n",
    "BUDGETS = [1, 10, 30, 50, 100, 200, 300, 400, 500, 750, 1000]\n",
    "\n",
    "RESULTS_normal = \"{\"\n",
    "RESULTS_local = \"{\"\n",
    "RESULTS_global = \"{\"\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "################################################## Current Budget: 1 ##################################################\n",
      "\n",
      "Performing sparse search\n",
      "Adaptive grid generation (Ritter-Novak)...\n",
      "Done in 0ms.\n",
      "Solving linear system (automatic method)...\n",
      "Done in 0ms.\n",
      "Optimizing (gradient descent)...\n",
      "Done in 0ms.\n",
      "Optimizing (multi-start)...\n",
      "Done in 0ms.\n",
      "\n",
      "################################################## Current Budget: 10 ##################################################\n",
      "\n",
      "Performing sparse search\n",
      "Adaptive grid generation (Ritter-Novak)...\n",
      "Done in 0ms.\n",
      "Solving linear system (automatic method)...\n",
      "Done in 0ms.\n",
      "Optimizing (gradient descent)...\n",
      "Done in 0ms.\n",
      "Optimizing (multi-start)...\n",
      "Done in 0ms.\n",
      "\n",
      "################################################## Current Budget: 30 ##################################################\n",
      "\n",
      "Performing sparse search\n",
      "Adaptive grid generation (Ritter-Novak)...\n",
      "Done in 0ms.\n",
      "Solving linear system (automatic method)...\n",
      "Done in 0ms.\n",
      "Optimizing (gradient descent)...\n",
      "Done in 0ms.\n",
      "Optimizing (multi-start)...\n",
      "Done in 0ms.\n",
      "\n",
      "################################################## Current Budget: 50 ##################################################\n",
      "\n",
      "Performing sparse search\n",
      "Adaptive grid generation (Ritter-Novak)...\n",
      "Done in 0ms.\n",
      "Solving linear system (automatic method)...\n",
      "Done in 0ms.\n",
      "Optimizing (gradient descent)...\n",
      "Done in 0ms.\n",
      "Optimizing (multi-start)...\n",
      "Done in 2ms.\n",
      "\n",
      "################################################## Current Budget: 100 ##################################################\n",
      "\n",
      "Performing sparse search\n",
      "Adaptive grid generation (Ritter-Novak)...\n",
      "Done in 1ms.\n",
      "Solving linear system (automatic method)...\n",
      "Done in 8ms.\n",
      "Optimizing (gradient descent)...\n",
      "Done in 1ms.\n",
      "Optimizing (multi-start)...\n",
      "Done in 2ms.\n",
      "\n",
      "################################################## Current Budget: 200 ##################################################\n",
      "\n",
      "Performing sparse search\n",
      "Adaptive grid generation (Ritter-Novak)...\n",
      "Done in 6ms.\n",
      "Solving linear system (automatic method)...\n",
      "Done in 15ms.\n",
      "Optimizing (gradient descent)...\n",
      "Done in 0ms.\n",
      "Optimizing (multi-start)...\n",
      "Done in 6ms.\n",
      "\n",
      "################################################## Current Budget: 300 ##################################################\n",
      "\n",
      "Performing sparse search\n",
      "Adaptive grid generation (Ritter-Novak)...\n",
      "Done in 10ms.\n",
      "Solving linear system (automatic method)...\n",
      "Done in 798ms.\n",
      "Optimizing (gradient descent)...\n",
      "Done in 0ms.\n",
      "Optimizing (multi-start)...\n",
      "Done in 5ms.\n",
      "\n",
      "################################################## Current Budget: 400 ##################################################\n",
      "\n",
      "Performing sparse search\n",
      "Adaptive grid generation (Ritter-Novak)...\n",
      "Done in 7ms.\n",
      "Solving linear system (automatic method)...\n",
      "Done in 1714ms.\n",
      "Optimizing (gradient descent)...\n",
      "Done in 1ms.\n",
      "Optimizing (multi-start)...\n",
      "Done in 7ms.\n",
      "\n",
      "################################################## Current Budget: 500 ##################################################\n",
      "\n",
      "Performing sparse search\n",
      "Adaptive grid generation (Ritter-Novak)...\n",
      "Done in 11ms.\n",
      "Solving linear system (automatic method)...\n",
      "Done in 2865ms.\n",
      "Optimizing (gradient descent)...\n",
      "Done in 0ms.\n",
      "Optimizing (multi-start)...\n",
      "Done in 11ms.\n",
      "\n",
      "################################################## Current Budget: 750 ##################################################\n",
      "\n",
      "Performing sparse search\n",
      "Adaptive grid generation (Ritter-Novak)...\n",
      "Done in 24ms.\n",
      "Solving linear system (automatic method)...\n",
      "Done in 8660ms.\n",
      "Optimizing (gradient descent)...\n",
      "Done in 3ms.\n",
      "Optimizing (multi-start)...\n",
      "Done in 15ms.\n",
      "\n",
      "################################################## Current Budget: 1000 ##################################################\n",
      "\n",
      "Performing sparse search\n",
      "Adaptive grid generation (Ritter-Novak)...\n",
      "Done in 37ms.\n",
      "Solving linear system (automatic method)...\n",
      "Done in 17822ms.\n",
      "Optimizing (gradient descent)...\n",
      "Done in 5ms.\n",
      "Optimizing (multi-start)...\n",
      "Done in 23ms.\n",
      "{(1,52.5) (9,23.124999999999986) (29,20.221948342338727) (49,12.642146873903025) (97,12.037968800252077) (197,5.324940782206068) (297,5.070573664356438) (397,5.059483529515382) (497,5.059483529505752) (749,4.9819789814573205) (997,4.975134049660271) }\n",
      "{(1,52.5) (9,39.26658373479667) (29,20.847171449176678) (49,49.99973745586844) (97,6.259687480962173) (197,5.002154846904871) (297,4.975751718068931) (397,4.975746034104377) (497,4.975697508130967) (749,3.980892241733912) (997,3.979835850885795) }\n",
      "{(1,48.864612088186476) (9,31.16918203994022) (29,20.48853217431511) (49,50.53387608332728) (97,3.0805866327728566) (197,0.14445847530268452) (297,0.06980177032781754) (397,0.06988725538127483) (497,0.02077395004058502) (749,0.003850124352695161) (997,0.4352002384999345) }\n"
     ]
    }
   ],
   "source": [
    "# os.mkdir(DIRECTORY)\n",
    "\n",
    "# f = open(DIRECTORY+\"/configurations.txt\", \"a\")\n",
    "# f.write(\"Dimension of hyperparameter space: \" +\n",
    "#         str(len(hyperparameterspace)) + \"\\n\")\n",
    "# for key in hyperparameterspace.keys():\n",
    "#     f.write(\"\\n\" + key + \": \" + str(hyperparameterspace[key]))\n",
    "# f.write(\"\\n\\nSparse grid degree: \" + str(SPARSE_PARAMS[0]))\n",
    "# f.write(\"\\nSparse grid adaptivity param: \" + str(SPARSE_PARAMS[1]))\n",
    "# f.write(\"\\nSparse grid optimization alg: \" + str(SPARSE_PARAMS[2]))\n",
    "# f.write(\"\\nBUDGETS: \" + str(BUDGETS))\n",
    "# f.close()\n",
    "\n",
    "\n",
    "################## MODEL AND FUNCTION DEFINITION ####################\n",
    "\n",
    "def evaluate_model(epochs, batch_size, learning_rate, number_of_layers, neurons_per_layer, deterministic=True):\n",
    "\n",
    "    ################# RASTRIGIN #################\n",
    "    sum = 0\n",
    "    sum += epochs ** 2 - 10 * math.cos(2 * math.pi * epochs)\n",
    "    sum += batch_size ** 2 - 10 * math.cos(2 * math.pi * batch_size)\n",
    "    # sum += learning_rate ** 2 - 10 * math.cos(2 * math.pi * learning_rate)\n",
    "    # sum += number_of_layers ** 2 - 10 * math.cos(2 * math.pi * number_of_layers)\n",
    "    # sum += neurons_per_layer ** 2 - 10 * math.cos(2 * math.pi * neurons_per_layer)\n",
    "    return len(hyperparameterspace) * 10 + sum\n",
    "\n",
    "    ################# ROSENBROCK #################\n",
    "    # sum = 0\n",
    "    # sum += (1-epochs)**2 + 100 * (batch_size - epochs**2) ** 2\n",
    "    # return sum\n",
    "\n",
    "    ################# EGGHOLDER #################\n",
    "    # return -epochs * math.sin(math.sqrt(abs(epochs - (batch_size + 47)))) - (batch_size + 47) * math.sin(math.sqrt(abs((batch_size + 47 + 0.5 * epochs))))\n",
    "\n",
    "    # return epochs + batch_size + learning_rate + number_of_layers + neurons_per_layer\n",
    "\n",
    "\n",
    "class ExampleFunction(pysgpp.ScalarFunction):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(ExampleFunction, self).__init__(\n",
    "            len(hyperparameterspace.keys()))\n",
    "\n",
    "    def eval(self, x):\n",
    "        # index = int(x[0]*(len(hyperparameterspace_special[\"loss\"])-1))\n",
    "        # hyperparameterspace_special[\"loss\"][index]\n",
    "\n",
    "        epochs = (HPO.from_standard(\n",
    "            hyperparameterspace_special[\"x0\"][0], hyperparameterspace_special[\"x0\"][1], x[0]))\n",
    "\n",
    "        batch_size = (HPO.from_standard(\n",
    "            hyperparameterspace_special[\"x1\"][0], hyperparameterspace_special[\"x1\"][1], x[1]))\n",
    "\n",
    "        # HPO.from_standard_log(hyperparameterspace_special[\"learning_rate\"][\n",
    "        model_learning_rate = 0\n",
    "        #                  0], hyperparameterspace_special[\"learning_rate\"][1], x[2])\n",
    "\n",
    "        number_of_layers = 0  # int(HPO.from_standard(\n",
    "        # hyperparameterspace_special[\"number_layers\"][0], hyperparameterspace_special[\"number_layers\"][1], x[3]))\n",
    "\n",
    "        neurons_per_layer = 0  # int(HPO.from_standard(\n",
    "        # hyperparameterspace_special[\"neurons_per_layer\"][0], hyperparameterspace_special[\"neurons_per_layer\"][1], x[4]))\n",
    "\n",
    "        return evaluate_model(epochs, batch_size, model_learning_rate, number_of_layers, neurons_per_layer)\n",
    "\n",
    "\n",
    "# resolution = 200\n",
    "\n",
    "# x = np.linspace(-2, 8, resolution)\n",
    "# y = np.linspace(-2, 8, resolution)\n",
    "\n",
    "# X, Y = np.meshgrid(x, y)\n",
    "\n",
    "# Z = np.zeros((resolution, resolution))\n",
    "\n",
    "# for i in range(resolution):\n",
    "#     for j in range(resolution):\n",
    "#         Z[i][j] = evaluate_model(X[i][j], Y[i][j], 0, 0, 0)\n",
    "\n",
    "\n",
    "# fig = plt.figure()\n",
    "# ax = plt.axes(projection='3d')\n",
    "# surface = ax.plot_surface(X, Y, Z, cmap='plasma')\n",
    "# ax.set_xlabel('x0')\n",
    "# ax.set_ylabel('x1')\n",
    "# ax.set_zlabel('y')\n",
    "# fig.colorbar(surface, shrink=0.8, aspect=15)\n",
    "# plt.savefig(\"./Testfunctions/Rastrigin_normal.pgf\",bbox_inches='tight' )\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "# fig = plt.figure()\n",
    "# ax = plt.axes(projection='3d')\n",
    "# surface = ax.plot_surface(X, Y, Z, cmap='plasma')\n",
    "# ax.set_xlabel('x0')\n",
    "# ax.set_ylabel('x1')\n",
    "# ax.set_zlabel('y')\n",
    "# ax.set_zticks([])\n",
    "# ax.view_init(90, 270)\n",
    "# fig.colorbar(surface, shrink=0.8, aspect=15)\n",
    "# plt.savefig(\"./Testfunctions/Rastrigin_above.pgf\",bbox_inches='tight' )\n",
    "# plt.show()\n",
    "\n",
    "#### For each dataset: run models with different budget #####\n",
    "for BUDGET in BUDGETS:\n",
    "\n",
    "    print(\"\\n################################################## Current Budget:\",\n",
    "            BUDGET, \"##################################################\")\n",
    "\n",
    "    ########################### SPARSE OPT ############################\n",
    "\n",
    "    print(\"\\nPerforming sparse search\")\n",
    "\n",
    "    f = ExampleFunction()\n",
    "    dataset = HPO.Dataset([], [])\n",
    "\n",
    "    optimization = HPO.SparseGridSearchOptimization(\n",
    "        dataset, f, hyperparameterspace, budget=BUDGET, verbosity=VERBOSE, degree=3, adaptivity=0.85)\n",
    "\n",
    "    [x0, fX0, x1, fX1, x2, fX2], cost  = optimization.fit()\n",
    "\n",
    "    RESULTS_normal += \"(\" + str(cost) + \",\" + str(fX0) + \") \"\n",
    "    RESULTS_local += \"(\" + str(cost) + \",\" + str(fX1) + \") \"\n",
    "    RESULTS_global += \"(\" + str(cost) + \",\" + str(fX2) + \") \"\n",
    "\n",
    "    # print(\"Best result from sparse grid:\")\n",
    "    # print(x0)\n",
    "    # print(fX0)\n",
    "\n",
    "    # print(\"Best result from local optimization:\")\n",
    "    # print(x1)\n",
    "    # print(fX1)\n",
    "\n",
    "    # print(\"Best result from global optimization:\")\n",
    "    # print(x2)\n",
    "    # print(fX2)\n",
    "\n",
    "    # print(\"Cost:\")\n",
    "    # print(cost)\n",
    "\n",
    "RESULTS_normal += \"}\"\n",
    "RESULTS_local += \"}\"\n",
    "RESULTS_global += \"}\"\n",
    "\n",
    "\n",
    "print(RESULTS_normal)\n",
    "print(RESULTS_local)\n",
    "print(RESULTS_global)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
