{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST dataset classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39msys\u001b[39;00m  \n\u001b[1;32m      2\u001b[0m sys\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39minsert(\u001b[39m0\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m../\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mHPO\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpysgpp\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n",
      "File \u001b[0;32m~/Repos/Masterarbeit/Code/Comparison_w_paper/../HPO.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m shuffle\n\u001b[1;32m      6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_selection\u001b[39;00m \u001b[39mimport\u001b[39;00m GridSearchCV, RandomizedSearchCV\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/__init__.py:990\u001b[0m\n\u001b[1;32m    988\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m library\n\u001b[1;32m    989\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m TYPE_CHECKING:\n\u001b[0;32m--> 990\u001b[0m         \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m _meta_registrations\n\u001b[1;32m    992\u001b[0m \u001b[39m# Enable CUDA Sanitizer\u001b[39;00m\n\u001b[1;32m    993\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mTORCH_CUDA_SANITIZER\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m os\u001b[39m.\u001b[39menviron:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_meta_registrations.py:16\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_prims_common\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m      8\u001b[0m     check,\n\u001b[1;32m      9\u001b[0m     corresponding_complex_dtype,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m     ELEMENTWISE_TYPE_PROMOTION_KIND,\n\u001b[1;32m     13\u001b[0m )\n\u001b[1;32m     15\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_prims_common\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mwrappers\u001b[39;00m \u001b[39mimport\u001b[39;00m out_wrapper\n\u001b[0;32m---> 16\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_refs\u001b[39;00m \u001b[39mimport\u001b[39;00m _broadcast_shapes\n\u001b[1;32m     17\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_pytree\u001b[39;00m \u001b[39mimport\u001b[39;00m tree_map\n\u001b[1;32m     19\u001b[0m aten \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mops\u001b[39m.\u001b[39maten\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_refs/__init__.py:14\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtyping\u001b[39;00m \u001b[39mimport\u001b[39;00m Callable, List, Optional, overload, Sequence, Tuple, Union\n\u001b[1;32m     12\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_prims\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mprims\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_prims_common\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mutils\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_prims_common\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     17\u001b[0m     check,\n\u001b[1;32m     18\u001b[0m     DeviceLikeType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     32\u001b[0m     TensorSequenceType,\n\u001b[1;32m     33\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_prims/__init__.py:1044\u001b[0m\n\u001b[1;32m   1030\u001b[0m ne \u001b[39m=\u001b[39m _make_elementwise_binary_prim(\n\u001b[1;32m   1031\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mne\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1032\u001b[0m     impl_aten\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mne,\n\u001b[1;32m   1033\u001b[0m     doc\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1034\u001b[0m     type_promotion\u001b[39m=\u001b[39mELEMENTWISE_PRIM_TYPE_PROMOTION_KIND\u001b[39m.\u001b[39mALWAYS_BOOL,\n\u001b[1;32m   1035\u001b[0m )\n\u001b[1;32m   1037\u001b[0m nextafter \u001b[39m=\u001b[39m _make_elementwise_binary_prim(\n\u001b[1;32m   1038\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mnextafter\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1039\u001b[0m     impl_aten\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mnextafter,\n\u001b[1;32m   1040\u001b[0m     doc\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1041\u001b[0m     type_promotion\u001b[39m=\u001b[39mELEMENTWISE_PRIM_TYPE_PROMOTION_KIND\u001b[39m.\u001b[39mDEFAULT,\n\u001b[1;32m   1042\u001b[0m )\n\u001b[0;32m-> 1044\u001b[0m \u001b[39mpow\u001b[39m \u001b[39m=\u001b[39m _make_elementwise_binary_prim(\n\u001b[1;32m   1045\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39mpow\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m   1046\u001b[0m     impl_aten\u001b[39m=\u001b[39;49mtorch\u001b[39m.\u001b[39;49mpow,\n\u001b[1;32m   1047\u001b[0m     doc\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m   1048\u001b[0m     type_promotion\u001b[39m=\u001b[39;49mELEMENTWISE_PRIM_TYPE_PROMOTION_KIND\u001b[39m.\u001b[39;49mDEFAULT,\n\u001b[1;32m   1049\u001b[0m )\n\u001b[1;32m   1051\u001b[0m remainder \u001b[39m=\u001b[39m _make_elementwise_binary_prim(\n\u001b[1;32m   1052\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mremainder\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1053\u001b[0m     impl_aten\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mremainder,\n\u001b[1;32m   1054\u001b[0m     doc\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1055\u001b[0m     type_promotion\u001b[39m=\u001b[39mELEMENTWISE_PRIM_TYPE_PROMOTION_KIND\u001b[39m.\u001b[39mDEFAULT,\n\u001b[1;32m   1056\u001b[0m )\n\u001b[1;32m   1059\u001b[0m shift_left \u001b[39m=\u001b[39m _make_elementwise_binary_prim(\n\u001b[1;32m   1060\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mshift_left\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1061\u001b[0m     impl_aten\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mbitwise_left_shift,\n\u001b[1;32m   1062\u001b[0m     doc\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1063\u001b[0m     type_promotion\u001b[39m=\u001b[39mELEMENTWISE_PRIM_TYPE_PROMOTION_KIND\u001b[39m.\u001b[39mDEFAULT,\n\u001b[1;32m   1064\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_prims/__init__.py:423\u001b[0m, in \u001b[0;36m_make_elementwise_binary_prim\u001b[0;34m(name, type_promotion, **kwargs)\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_make_elementwise_binary_prim\u001b[39m(\n\u001b[1;32m    417\u001b[0m     name: \u001b[39mstr\u001b[39m, \u001b[39m*\u001b[39m, type_promotion: ELEMENTWISE_PRIM_TYPE_PROMOTION_KIND, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[1;32m    418\u001b[0m ):\n\u001b[1;32m    419\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    420\u001b[0m \u001b[39m    Creates an elementwise binary prim.\u001b[39;00m\n\u001b[1;32m    421\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 423\u001b[0m     \u001b[39mreturn\u001b[39;00m _make_prim(\n\u001b[1;32m    424\u001b[0m         schema\u001b[39m=\u001b[39;49m\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m{\u001b[39;49;00mname\u001b[39m}\u001b[39;49;00m\u001b[39m(Tensor self, Tensor other) -> Tensor\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    425\u001b[0m         meta\u001b[39m=\u001b[39;49mpartial(_elementwise_meta, type_promotion\u001b[39m=\u001b[39;49mtype_promotion),\n\u001b[1;32m    426\u001b[0m         return_type\u001b[39m=\u001b[39;49mRETURN_TYPE\u001b[39m.\u001b[39;49mNEW,\n\u001b[1;32m    427\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    428\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_prims/__init__.py:294\u001b[0m, in \u001b[0;36m_make_prim\u001b[0;34m(schema, return_type, meta, impl_aten, doc)\u001b[0m\n\u001b[1;32m    290\u001b[0m _prim \u001b[39m=\u001b[39m _prim_packet\u001b[39m.\u001b[39mdefault\n\u001b[1;32m    292\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_subclasses\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfake_tensor\u001b[39;00m \u001b[39mimport\u001b[39;00m contains_tensor_types\n\u001b[0;32m--> 294\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39many\u001b[39m(contains_tensor_types(a\u001b[39m.\u001b[39mtype) \u001b[39mfor\u001b[39;00m a \u001b[39min\u001b[39;00m _prim\u001b[39m.\u001b[39m_schema\u001b[39m.\u001b[39marguments):\n\u001b[1;32m    295\u001b[0m     prim_backend_select_impl\u001b[39m.\u001b[39mimpl(name, _backend_select_impl)\n\u001b[1;32m    297\u001b[0m \u001b[39mfor\u001b[39;00m p \u001b[39min\u001b[39;00m (_prim_packet, _prim):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import sys  \n",
    "sys.path.insert(0, '../')\n",
    "\n",
    "\n",
    "import HPO\n",
    "import pysgpp\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import sklearn.metrics\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout, MaxPooling2D, Conv2D\n",
    "from scikeras.wrappers import KerasRegressor\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.compose import TransformedTargetRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.feature_selection import SelectPercentile, chi2\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from numpy.random import seed\n",
    "import random\n",
    "import time\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "\n",
    "random.seed(1)\n",
    "seed(2)\n",
    "tf.random.set_seed(3)\n",
    "\n",
    "def reset_seeds():\n",
    "    np.random.seed(1)\n",
    "    random.seed(2)\n",
    "    tf.random.set_seed(3)\n",
    "\n",
    "VERBOSE = 1\n",
    "CV = 2 #[(slice(None), slice(None))]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter space definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameterspace = {\n",
    "    #'epochs': [\"interval-int\", 1, 10],\n",
    "    'batch_size': [\"interval-int\", 20, 2000],\n",
    "    'learning_rate': [\"interval-log\", 1e-16, 1],\n",
    "    #'number_conv_layers': [\"interval-int\", 1, 4],\n",
    "    #'number_fc_layers': [\"interval-int\", 1, 4],\n",
    "    #'kernel_size': [\"interval-int\", 1, 5],\n",
    "    #'pool_size': [\"interval-int\", 1, 4],\n",
    "    #'neurons_per_fc_layer': [\"interval-int\", 1, 10],\n",
    "    #'dropout_prob': [\"interval\", 0, 1]\n",
    "}\n",
    "\n",
    "hyperparameterspace_special = {}\n",
    "for key in hyperparameterspace.keys():\n",
    "    liste = []\n",
    "    for i in range(1, len(hyperparameterspace[key])):\n",
    "        liste.append(hyperparameterspace[key][i])\n",
    "    hyperparameterspace_special[key] = liste\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_classes = 10\n",
    "input_shape = (28, 28, 1)\n",
    "\n",
    "\n",
    "def create_model(learning_rate=1e-4):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(keras.Input(shape=input_shape))\n",
    "\n",
    "    model.add(layers.Conv2D(32, kernel_size=(5, 5), activation=\"relu\"))\n",
    "    model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(layers.Conv2D(32, kernel_size=(5, 5), activation=\"relu\"))\n",
    "    model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(layers.Flatten())\n",
    "\n",
    "    model.add(layers.Dense(num_classes, activation=\"softmax\"))\n",
    "\n",
    "    optimizer = keras.optimizers.SGD(learning_rate=learning_rate)\n",
    "\n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIRECTORY = \"Current_tests/\"+time.strftime(\"%H_%M_%S\", time.localtime())\n",
    "\n",
    "SPARSE_PARAMS = [2, 0.85, \"gradient_descent\"]\n",
    "\n",
    "BUDGETS = [7, 10, 16, 30, 50]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################## MODEL AND FUNCTION DEFINITION ####################\n",
    "\n",
    "def evaluate_model(batch_size, learning_rate, deterministic=True):\n",
    "    \n",
    "    if deterministic:\n",
    "        reset_seeds()\n",
    "\n",
    "    (x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "    # Scale images to the [0, 1] range\n",
    "    x_train = x_train.astype(\"float32\") / 255\n",
    "    x_test = x_test.astype(\"float32\") / 255\n",
    "\n",
    "    # Make sure images have shape (28, 28, 1)\n",
    "    x_train = np.expand_dims(x_train, -1)\n",
    "    x_test = np.expand_dims(x_test, -1)\n",
    "\n",
    "    # convert class vectors to binary class matrices\n",
    "    y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "    y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "    model = create_model(learning_rate)\n",
    "\n",
    "    callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=2)\n",
    "\n",
    "    model.fit(x_train, y_train, verbose=0, batch_size=batch_size, epochs=20, validation_split=0.1, shuffle=False, callbacks=[callback])\n",
    "\n",
    "    score = model.evaluate(x_test, y_test, verbose=0)\n",
    "\n",
    "    K.clear_session()\n",
    "    del model \n",
    "\n",
    "    return -score[1]\n",
    "    \n",
    "\n",
    "def blackboxfunction_grid(params):\n",
    "\n",
    "    batch_size = int(params[0])\n",
    "\n",
    "    learning_rate = params[1]\n",
    "\n",
    "    return evaluate_model(batch_size, learning_rate)\n",
    "\n",
    "def blackboxfunction_random(params):\n",
    "    \n",
    "    batch_size = int(params[0])\n",
    "\n",
    "    learning_rate = params[1]\n",
    "\n",
    "    return evaluate_model(batch_size, learning_rate, deterministic=False)\n",
    "\n",
    "def blackboxfunction_bayesian(params):\n",
    "    \n",
    "    batch_size = int(params[0])\n",
    "\n",
    "    learning_rate = 10 ** params[1]\n",
    "\n",
    "    return evaluate_model(batch_size, learning_rate, deterministic=False)\n",
    "\n",
    "##################### Function for sparse grid search #####################\n",
    "\n",
    "class ExampleFunction(pysgpp.ScalarFunction):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(ExampleFunction, self).__init__(\n",
    "            len(hyperparameterspace.keys()))\n",
    "\n",
    "    def eval(self, x):\n",
    "        \n",
    "        batch_size = int(HPO.from_standard(\n",
    "            hyperparameterspace_special[\"batch_size\"][0], hyperparameterspace_special[\"batch_size\"][1], x[0]))\n",
    "\n",
    "        learning_rate = HPO.from_standard_log(\n",
    "            hyperparameterspace_special[\"learning_rate\"][0], hyperparameterspace_special[\"learning_rate\"][1], x[1])\n",
    "\n",
    "        return evaluate_model(batch_size, learning_rate)\n",
    "\n",
    "\n",
    "RESULTS_GRID = \"{\"\n",
    "RESULTS_RANDOM = \"{\"\n",
    "RESULTS_BAYESIAN = \"{\"\n",
    "RESULTS_SPARSE = \"{\"\n",
    "\n",
    "dataset = HPO.Dataset([], [])\n",
    "\n",
    "##### For each dataset: run models with different budget #####\n",
    "for BUDGET in BUDGETS:\n",
    "\n",
    "    print(\"\\n################################################## Current Budget:\",\n",
    "            BUDGET, \"##################################################\")\n",
    "\n",
    "    ############################## GRID SEARCH #######################\n",
    "\n",
    "    print(\"\\nPerforming grid search\")\n",
    "    optimization = HPO.GridSearchOptimization(\n",
    "        dataset, blackboxfunction_grid, hyperparameterspace, budget=BUDGET, verbosity=VERBOSE, cv=CV)\n",
    "\n",
    "    result, cost = optimization.fit()\n",
    "\n",
    "    index_best = 0\n",
    "    for m in range(len(result)):\n",
    "        if result[m][1] < result[index_best][1]:\n",
    "            index_best = m\n",
    "\n",
    "    best_score = result[index_best][1]\n",
    "    best_params = result[index_best][0]\n",
    "    \n",
    "\n",
    "    print(\"Best score with Grid search:\", best_score)\n",
    "\n",
    "    if VERBOSE > 0:\n",
    "        print(\"With Hyperparameters: \")\n",
    "        m = 0\n",
    "        for key in hyperparameterspace.keys():\n",
    "            if hyperparameterspace[key][0] == \"list\":\n",
    "                index = int(\n",
    "                    best_params[m]*(len(hyperparameterspace_special[key])-1))\n",
    "                print(key + \": \" +\n",
    "                    str(hyperparameterspace_special[key][index]))\n",
    "            else:\n",
    "                print(key + \": \" + str(best_params[m]))\n",
    "            m += 1\n",
    "\n",
    "    print(\"Best score with Grid search:\", best_score)\n",
    "\n",
    "    RESULTS_GRID += \"(\" + str(cost) + \",\" + str(-best_score) + \")\"\n",
    "\n",
    "    K.clear_session()\n",
    "\n",
    "    # ########################### RANDOM SEARCH #######################\n",
    "    print(\"\\nPerforming random search\")\n",
    "\n",
    "    optimization = HPO.RandomSearchOptimization(\n",
    "        dataset, blackboxfunction_random, hyperparameterspace, budget=BUDGET, verbosity=VERBOSE, cv=CV)\n",
    "\n",
    "    result, cost = optimization.fit()\n",
    "\n",
    "    index_best = 0\n",
    "    for m in range(len(result)):\n",
    "        if result[m][1] < result[index_best][1]:\n",
    "            index_best = m\n",
    "\n",
    "    best_score = result[index_best][1]\n",
    "    best_params = result[index_best][0]\n",
    "    \n",
    "    if VERBOSE > 0:\n",
    "        print(\"With Hyperparameters: \")\n",
    "        m = 0\n",
    "        for key in hyperparameterspace.keys():\n",
    "            if hyperparameterspace[key][0] == \"list\":\n",
    "                index = int(\n",
    "                    best_params[m]*(len(hyperparameterspace_special[key])-1))\n",
    "                print(key + \": \" +\n",
    "                      str(hyperparameterspace_special[key][index]))\n",
    "            else:\n",
    "                print(key + \": \" + str(best_params[m]))\n",
    "            m += 1\n",
    "\n",
    "    print(\"Best score with Random search:\", best_score)\n",
    "\n",
    "    RESULTS_RANDOM += \"(\" + str(cost) + \",\" + str(-best_score) + \")\"\n",
    "    \n",
    "\n",
    "    K.clear_session()\n",
    "\n",
    "    ########################### BAYESIAN OPT #####################\n",
    "    print(\"\\nPerforming bayesian optimization\")\n",
    "\n",
    "    optimization = HPO.BayesianOptimization(\n",
    "        dataset, blackboxfunction_bayesian, hyperparameterspace, budget=BUDGET, verbosity=VERBOSE)\n",
    "\n",
    "    result, cost = optimization.fit()\n",
    "\n",
    "    index_best = 0\n",
    "    for m in range(len(result)):\n",
    "        if result[m][1] < result[index_best][1]:\n",
    "            index_best = m\n",
    "\n",
    "    best_score = result[index_best][1]\n",
    "    best_params = result[index_best][0]\n",
    "\n",
    "    \n",
    "    \n",
    "    if VERBOSE > 0:\n",
    "        print(\"With Hyperparameters: \")\n",
    "        m = 0\n",
    "        for key in hyperparameterspace.keys():\n",
    "            if hyperparameterspace[key][0] == \"list\":\n",
    "                index = int(\n",
    "                    best_params[m]*(len(hyperparameterspace_special[key])-1))\n",
    "                print(key + \": \" +\n",
    "                      str(hyperparameterspace_special[key][index]))\n",
    "            else:\n",
    "                print(key + \": \" + str(best_params[m]))\n",
    "            m += 1\n",
    "    \n",
    "\n",
    "    print(\"Best score with Bayesian Optimization:\", best_score)\n",
    "\n",
    "\n",
    "    RESULTS_BAYESIAN += \"(\" + str(BUDGET) + \",\" + str(-best_score) + \")\"\n",
    "    \n",
    "\n",
    "    K.clear_session()\n",
    "\n",
    "    ########################### SPARSE OPT ############################\n",
    "\n",
    "    print(\"\\nPerforming sparse search\")\n",
    "\n",
    "    f = ExampleFunction()\n",
    "\n",
    "    optimization = HPO.SparseGridSearchOptimization(\n",
    "        dataset, f, hyperparameterspace, budget=BUDGET, verbosity=VERBOSE, degree=SPARSE_PARAMS[0], adaptivity=SPARSE_PARAMS[1], optimizer=SPARSE_PARAMS[2])\n",
    "\n",
    "    [X0, fX0, X1, fX1, X2, fX2], cost = optimization.fit()\n",
    "\n",
    "    cost = cost + 2\n",
    "    bestFX = fX0 \n",
    "    bestX = X0\n",
    "    if fX1 < bestFX:\n",
    "        bestFX = fX1 \n",
    "        bestX = X1 \n",
    "    if fX2 < bestFX:\n",
    "        bestFX = fX2\n",
    "        bestX = X2\n",
    "\n",
    "    RESULTS_SPARSE += \"(\" + str(cost) + \",\" + str(-bestFX) + \")\"\n",
    "\n",
    "    if VERBOSE > 0:\n",
    "        print(\"With Hyperparameters: \")\n",
    "        m = 0\n",
    "        for key in hyperparameterspace.keys():\n",
    "            if hyperparameterspace[key][0] == \"list\":\n",
    "                index = int(\n",
    "                    X0[m]*(len(hyperparameterspace_special[key])-1))\n",
    "                print(key + \": \" +\n",
    "                      str(hyperparameterspace_special[key][index]))\n",
    "            else:\n",
    "                print(key + \": \" + str(X0[m]))\n",
    "            m += 1\n",
    "\n",
    "    K.clear_session()\n",
    "\n",
    "    print(\"GRID SEARCH\")\n",
    "    print(RESULTS_GRID+\"}\")\n",
    "\n",
    "    print(\"RANDOM SEARCH\")\n",
    "    print(RESULTS_RANDOM+\"}\")\n",
    "\n",
    "    print(\"BAYESIAN SEARCH\")\n",
    "    print(RESULTS_BAYESIAN+\"}\")\n",
    "\n",
    "    print(\"SPARSE SEARCH\")\n",
    "    print(RESULTS_SPARSE+\"}\")\n",
    "\n",
    "\n",
    "print(\"GRID SEARCH\")\n",
    "print(RESULTS_GRID+\"}\")\n",
    "\n",
    "print(\"RANDOM SEARCH\")\n",
    "print(RESULTS_RANDOM+\"}\")\n",
    "\n",
    "print(\"BAYESIAN SEARCH\")\n",
    "print(RESULTS_BAYESIAN+\"}\")\n",
    "\n",
    "print(\"SPARSE SEARCH\")\n",
    "print(RESULTS_SPARSE+\"}\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
