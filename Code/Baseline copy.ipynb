{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline experiment\n",
    "\n",
    "Experiment to compare the 4 Optimization algorithms before trying to improve sparse search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import HPO\n",
    "import pysgpp\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import sklearn.metrics\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from scikeras.wrappers import KerasRegressor\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.compose import TransformedTargetRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.feature_selection import SelectPercentile, chi2\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from numpy.random import seed\n",
    "import random\n",
    "import time\n",
    "import os\n",
    "import math\n",
    "\n",
    "random.seed(1)\n",
    "seed(2)\n",
    "tf.random.set_seed(3)\n",
    "\n",
    "def reset_seeds():\n",
    "    np.random.seed(1)\n",
    "    random.seed(2)\n",
    "    tf.random.set_seed(3)\n",
    "\n",
    "VERBOSE = 1\n",
    "CV = 2 #[(slice(None), slice(None))]\n",
    "TESTING = True\n",
    "\n",
    "DATASETS = []\n",
    "\n",
    "GRID_RESULT = []\n",
    "RANDOM_RESULT = []\n",
    "BAYESIAN_RESULT = []\n",
    "SPARSE_RESULT = []\n",
    "SPARSE_RESULT_OPTIMIZED = []\n",
    "\n",
    "GRID_COST = []\n",
    "RANDOM_COST = []\n",
    "BAYESIAN_COST = []\n",
    "SPARSE_COST = []\n",
    "SPARSE_COST_OPTIMIZED = []"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter space definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameterspace = {\n",
    "    'epochs': [\"interval\", -512, 512],\n",
    "    'batch_size': [\"interval\", -512, 512],\n",
    "    #'learning_rate': [\"interval-log\", 0.000000001, 0.1],\n",
    "    #'number_layers': [\"interval-int\", 1, 20],\n",
    "    #'neurons_per_layer': [\"interval-int\", 1, 50]\n",
    "}\n",
    "\n",
    "hyperparameterspace_special = {}\n",
    "for key in hyperparameterspace.keys():\n",
    "    liste = []\n",
    "    for i in range(1, len(hyperparameterspace[key])):\n",
    "        liste.append(hyperparameterspace[key][i])\n",
    "    hyperparameterspace_special[key] = liste\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_model(learning_rate=0.0001, input_dim=10, number_layers=1, neurons_per_layer=20):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(neurons_per_layer, input_shape=(input_dim,), activation='relu'))\n",
    "    for _ in range(number_layers):\n",
    "        model.add(Dense(neurons_per_layer, activation='relu'))\n",
    "    model.add(Dense(1, activation=None))\n",
    "\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "    model.compile(loss='mean_squared_error', optimizer=optimizer)\n",
    "    return model\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIRECTORY = \"Current_tests/\"+time.strftime(\"%H_%M_%S\", time.localtime())\n",
    "\n",
    "SPARSE_PARAMS = [2, 0.75, \"gradient_descent\"]\n",
    "\n",
    "ITER = 20\n",
    "BUDGETS = [(2 * x) + 1 for x in range(ITER)]\n",
    "\n",
    "for i in range(3):\n",
    "    BUDGETS.append((i+1)**len(hyperparameterspace))\n",
    "\n",
    "BUDGETS = list(set(BUDGETS))\n",
    "BUDGETS.sort()\n",
    "\n",
    "\n",
    "\n",
    "BUDGETS = [1, 4, 5, 9, 10, 15, 16, 20, 30, 50, 75, 100, 130]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir(DIRECTORY)\n",
    "\n",
    "f = open(DIRECTORY+\"/configurations.txt\", \"a\")\n",
    "f.write(\"Dimension of hyperparameter space: \" +\n",
    "        str(len(hyperparameterspace)) + \"\\n\")\n",
    "for key in hyperparameterspace.keys():\n",
    "    f.write(\"\\n\" + key + \": \" + str(hyperparameterspace[key]))\n",
    "f.write(\"\\n\\nSparse grid degree: \" + str(SPARSE_PARAMS[0]))\n",
    "f.write(\"\\nSparse grid adaptivity param: \" + str(SPARSE_PARAMS[1]))\n",
    "f.write(\"\\nSparse grid optimization alg: \" + str(SPARSE_PARAMS[2]))\n",
    "f.write(\"\\nBUDGETS: \" + str(BUDGETS))\n",
    "f.close()\n",
    "\n",
    "ids = [233211]#, 359952, 359931, 359949, 359938]\n",
    "# [359940, 317614, 359934, 359946, 359932, 233214, 359943]\n",
    "\n",
    "for i in range(len(ids)):\n",
    "    print(\"######################################################################################################################################################\")\n",
    "    print(\"Current Dataset:\", (i+1), \"of\", len(ids), \"with id:\", ids[i])\n",
    "\n",
    "    dataset = HPO.Dataset(task_id=ids[i])\n",
    "\n",
    "    print(\"The average value for target is:\", sum(\n",
    "        dataset.get_Y()/len(dataset.get_Y())))\n",
    "    print(\"Min target:\", min(dataset.get_Y()),\n",
    "          \"Max target:\", max(dataset.get_Y()))\n",
    "\n",
    "    current_dataset_grid = []\n",
    "    current_dataset_random = []\n",
    "    current_dataset_bayesian = []\n",
    "    current_dataset_sparse = []\n",
    "    current_dataset_sparse_opt = []\n",
    "\n",
    "    current_dataset_grid_cost = []\n",
    "    current_dataset_random_cost = []\n",
    "    current_dataset_bayesian_cost = []\n",
    "    current_dataset_sparse_cost = []\n",
    "    current_dataset_sparse_opt_cost = []\n",
    "\n",
    "    ################## MODEL AND FUNCTION DEFINITION ####################\n",
    "\n",
    "    def evaluate_model(epochs, batch_size, learning_rate, number_of_layers, neurons_per_layer, deterministic=True):\n",
    "\n",
    "        return -epochs * math.sin(math.sqrt(abs(epochs - (batch_size + 47)))) - (batch_size + 47) * math.sin(math.sqrt(abs((batch_size + 47 + 0.5 * epochs))))\n",
    "\n",
    "        # return epochs + batch_size + learning_rate + number_of_layers + neurons_per_layer\n",
    "\n",
    "        kfold = KFold(n_splits=CV)\n",
    "\n",
    "        split = (kfold.split(dataset.get_X(), dataset.get_Y()))\n",
    "\n",
    "        values = []\n",
    "\n",
    "        numeric_features = [not x for x in dataset.get_categorical_indicator()]\n",
    "        numeric_transformer = Pipeline(\n",
    "            steps=[(\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "                   (\"scaler\", StandardScaler())]\n",
    "        )\n",
    "\n",
    "        categorical_transformer = Pipeline(\n",
    "            steps=[\n",
    "                (\"encoder\", OneHotEncoder(\n",
    "                    handle_unknown=\"infrequent_if_exist\", sparse_output=False)),\n",
    "                # (\"selector\", SelectPercentile(chi2, percentile=50)),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        preprocessor = ColumnTransformer(\n",
    "            transformers=[\n",
    "                (\"num\", numeric_transformer, numeric_features),\n",
    "                (\"cat\", categorical_transformer,\n",
    "                 dataset.get_categorical_indicator()),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        for i, (train_index, test_index) in enumerate(split):\n",
    "\n",
    "            if deterministic:\n",
    "                reset_seeds()\n",
    "\n",
    "            X_train = dataset.get_X()[train_index]\n",
    "            Y_train = dataset.get_Y()[train_index]\n",
    "\n",
    "            X_val = dataset.get_X()[test_index]\n",
    "            Y_val = dataset.get_Y()[test_index]\n",
    "\n",
    "            preprocessor.fit(X_train, Y_train)\n",
    "\n",
    "            X_train = preprocessor.transform(X_train)\n",
    "            X_val = preprocessor.transform(X_val)\n",
    "\n",
    "            regressor = KerasRegressor(model=create_model,\n",
    "                                       learning_rate=learning_rate,\n",
    "                                       input_dim=len(\n",
    "                                           X_train[0]),\n",
    "                                       number_layers=number_of_layers,\n",
    "                                       neurons_per_layer=neurons_per_layer,\n",
    "                                       verbose=0)\n",
    "\n",
    "            regressor = TransformedTargetRegressor(regressor=regressor,\n",
    "                                                   transformer=StandardScaler())\n",
    "\n",
    "            regressor.fit(X_train, Y_train, epochs=epochs,\n",
    "                          batch_size=batch_size, shuffle=False)\n",
    "\n",
    "            Y_predicted = regressor.predict(X_val)\n",
    "            # error = sklearn.metrics.mean_absolute_error(Y_predicted, Y_val)\n",
    "            error = sklearn.metrics.mean_absolute_percentage_error(\n",
    "                Y_predicted, Y_val)\n",
    "            values.append(error)\n",
    "\n",
    "            del regressor\n",
    "            K.clear_session()\n",
    "\n",
    "        result = sum(values)/len(values)\n",
    "        return result\n",
    "\n",
    "    def blackboxfunction_grid(params):\n",
    "        # index = int(params[0]*(len(hyperparameterspace_special[\"loss\"])-1))\n",
    "        # hyperparameterspace_special[\"loss\"][index]\n",
    "\n",
    "        epochs = int(params[0])\n",
    "\n",
    "        batch_size = int(params[1])\n",
    "\n",
    "        learning_rate = 1 # params[2]\n",
    "\n",
    "        number_of_layers = 1  # int(params[3])\n",
    "\n",
    "        neurons_per_layer = 40  # int(params[4])\n",
    "\n",
    "        return evaluate_model(epochs, batch_size, learning_rate, number_of_layers, neurons_per_layer)\n",
    "\n",
    "    def blackboxfunction_random(params):\n",
    "        # index = int(params[0]*(len(hyperparameterspace_special[\"loss\"])-1))\n",
    "        # hyperparameterspace_special[\"loss\"][index]\n",
    "\n",
    "        epochs = int(params[0])\n",
    "\n",
    "        batch_size = int(params[1])\n",
    "\n",
    "        learning_rate = 1 # params[2]\n",
    "\n",
    "        number_of_layers = 1  # int(params[3])\n",
    "\n",
    "        neurons_per_layer = 40  # int(params[4])\n",
    "\n",
    "        return evaluate_model(epochs, batch_size, learning_rate, number_of_layers, neurons_per_layer, deterministic=False)\n",
    "\n",
    "    def blackboxfunction_bayesian(params):\n",
    "        # index = int(params[0]*(len(hyperparameterspace_special[\"loss\"])-1))\n",
    "        # hyperparameterspace_special[\"loss\"][index]\n",
    "\n",
    "        epochs = int(params[0])\n",
    "\n",
    "        batch_size = int(params[1])\n",
    "\n",
    "        model_learning_rate = 1 #10 ** (params[2])\n",
    "\n",
    "        number_of_layers = 1  # int(params[3])\n",
    "\n",
    "        neurons_per_layer = 40  # int(params[4])\n",
    "\n",
    "        return evaluate_model(epochs, batch_size, model_learning_rate, number_of_layers, neurons_per_layer, deterministic=False)\n",
    "\n",
    "    ##################### Function for sparse grid search #####################\n",
    "\n",
    "    class ExampleFunction(pysgpp.ScalarFunction):\n",
    "\n",
    "        def __init__(self):\n",
    "            super(ExampleFunction, self).__init__(\n",
    "                len(hyperparameterspace.keys()))\n",
    "\n",
    "        def eval(self, x):\n",
    "            # index = int(x[0]*(len(hyperparameterspace_special[\"loss\"])-1))\n",
    "            # hyperparameterspace_special[\"loss\"][index]\n",
    "\n",
    "            epochs = int(HPO.from_standard(\n",
    "                hyperparameterspace_special[\"epochs\"][0], hyperparameterspace_special[\"epochs\"][1], x[0]))\n",
    "\n",
    "            batch_size = int(HPO.from_standard(\n",
    "                hyperparameterspace_special[\"batch_size\"][0], hyperparameterspace_special[\"batch_size\"][1], x[1]))\n",
    "\n",
    "            # HPO.from_standard_log(hyperparameterspace_special[\"learning_rate\"][\n",
    "            model_learning_rate = 1\n",
    "            #                  0], hyperparameterspace_special[\"learning_rate\"][1], x[2])\n",
    "\n",
    "            number_of_layers = 1  # int(HPO.from_standard(\n",
    "            # hyperparameterspace_special[\"number_layers\"][0], hyperparameterspace_special[\"number_layers\"][1], x[3]))\n",
    "\n",
    "            neurons_per_layer = 40  # int(HPO.from_standard(\n",
    "            # hyperparameterspace_special[\"neurons_per_layer\"][0], hyperparameterspace_special[\"neurons_per_layer\"][1], x[4]))\n",
    "\n",
    "            return evaluate_model(epochs, batch_size, model_learning_rate, number_of_layers, neurons_per_layer)\n",
    "\n",
    "    ##### For each dataset: run models with different budget #####\n",
    "    for BUDGET in BUDGETS:\n",
    "\n",
    "        print(\"\\n################################################## Current Budget:\",\n",
    "              BUDGET, \"##################################################\")\n",
    "\n",
    "        ############################## GRID SEARCH #######################\n",
    "        grid_sizes = [x ** len(hyperparameterspace) for x in range(9)]\n",
    "        if BUDGET in grid_sizes:\n",
    "            print(\"\\nPerforming grid search\")\n",
    "            optimization = HPO.GridSearchOptimization(\n",
    "                dataset, blackboxfunction_grid, hyperparameterspace, budget=BUDGET, verbosity=VERBOSE, cv=CV)\n",
    "\n",
    "            result, cost = optimization.fit()\n",
    "\n",
    "            index_best = 0\n",
    "            for m in range(len(result)):\n",
    "                if result[m][1] < result[index_best][1]:\n",
    "                    index_best = m\n",
    "\n",
    "            best_score = result[index_best][1]\n",
    "            best_params = result[index_best][0]\n",
    "\n",
    "            if VERBOSE > 0:\n",
    "                print(\"With Hyperparameters: \")\n",
    "                m = 0\n",
    "                for key in hyperparameterspace.keys():\n",
    "                    if hyperparameterspace[key][0] == \"list\":\n",
    "                        index = int(\n",
    "                            best_params[m]*(len(hyperparameterspace_special[key])-1))\n",
    "                        print(key + \": \" +\n",
    "                              str(hyperparameterspace_special[key][index]))\n",
    "                    else:\n",
    "                        print(key + \": \" + str(best_params[m]))\n",
    "                    m += 1\n",
    "\n",
    "            print(\"Best score with Grid search:\", best_score)\n",
    "\n",
    "            current_dataset_grid.append(best_score)\n",
    "            current_dataset_grid_cost.append(cost)\n",
    "\n",
    "            K.clear_session()\n",
    "\n",
    "        # ########################### RANDOM SEARCH #######################\n",
    "        print(\"\\nPerforming random search\")\n",
    "\n",
    "        optimization = HPO.RandomSearchOptimization(\n",
    "            dataset, blackboxfunction_random, hyperparameterspace, budget=BUDGET, verbosity=VERBOSE, cv=CV)\n",
    "\n",
    "        result, cost = optimization.fit()\n",
    "\n",
    "        index_best = 0\n",
    "        for m in range(len(result)):\n",
    "            if result[m][1] < result[index_best][1]:\n",
    "                index_best = m\n",
    "\n",
    "        best_score = result[index_best][1]\n",
    "        best_params = result[index_best][0]\n",
    "\n",
    "        if VERBOSE > 0:\n",
    "            print(\"With Hyperparameters: \")\n",
    "            m = 0\n",
    "            for key in hyperparameterspace.keys():\n",
    "                if hyperparameterspace[key][0] == \"list\":\n",
    "                    index = int(\n",
    "                        best_params[m]*(len(hyperparameterspace_special[key])-1))\n",
    "                    print(key + \": \" +\n",
    "                          str(hyperparameterspace_special[key][index]))\n",
    "                else:\n",
    "                    print(key + \": \" + str(best_params[m]))\n",
    "                m += 1\n",
    "\n",
    "        print(\"Best score with Random search:\", best_score)\n",
    "\n",
    "        current_dataset_random.append(best_score)\n",
    "        current_dataset_random_cost.append(cost)\n",
    "\n",
    "        K.clear_session()\n",
    "\n",
    "        ########################### BAYESIAN OPT #####################\n",
    "        print(\"\\nPerforming bayesian optimization\")\n",
    "\n",
    "        optimization = HPO.BayesianOptimization(\n",
    "            dataset, blackboxfunction_bayesian, hyperparameterspace, budget=BUDGET, verbosity=VERBOSE)\n",
    "\n",
    "        result, cost = optimization.fit()\n",
    "\n",
    "        index_best = 0\n",
    "        for m in range(len(result)):\n",
    "            if result[m][1] < result[index_best][1]:\n",
    "                index_best = m\n",
    "\n",
    "        best_score = result[index_best][1]\n",
    "        best_params = result[index_best][0]\n",
    "\n",
    "        if VERBOSE > 0:\n",
    "            print(\"With Hyperparameters: \")\n",
    "            m = 0\n",
    "            for key in hyperparameterspace.keys():\n",
    "                if hyperparameterspace[key][0] == \"list\":\n",
    "                    index = int(\n",
    "                        best_params[m]*(len(hyperparameterspace_special[key])-1))\n",
    "                    print(key + \": \" +\n",
    "                          str(hyperparameterspace_special[key][index]))\n",
    "                elif hyperparameterspace[key][0] == \"interval-log\":\n",
    "                    print(key + \": \" + str(10 ** best_params[m]))\n",
    "                else:\n",
    "                    print(key + \": \" + str(best_params[m]))\n",
    "                m += 1\n",
    "\n",
    "        print(\"Best score with Bayesian Optimization:\", best_score)\n",
    "\n",
    "        current_dataset_bayesian.append(best_score)\n",
    "        current_dataset_bayesian_cost.append(BUDGET)\n",
    "\n",
    "        K.clear_session()\n",
    "\n",
    "        ########################### SPARSE OPT ############################\n",
    "\n",
    "        costs_sparse = [1]\n",
    "        for _ in range(40):\n",
    "            costs_sparse.append(costs_sparse[-1]+2*len(hyperparameterspace))\n",
    "\n",
    "        #if BUDGET in costs_sparse:\n",
    "        print(\"\\nPerforming sparse search\")\n",
    "\n",
    "        f = ExampleFunction()\n",
    "\n",
    "        optimization = HPO.SparseGridSearchOptimization(\n",
    "            dataset, f, hyperparameterspace, budget=BUDGET, verbosity=VERBOSE, degree=SPARSE_PARAMS[0], adaptivity=SPARSE_PARAMS[1], optimizer=SPARSE_PARAMS[2])\n",
    "\n",
    "        result = optimization.fit()\n",
    "\n",
    "        print(\"Best score with Sparse Search:\",\n",
    "                result[0][1], \"optimized:\", result[0][3])\n",
    "\n",
    "        current_dataset_sparse.append(result[0][1])\n",
    "        current_dataset_sparse_opt.append(result[0][3])\n",
    "\n",
    "        current_dataset_sparse_cost.append(result[1])\n",
    "        current_dataset_sparse_opt_cost.append(result[1]+1)\n",
    "\n",
    "        K.clear_session()\n",
    "\n",
    "        print(current_dataset_grid)\n",
    "        print(current_dataset_random)\n",
    "        print(current_dataset_bayesian)\n",
    "        print(current_dataset_sparse)\n",
    "        print(current_dataset_sparse_opt)\n",
    "\n",
    "    GRID_RESULT.append(current_dataset_grid)\n",
    "    RANDOM_RESULT.append(current_dataset_random)\n",
    "    BAYESIAN_RESULT.append(current_dataset_bayesian)\n",
    "    SPARSE_RESULT.append(current_dataset_sparse)\n",
    "    SPARSE_RESULT_OPTIMIZED.append(current_dataset_sparse_opt)\n",
    "\n",
    "    GRID_COST.append(current_dataset_grid_cost)\n",
    "    RANDOM_COST.append(current_dataset_random_cost)\n",
    "    BAYESIAN_COST.append(current_dataset_bayesian_cost)\n",
    "    SPARSE_COST.append(current_dataset_sparse_cost)\n",
    "    SPARSE_COST_OPTIMIZED.append(current_dataset_sparse_opt_cost)\n",
    "\n",
    "    print(\"###################### Current dataset\",\n",
    "          ids[i], \"######################\")\n",
    "\n",
    "    dataset = HPO.Dataset(task_id=ids[i])\n",
    "\n",
    "    print(\"Target average:\", sum(\n",
    "        dataset.get_Y()/len(dataset.get_Y())))\n",
    "    print(\"Min target:\", min(dataset.get_Y()),\n",
    "          \"Max target:\", max(dataset.get_Y()))\n",
    "\n",
    "    # plotting the points\n",
    "    plt.plot(GRID_COST[i], GRID_RESULT[i], '.-',\n",
    "             color='black', label=\"Grid search\")\n",
    "    plt.plot(RANDOM_COST[i], RANDOM_RESULT[i], '.-',\n",
    "             color='red', label=\"Random search\")\n",
    "    plt.plot(BAYESIAN_COST[i], BAYESIAN_RESULT[i], '.-',\n",
    "             color='blue', label=\"Bayesian Optimization\")\n",
    "    plt.plot(SPARSE_COST[i], SPARSE_RESULT[i], '.-',\n",
    "             color='purple', label=\"Sparse Grid search\")\n",
    "    plt.plot(SPARSE_COST_OPTIMIZED[i], SPARSE_RESULT_OPTIMIZED[i],\n",
    "             '.-', color='pink', label=\"Sparse Grid search (opt)\")\n",
    "\n",
    "    # naming the x axis\n",
    "    plt.xlabel('Function evaluations')\n",
    "    # naming the y axis\n",
    "    plt.ylabel('Mean absolute percentage')\n",
    "\n",
    "    # show a legend on the plot\n",
    "    plt.legend()\n",
    "\n",
    "    plt.savefig(DIRECTORY + \"/task_id\" + str(ids[i]))\n",
    "    # function to show the plot\n",
    "    plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(ids)):\n",
    "    print(\"###################### Current dataset\", ids[i], \"######################\")\n",
    "    \n",
    "    dataset = HPO.Dataset(task_id=ids[i])\n",
    "    \n",
    "    print(\"Target average:\", sum(\n",
    "        dataset.get_Y()/len(dataset.get_Y())))\n",
    "    print(\"Min target:\", min(dataset.get_Y()),\n",
    "          \"Max target:\", max(dataset.get_Y()))\n",
    "\n",
    "\n",
    "    # plotting the points \n",
    "    plt.plot(GRID_COST[i], GRID_RESULT[i], '.-', color='black', label=\"Grid search\")\n",
    "    plt.plot(RANDOM_COST[i], RANDOM_RESULT[i], '.-', color='red', label=\"Random search\")\n",
    "    plt.plot(BAYESIAN_COST[i], BAYESIAN_RESULT[i], '.-', color='blue', label=\"Bayesian Optimization\")\n",
    "    plt.plot(SPARSE_COST[i], SPARSE_RESULT[i], '.-', color='purple', label=\"Sparse Grid search\")\n",
    "    plt.plot(SPARSE_COST_OPTIMIZED[i], SPARSE_RESULT_OPTIMIZED[i], '.-', color='pink', label=\"Sparse Grid search (opt)\")\n",
    "    \n",
    "    # naming the x axis\n",
    "    plt.xlabel('Function evaluations')\n",
    "    # naming the y axis\n",
    "    plt.ylabel('Mean absolute percentage')\n",
    "    \n",
    "    # show a legend on the plot\n",
    "    plt.legend()\n",
    "    \n",
    "    # function to show the plot\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
