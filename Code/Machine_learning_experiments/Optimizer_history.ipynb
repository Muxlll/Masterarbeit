{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline experiment\n",
    "\n",
    "Experiment to compare the 4 Optimization algorithms before trying to improve sparse search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-02 09:04:41.824219: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-02 09:04:43.224340: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import sys  \n",
    "sys.path.insert(0, '../')\n",
    "\n",
    "import HPO\n",
    "import pysgpp\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import sklearn.metrics\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from scikeras.wrappers import KerasRegressor\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.compose import TransformedTargetRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.feature_selection import SelectPercentile, chi2\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from numpy.random import seed\n",
    "import random\n",
    "import time\n",
    "import os\n",
    "import math\n",
    "from matplotlib import cm\n",
    "import matplotlib \n",
    "\n",
    "matplotlib.use(\"pgf\")\n",
    "matplotlib.rcParams.update({\n",
    "    \"pgf.texsystem\": \"pdflatex\",\n",
    "    'font.family': 'serif',\n",
    "    'text.usetex': True,\n",
    "    'pgf.rcfonts': False,\n",
    "})\n",
    "\n",
    "random.seed(1)\n",
    "seed(2)\n",
    "tf.random.set_seed(3)\n",
    "\n",
    "def reset_seeds():\n",
    "    np.random.seed(1)\n",
    "    random.seed(2)\n",
    "    tf.random.set_seed(3)\n",
    "\n",
    "VERBOSE = 0\n",
    "\n",
    "SPARSE_RESULT = []\n",
    "SPARSE_RESULT_OPTIMIZED = []\n",
    "\n",
    "SPARSE_COST = []\n",
    "SPARSE_COST_OPTIMIZED = []"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model creation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(learning_rate=0.0001, input_dim=10, number_layers=1, neurons_per_layer=20):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(neurons_per_layer, input_shape=(input_dim,), activation='relu'))\n",
    "    for _ in range(number_layers):\n",
    "        model.add(Dense(neurons_per_layer, activation='relu'))\n",
    "    model.add(Dense(1, activation=None))\n",
    "\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "    model.compile(loss='mean_squared_error', optimizer=optimizer)\n",
    "    return model\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameterspace = {\n",
    "    'epochs': [\"interval-int\", 1, 40],\n",
    "    #'batch_size': [\"interval-int\", 1, 200],\n",
    "    'learning rate': [\"interval-log\", 1e-10, 1e-1],\n",
    "    #'number_layers': [\"interval-int\", 1, 20],\n",
    "    #'neurons_per_layer': [\"interval-int\", 1, 50]\n",
    "}\n",
    "\n",
    "hyperparameterspace_special = {}\n",
    "for key in hyperparameterspace.keys():\n",
    "    liste = []\n",
    "    for i in range(1, len(hyperparameterspace[key])):\n",
    "        liste.append(hyperparameterspace[key][i])\n",
    "    hyperparameterspace_special[key] = liste"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adaptive grid generation (Ritter-Novak)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-02 09:04:46.370410: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done in 95547ms.\n",
      "Solving linear system (automatic method)...\n",
      "Done in 0ms.\n",
      "Before Optimization:\n",
      "Epochs: 30.25\n",
      "Learning rate: 3.162277660168379e-06\n",
      "Function value: 0.7287221550941467\n",
      "Optimizing (gradient descent)...\n",
      "####  Local optimal point:\n",
      "40.0\n",
      "3.162277660168379e-06\n",
      "Done in 0ms.\n",
      "Optimal point evaluated: 0.6684863269329071\n",
      "Optimal point interpolated: 0.6702930331230164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maxi/Repos/Masterarbeit/Code/Machine_learning_experiments/../HPO.py:1028: UserWarning: Matplotlib is currently using pgf, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/tmp/ipykernel_20300/3432258698.py:143: UserWarning: Matplotlib is currently using pgf, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adaptive grid generation (Ritter-Novak)...\n",
      "Done in 199870ms.\n",
      "Solving linear system (automatic method)...\n",
      "Done in 0ms.\n",
      "Before Optimization:\n",
      "Epochs: 30.25\n",
      "Learning rate: 0.0005623413251903491\n",
      "Function value: 0.3527909889817238\n",
      "Optimizing (gradient descent)...\n",
      "####  Local optimal point:\n",
      "39.999995027074235\n",
      "0.09999971402022596\n",
      "Done in 0ms.\n",
      "Optimal point evaluated: 1.2569370865821838\n",
      "Optimal point interpolated: -0.9501413460066046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maxi/Repos/Masterarbeit/Code/Machine_learning_experiments/../HPO.py:1028: UserWarning: Matplotlib is currently using pgf, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/tmp/ipykernel_20300/3432258698.py:143: UserWarning: Matplotlib is currently using pgf, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adaptive grid generation (Ritter-Novak)...\n",
      "Done in 555861ms.\n",
      "Solving linear system (automatic method)...\n",
      "Done in 0ms.\n",
      "Before Optimization:\n",
      "Epochs: 27.8125\n",
      "Learning rate: 0.0005623413251903491\n",
      "Function value: 0.32599571347236633\n",
      "Optimizing (gradient descent)...\n",
      "####  Local optimal point:\n",
      "27.8125\n",
      "0.0005623413251903491\n",
      "Done in 0ms.\n",
      "Optimal point evaluated: 0.32599571347236633\n",
      "Optimal point interpolated: 0.32599571347236633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maxi/Repos/Masterarbeit/Code/Machine_learning_experiments/../HPO.py:1028: UserWarning: Matplotlib is currently using pgf, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/tmp/ipykernel_20300/3432258698.py:143: UserWarning: Matplotlib is currently using pgf, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adaptive grid generation (Ritter-Novak)...\n",
      "Done in 881875ms.\n",
      "Solving linear system (automatic method)...\n",
      "Done in 1ms.\n",
      "Before Optimization:\n",
      "Epochs: 20.5\n",
      "Learning rate: 0.00021287516617963725\n",
      "Function value: 0.2671877220273018\n",
      "Optimizing (gradient descent)...\n",
      "Done in 0ms.\n",
      "####  Local optimal point:\n",
      "21.71874998517095\n",
      "0.0209375113902317\n",
      "Optimal point evaluated: 0.5238737538456917\n",
      "Optimal point interpolated: -0.24662736027568488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maxi/Repos/Masterarbeit/Code/Machine_learning_experiments/../HPO.py:1028: UserWarning: Matplotlib is currently using pgf, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n",
      "/tmp/ipykernel_20300/3432258698.py:143: UserWarning: Matplotlib is currently using pgf, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "\n",
    "################## MODEL AND FUNCTION DEFINITION ####################\n",
    "CV = 2\n",
    "dataset = HPO.Dataset(task_id=233211)\n",
    "\n",
    "def evaluate_model(epochs, batch_size, learning_rate, number_of_layers, neurons_per_layer, deterministic=True):\n",
    "    # sum = 0\n",
    "    # sum += epochs ** 2 - 10 * math.cos(2 * math.pi * epochs)\n",
    "    # sum += learning_rate ** 2 - 10 * math.cos(2 * math.pi * learning_rate)\n",
    "    # # sum += learning_rate ** 2 - 10 * math.cos(2 * math.pi * learning_rate)\n",
    "    # # sum += number_of_layers ** 2 - 10 * math.cos(2 * math.pi * number_of_layers)\n",
    "    # # sum += neurons_per_layer ** 2 - 10 * math.cos(2 * math.pi * neurons_per_layer)\n",
    "    # return len(hyperparameterspace) * 10 + sum\n",
    "\n",
    "    # sum = 0\n",
    "    # sum += (1-epochs)**2 + 100 * (learning_rate - epochs**2) ** 2\n",
    "    # return sum\n",
    "    #return epochs\n",
    "\n",
    "    kfold = KFold(n_splits=CV)\n",
    "\n",
    "    split = (kfold.split(dataset.get_X(), dataset.get_Y()))\n",
    "\n",
    "    values = []\n",
    "\n",
    "    numeric_features = [not x for x in dataset.get_categorical_indicator()]\n",
    "    numeric_transformer = Pipeline(\n",
    "        steps=[(\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "                (\"scaler\", StandardScaler())]\n",
    "    )\n",
    "\n",
    "    categorical_transformer = Pipeline(\n",
    "        steps=[\n",
    "            (\"encoder\", OneHotEncoder(\n",
    "                handle_unknown=\"infrequent_if_exist\", sparse_output=False)),\n",
    "            # (\"selector\", SelectPercentile(chi2, percentile=50)),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"num\", numeric_transformer, numeric_features),\n",
    "            (\"cat\", categorical_transformer,\n",
    "                dataset.get_categorical_indicator()),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    for i, (train_index, test_index) in enumerate(split):\n",
    "\n",
    "        if deterministic:\n",
    "            reset_seeds()\n",
    "\n",
    "        X_train = dataset.get_X()[train_index]\n",
    "        Y_train = dataset.get_Y()[train_index]\n",
    "\n",
    "        X_val = dataset.get_X()[test_index]\n",
    "        Y_val = dataset.get_Y()[test_index]\n",
    "\n",
    "        preprocessor.fit(X_train, Y_train)\n",
    "\n",
    "        X_train = preprocessor.transform(X_train)\n",
    "        X_val = preprocessor.transform(X_val)\n",
    "\n",
    "        regressor = KerasRegressor(model=create_model,\n",
    "                                    learning_rate=learning_rate,\n",
    "                                    input_dim=len(\n",
    "                                        X_train[0]),\n",
    "                                    number_layers=number_of_layers,\n",
    "                                    neurons_per_layer=neurons_per_layer,\n",
    "                                    verbose=0)\n",
    "\n",
    "        regressor = TransformedTargetRegressor(regressor=regressor,\n",
    "                                                transformer=StandardScaler())\n",
    "\n",
    "        regressor.fit(X_train, Y_train, epochs=int(epochs),\n",
    "                        batch_size=int(batch_size), shuffle=False)\n",
    "\n",
    "        Y_predicted = regressor.predict(X_val)\n",
    "        # error = sklearn.metrics.mean_absolute_error(Y_predicted, Y_val)\n",
    "        error = sklearn.metrics.mean_absolute_percentage_error(\n",
    "            Y_predicted, Y_val)\n",
    "        values.append(error)\n",
    "\n",
    "        del regressor\n",
    "        K.clear_session()\n",
    "\n",
    "    result = sum(values)/len(values)\n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "class ExampleFunction(pysgpp.ScalarFunction):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(ExampleFunction, self).__init__(\n",
    "            len(hyperparameterspace.keys()))\n",
    "\n",
    "    def eval(self, x):\n",
    "        epochs = int(HPO.from_standard(\n",
    "            hyperparameterspace_special[\"epochs\"][0], hyperparameterspace_special[\"epochs\"][1], x[0]))\n",
    "\n",
    "        batch_size = 100 \n",
    "\n",
    "        model_learning_rate = HPO.from_standard_log(\n",
    "            hyperparameterspace_special[\"learning rate\"][0], hyperparameterspace_special[\"learning rate\"][1], x[1])\n",
    "\n",
    "        number_of_layers = 1\n",
    "\n",
    "        neurons_per_layer = 30\n",
    "\n",
    "        return evaluate_model(epochs, batch_size, model_learning_rate, number_of_layers, neurons_per_layer)\n",
    "\n",
    "BUDGETS = [5, 10, 30, 50]\n",
    "\n",
    "\n",
    "for budget in BUDGETS:\n",
    "\n",
    "    optimizer = HPO.SparseGridSearchOptimization(dataset, ExampleFunction(), hyperparameterspace, budget, verbosity=0, degree=2, adaptivity=0.85)\n",
    "    optimizer = optimizer.fit()\n",
    "\n",
    "    x = []\n",
    "    y = []\n",
    "    history_points = optimizer.getHistoryOfOptimalPoints()\n",
    "    for i in range(history_points.getNrows()):\n",
    "        vec = pysgpp.DataVector(history_points.getNcols())\n",
    "        history_points.getRow(i, vec)\n",
    "        x.append(vec[0])\n",
    "        y.append(vec[1])\n",
    "\n",
    "    # fig, ax = plt.subplots()\n",
    "    # img = plt.imread(\"function.png\")\n",
    "    # ax.imshow(img, extent=[0, 1, 0, 1])\n",
    "    # plt.plot(x, y, color=\"white\")\n",
    "\n",
    "    # # naming the x axis\n",
    "    # plt.xlabel('x')\n",
    "    # # naming the y axis\n",
    "    # plt.ylabel('y')\n",
    "\n",
    "    # plt.xlim([0,1])\n",
    "    # plt.ylim([0,1])\n",
    "\n",
    "    # function to show the plot\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
