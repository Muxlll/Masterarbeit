{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dabb667d",
   "metadata": {},
   "source": [
    "# Hyperparameteroptimization\n",
    "\n",
    "https://github.com/SGpp/SGpp/blob/master/optimization/examples/optimization.py\n",
    "\n",
    "Steps:\n",
    "   1. Definition of the data\n",
    "   2. Definition of the hyperparameter space\n",
    "   3. Loop over all different combinations of the hyperparamter space\n",
    "       1. Define the model with the hyperparameters\n",
    "       2. Optimize model (learning phase)\n",
    "       3. Evaluate model and store metric with the parameters\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e6368f",
   "metadata": {},
   "source": [
    "## 0. Imports & utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "254923fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import torch\n",
    "from sklearn import svm, metrics\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "import timeit\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import itertools\n",
    "\n",
    "from mpl_toolkits import mplot3d\n",
    "\n",
    "\n",
    "from scipy.io import arff\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time, sys\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import pysgpp\n",
    "\n",
    "from bayes_opt import BayesianOptimization, UtilityFunction\n",
    "\n",
    "\n",
    "def update_progress(progress, time, remaining_time):\n",
    "    bar_length = 20\n",
    "    if isinstance(progress, int):\n",
    "        progress = float(progress)\n",
    "    if not isinstance(progress, float):\n",
    "        progress = 0\n",
    "    if progress < 0:\n",
    "        progress = 0\n",
    "    if progress >= 1:\n",
    "        progress = 1\n",
    "\n",
    "    block = int(round(bar_length * progress))\n",
    "    clear_output(wait = True)\n",
    "    text = \"Progress: [{0}] {1:.1f}%\".format( \"#\" * block + \"-\" * (bar_length - block), progress * 100)\n",
    "    text += \"\\nCurrent time per iteration: \" + str(time)\n",
    "    text += \"\\nApprox. time remaining: \" + str(remaining_time)\n",
    "    print(text)\n",
    "\n",
    "    \n",
    "def to_standard(lower, upper, value):\n",
    "    return (value-lower)/(upper-lower)\n",
    "\n",
    "\n",
    "def from_standard(lower, upper, value):\n",
    "    return value*(upper-lower)+lower"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "390510ac",
   "metadata": {},
   "source": [
    "## 1. Definition of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59d6d9fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples:  748\n"
     ]
    }
   ],
   "source": [
    "SPLIT_RATIO = 0.8\n",
    "\n",
    "data = arff.loadarff('php0iVrYT.arff')\n",
    "df = pd.DataFrame(data[0])\n",
    "\n",
    "df['Class'].replace([b'1', b'2'], [1, 2], inplace=True)\n",
    "\n",
    "X = []\n",
    "Y = []\n",
    "\n",
    "for i in range(len(df)):\n",
    "    data = []\n",
    "    data.append(df['V1'][i])\n",
    "    data.append(df['V2'][i])\n",
    "    data.append(df['V3'][i])\n",
    "    data.append(df['V4'][i])\n",
    "    \n",
    "    X.append(data)\n",
    "    Y.append(df['Class'][i])\n",
    "\n",
    "print(\"Number of samples: \", len(X))\n",
    "\n",
    "X, Y = shuffle(X, Y)\n",
    "X = np.array(X[:740])\n",
    "Y = np.array(Y[:740])\n",
    "\n",
    "# 10 fold validation:\n",
    "size_chunks = int(len(X)/10)\n",
    "X_folds = [X[x:x+size_chunks] for x in range(0, len(X)-size_chunks, size_chunks)]\n",
    "Y_folds = [Y[x:x+size_chunks] for x in range(0, len(Y)-size_chunks, size_chunks)]\n",
    "\n",
    "#X_train = torch.Tensor(X[:int(len(X) * SPLIT_RATIO)])\n",
    "#X_test = torch.Tensor(X[int(len(X) * SPLIT_RATIO):])\n",
    "#Y_train = torch.Tensor(Y[:int(len(Y) * SPLIT_RATIO)])\n",
    "#Y_test = torch.Tensor(Y[int(len(Y) * SPLIT_RATIO):])\n",
    "\n",
    "#print(\"Number of training samples: \", len(X_train))\n",
    "#print(\"Number of testing samples: \", len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "573e7eb2",
   "metadata": {},
   "source": [
    "## 2. Definition of Hyperparameter space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2e13b83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of hyperparameters:  5\n"
     ]
    }
   ],
   "source": [
    "hyperparameters = {\n",
    "    \"C\" : [0, 10],\n",
    "    \"kernel\" : [1, 5], #[\"set\", \"linear\", \"poly\", \"rbf\", \"sigmoid\", \"precomputed\"],\n",
    "    \"degree\" : [1, 5],\n",
    "    \"gamma\" : [1, 3], #[\"set\", \"scale\", \"auto\"],\n",
    "    \"tol\" : [0.000001, 0.1]\n",
    "}\n",
    "\n",
    "print(\"Number of hyperparameters: \", len(hyperparameters))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6abe03cd",
   "metadata": {},
   "source": [
    "## 3. Loop over combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380997d8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adaptive grid generation (Ritter-Novak)...\n"
     ]
    }
   ],
   "source": [
    "class ExampleFunction(pysgpp.ScalarFunction):\n",
    "    \"\"\"Example objective function from the title of my Master's thesis.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super(ExampleFunction, self).__init__(2)\n",
    "\n",
    "\n",
    "    def eval(self, x):\n",
    "        \n",
    "        C = x[0]\n",
    "        kernel = x[1]\n",
    "        degree = x[2]\n",
    "        gamma = x[3]\n",
    "        tol = x[4]\n",
    "        \n",
    "        if kernel < 0.2:\n",
    "            kernel = \"linear\"\n",
    "        elif kernel < 0.4:\n",
    "            kernel = \"poly\"\n",
    "        elif kernel < 0.6:\n",
    "            kernel = \"rbf\"\n",
    "        elif kernel < 0.8:\n",
    "            kernel = \"sigmoid\"\n",
    "        elif kernel <= 1:\n",
    "            kernel = \"precomputed\"\n",
    "        \n",
    "        if gamma < 0.5:\n",
    "            gamma = \"scale\"\n",
    "        elif gamma <= 1:\n",
    "            gamma = \"auto\"\n",
    "        \n",
    "        classifier = svm.SVC(C=C, kernel=kernel, degree=int(degree), gamma=gamma, tol=tol)\n",
    "        \n",
    "        scores = cross_val_score(classifier, X, Y, cv=10)\n",
    "        \n",
    "        accuracy = scores.mean()\n",
    "        return -accuracy\n",
    "################################## generate Grid ##################################\n",
    "\n",
    "pysgpp.omp_set_num_threads(1)\n",
    "\n",
    "f = ExampleFunction()\n",
    "# dimension of domain\n",
    "d = f.getNumberOfParameters()\n",
    "# B-spline degree\n",
    "p = 4\n",
    "# maximal number of grid points\n",
    "N = 10\n",
    "# adaptivity of grid generation\n",
    "gamma = 0.9\n",
    "\n",
    "\n",
    "grid = pysgpp.Grid.createModBsplineGrid(d, p)\n",
    "gridGen = pysgpp.OptIterativeGridGeneratorRitterNovak(f, grid, N, gamma)\n",
    "\n",
    "functionValues = gridGen.getFunctionValues()\n",
    "\n",
    "if not gridGen.generate():\n",
    "    print(\"Grid generation failed, exiting.\")\n",
    "    sys.exit(1)\n",
    "\n",
    "gridStorage = grid.getStorage()\n",
    "\n",
    "x_values = []\n",
    "y_values = []\n",
    "for i in range(gridStorage.getSize()):\n",
    "    gp = gridStorage.getPoint(i)\n",
    "    x_values.append(gp.getStandardCoordinate(0)) \n",
    "    y_values.append(gp.getStandardCoordinate(1))\n",
    "    \n",
    "    \n",
    "plt.plot(x_values, y_values, 'bo')\n",
    "\n",
    "######################################## grid functions ########################################\n",
    "# Hierarchization\n",
    "functionValues = gridGen.getFunctionValues()\n",
    "coeffs = pysgpp.DataVector(len(functionValues))\n",
    "hierSLE = pysgpp.HierarchisationSLE(grid)\n",
    "sleSolver = pysgpp.AutoSLESolver()\n",
    "\n",
    "if not sleSolver.solve(hierSLE, gridGen.getFunctionValues(), coeffs):\n",
    "    print(\"Solving failed, exiting.\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# define interpolant and gradient\n",
    "ft = pysgpp.InterpolantScalarFunction(grid, coeffs)\n",
    "ftGradient = pysgpp.InterpolantScalarFunctionGradient(grid, coeffs)\n",
    "gradientDescent = pysgpp.OptGradientDescent(ft, ftGradient)\n",
    "x0 = pysgpp.DataVector(d)\n",
    "\n",
    "##################### find point with minimal loss (which are already evaluated) #################\n",
    "\n",
    "# find point with smallest value as start point for gradient descent\n",
    "x0Index = 0\n",
    "fX0 = functionValues[0]\n",
    "for i in range(1, len(functionValues)):\n",
    "    if functionValues[i] < fX0:\n",
    "        fX0 = functionValues[i]\n",
    "        x0Index = i\n",
    "\n",
    "x0 = gridStorage.getCoordinates(gridStorage.getPoint(x0Index));\n",
    "ftX0 = ft.eval(x0)\n",
    "\n",
    "print(\"\\nOptimal hyperparameters so far:\")\n",
    "print(\"Epochs: \", from_standard(1,300,x0[1]))\n",
    "print(\"learning_rate: \", from_standard(0.00001,0.01,x0[0]))\n",
    "\n",
    "print(\"Resulting loss:\")\n",
    "print(ftX0)\n",
    "\n",
    "################################## Optimize with gradient descent ##################################\n",
    "#print(\"x0 = {}\".format(x0))\n",
    "#print(\"f(x0) = {:.6g}, ft(x0) = {:.6g}\\n\".format(fX0, ftX0))\n",
    "\n",
    "## We apply the gradient method and print the results.\n",
    "gradientDescent.setStartingPoint(x0)\n",
    "gradientDescent.optimize()\n",
    "xOpt = gradientDescent.getOptimalPoint()\n",
    "ftXOpt = gradientDescent.getOptimalValue()\n",
    "\n",
    "print(xOpt)\n",
    "fXOpt = f.eval(xOpt)\n",
    "\n",
    "print(\"\\nOptimal hyperparameters after optimization:\")\n",
    "print(\"Epochs: \", from_standard(1,300,xOpt[1]))\n",
    "print(\"learning_rate: \", from_standard(0.00001,0.01,xOpt[0]))\n",
    "print(\"Resulting loss (Optimal value from optimization):\")\n",
    "print(ftXOpt)\n",
    "print(\"Resulting loss (Optimal point evaluated):\")\n",
    "print(fXOpt)\n",
    "#print(\"\\nxOpt = {}\".format(xOpt))\n",
    "#print(\"f(xOpt) = {:.6g}, ft(xOpt) = {:.6g}\\n\".format(fXOpt, ftXOpt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68bd419d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
