\babel@toc {american}{}\relax 
\addvspace {10\p@ }
\addvspace {10\p@ }
\addvspace {10\p@ }
\contentsline {figure}{\numberline {2.1}{\ignorespaces Neural network consisting of only one perceptron. \relax }}{3}{figure.caption.4}%
\contentsline {figure}{\numberline {2.2}{\ignorespaces Neural network consisting of two hidden layers. Taken from \blx@tocontentsinit {0}\cite {da2017artificial}. \relax }}{3}{figure.caption.5}%
\contentsline {figure}{\numberline {2.3}{\ignorespaces Comparison of grid search (left) and random search (right) in the two dimensional case. For both techniques, 9 different combinations are evaluated. In the left case, only 3 distinct values for each hyperparameter are set whereas there are 9 different values for each parameter in the random search. Taken from \blx@tocontentsinit {0}\cite {feurer2019hyperparameter}. \relax }}{6}{figure.caption.6}%
\contentsline {figure}{\numberline {2.4}{\ignorespaces Schematic iteration steps of the bayesian optimization. The maximum of the acquisition function determines the next function evaluation (red dot in the middle). The goal is to find the minimum of the dashed line. The blue band is the uncertainty of the function. Taken from \blx@tocontentsinit {0}\cite {feurer2019hyperparameter}. \relax }}{9}{figure.caption.7}%
\contentsline {figure}{\numberline {2.5}{\ignorespaces Interpolation of the function $ f $ (black line) by its interpolant $ u $ (red, dashed) in the nodal basis. Level of the grid is 3 and hat functions are used. Taken from \blx@tocontentsinit {0}\cite {pfluger2010spatially}. \relax }}{11}{figure.caption.8}%
\contentsline {figure}{\numberline {2.6}{\ignorespaces Hierarchical subspaces up to level 3 on the left. On the right, nodal spaces up to level 3. The combination of $ W_1 $ up to $ W_3 $ is the same space as $ V_3 $. Taken from \blx@tocontentsinit {0}\cite {pfluger2010spatially}. \relax }}{12}{figure.caption.9}%
\contentsline {figure}{\numberline {2.7}{\ignorespaces Interpolation of the function $ f $ (black line) by its interpolant $ u $ (red, dashed) in the hierarchical basis. Level of the grid is 3 and hat functions are used. Taken from \blx@tocontentsinit {0}\cite {pfluger2010spatially}.\relax }}{13}{figure.caption.10}%
\contentsline {figure}{\numberline {2.8}{\ignorespaces Example of a basis function in two dimensions. It is constructed with the tensor product of two 1d hat functions. Taken from \blx@tocontentsinit {0}\cite {garcke2013sparse}. \relax }}{14}{figure.caption.11}%
\contentsline {figure}{\numberline {2.9}{\ignorespaces Two dimensional example of a sparse grid with $ n = 3 $. Left, the subspaces $ W_{\vec {l}} $ can be seen and on the right is the resulting sparse grid. Taken from \blx@tocontentsinit {0}\cite {garcke2013sparse}. \relax }}{15}{figure.caption.12}%
\contentsline {figure}{\numberline {2.10}{\ignorespaces Example of the 2-dimensional combination technique. Here the blue regular grids are added and the red ones are subtracted. On the left, the normal combination technique can be seen and on the right is an dimension-adaptive version. Taken from \blx@tocontentsinit {0}\cite {pfluger2010spatially}. \relax }}{16}{figure.caption.13}%
\contentsline {figure}{\numberline {2.11}{\ignorespaces Example of the spatially adaptive combination technique in two dimensions. Taken from \blx@tocontentsinit {0}\cite {obersteiner2021generalized}. \relax }}{17}{figure.caption.15}%
\contentsline {figure}{\numberline {2.12}{\ignorespaces HPC of level $ k = 5 $ (red stars) and full grid (black dots). A full grid would have $ 33^2 = 1089 $ and this grid has $ 147 $ points. Taken from \blx@tocontentsinit {0}\cite {duan2016induction}.\relax }}{20}{figure.caption.36}%
\addvspace {10\p@ }
\addvspace {10\p@ }
\addvspace {10\p@ }
\providecommand \tocbasic@end@toc@file {}\tocbasic@end@toc@file 
