\chapter{\abstractname}

In recent years, machine learning has gained significant importance due to the increasing amount of available data. The numerous different model architectures share a common characteristic - they have parameters or design decisions that are fixed before being trained on data. The right choice of the so-called hyperparameters can have a huge impact on the performance which is why they have to be optimized. Different techniques like grid search, random search, and Bayesian optimization have been developed to tackle this problem.

In this thesis, a new approach called adaptive sparse grid search for hyperparameter optimization is introduced. This technique allows to adapt to the hyperparameter space and the model which leads to less training and evaluation runs compared to normal grid search. Additionally, we present an adapted random search approach which is also adaptive to the data by iteratively adding sampled points. Three different refinement strategies for the concrete sampling are introduced and analyzed.

We compare the newly proposed approaches to the aforementioned three techniques with respect to both computational budget and resultant model performance. We conduct experiments using diverse machine learning tasks and datasets. The findings demonstrate that adaptive sparse grid search for hyperparameter optimization significantly outperforms standard grid search, particularly in high-dimensional settings. The comparisons show that each algorithm performs well for specific optimization settings. The iterative sparse grid search approach shows promise, though it necessitates further in-depth analysis.

\chapter*{Zusammenfassung} 

In den letzten Jahren hat das maschinelle Lernen aufgrund der zunehmenden Menge an verfügbaren Daten erheblich an Bedeutung gewonnen. Die zahlreichen unterschiedlichen Modellarchitekturen haben ein gemeinsames Merkmal - sie haben Parameter oder Designentscheidungen, die vor dem Training auf Daten festgelegt werden. Die richtige Wahl der so genannten Hyperparameter kann einen großen Einfluss auf die Leistung haben, weshalb sie optimiert werden müssen. Verschiedene Techniken wie Gittersuche, Zufallssuche und Bayes'sche Optimierung wurden entwickelt, um dieses Problem zu lösen.

In dieser Arbeit wird ein neuer Ansatz, die adaptive Sparse-Grid-Suche für die Hyperparameter-Optimierung, vorgestellt. Diese Technik ermöglicht die Anpassung an den Hyperparameterraum und das Modell, was im Vergleich zur normalen Gittersuche zu weniger Trainings- und Evaluierungsläufen führt. Zusätzlich wird ein angepasster Zufallssuchansatz vorgestellt, der sich ebenfalls an die Daten anpasst, indem iterativ Zufallspunkte hinzugefügt werden. Es werden drei verschiedene Verfeinerungsstrategien für das konkrete Sampling vorgestellt und analysiert.

Wir vergleichen die neuen Ansätze mit den anderen drei genannten Techniken hinsichtlich des Budgets und der resultierenden Modellleistung unter Verwendung verschiedener maschineller Lernaufgaben und Datensätze. Die Ergebnisse zeigen, dass die adaptive Sparse-Grid-Suche für die Hyperparameter-Optimierung deutlich besser abschneidet als die normale Gittersuche in hohen Dimensionen. Die Vergleiche zeigen, dass jeder Algorithmus für bestimmte Optimierungsprobleme gut abschneidet. Die iterative Sparse-Grid-Suche zeigt vielversprechende Ergebnisse.
