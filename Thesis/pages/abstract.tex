\chapter{\abstractname}

In recent years, machine learning has gained significant importance due to the increasing amount of available data. The numerous different model architectures share a common characteristic - they have parameters or design decisions that are fixed before being trained on data. The right choice of the so-called hyperparameters can have a huge impact on the performance which is why they have to be optimized. Different techniques like grid search, random search, and Bayesian optimization have been developed to tackle this problem. \newline

In this thesis, a new approach called adaptive sparse grid search for hyperparameter optimization is introduced. This technique allows to adapt to the hyperparameter space and the model which leads to less training and evaluation runs compared to normal grid search. Additionally, we present an adapted random search approach which is also adaptive to the data by iteratively adding sampled points. Three different refinement strategies for the concrete sampling are introduced and analyzed. \newline

We compare the new approaches to the other three techniques mentioned regarding budget and resulting model performance using different machine learning tasks and datasets. The results show that adaptive sparse grid search for hyperparameter optimization is performing much better than normal grid search in high dimensions. The comparisons show that each algorithm performs well for specific optimization settings. The iterative sparse grid search is promising and still requires further analysis.

\chapter*{Zusammenfassung} 

In den letzten Jahren hat das maschinelle Lernen aufgrund der zunehmenden Menge an verfügbaren Daten erheblich an Bedeutung gewonnen. Die zahlreichen unterschiedlichen Modellarchitekturen haben ein gemeinsames Merkmal - sie haben Parameter oder Designentscheidungen, die vor dem Training auf Daten festgelegt werden. Die richtige Wahl der so genannten Hyperparameter kann einen großen Einfluss auf die Leistung haben, weshalb sie optimiert werden müssen. Verschiedene Techniken wie Gittersuche, Zufallssuche und Bayes'sche Optimierung wurden entwickelt, um dieses Problem zu lösen. \newline

In dieser Arbeit wird ein neuer Ansatz, die adaptive Sparse-Grid-Suche für die Hyperparameter-Optimierung, vorgestellt. Diese Technik ermöglicht die Anpassung an den Hyperparameterraum und das Modell, was im Vergleich zur normalen Gittersuche zu weniger Trainings- und Evaluierungsläufen führt. Zusätzlich wird ein angepasster Zufallssuchansatz vorgestellt, der sich ebenfalls an die Daten anpasst, indem iterativ Zufallspunkte hinzugefügt werden. Es werden drei verschiedene Verfeinerungsstrategien für das konkrete Sampling vorgestellt und analysiert. \newline

Wir vergleichen die neuen Ansätze mit den anderen drei genannten Techniken hinsichtlich des Budgets und der resultierenden Modellleistung unter Verwendung verschiedener maschineller Lernaufgaben und Datensätze. Die Ergebnisse zeigen, dass die adaptive Sparse-Grid-Suche für die Hyperparameter-Optimierung deutlich besser abschneidet als die normale Gittersuche in hohen Dimensionen. Die Vergleiche zeigen, dass jeder Algorithmus für bestimmte Optimierungsprobleme gut abschneidet. Die iterative Sparse-Grid-Suche zeigt vielversprechende Ergebnisse.
